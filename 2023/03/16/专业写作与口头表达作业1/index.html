<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png"><link rel="icon" href="/img/fluid.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="author" content="peter？"><meta name="keywords" content=""><meta name="description" content="截止：今晚之前 要求：? Pathology diagnostics relies on the assessment of morphology by trained experts, which remains subjective and qualitative. Here we developed a framework for large-scale histomorphometry ("><meta property="og:type" content="article"><meta property="og:title" content="专业写作与口头表达作业1"><meta property="og:url" content="http://petertan303.github.io/2023/03/16/%E4%B8%93%E4%B8%9A%E5%86%99%E4%BD%9C%E4%B8%8E%E5%8F%A3%E5%A4%B4%E8%A1%A8%E8%BE%BE%E4%BD%9C%E4%B8%9A1/index.html"><meta property="og:site_name" content="petertan303"><meta property="og:description" content="截止：今晚之前 要求：? Pathology diagnostics relies on the assessment of morphology by trained experts, which remains subjective and qualitative. Here we developed a framework for large-scale histomorphometry ("><meta property="og:locale" content="zh_CN"><meta property="article:published_time" content="2023-03-16T04:57:39.000Z"><meta property="article:modified_time" content="2023-04-23T15:21:36.305Z"><meta property="article:author" content="peter？"><meta name="twitter:card" content="summary_large_image"><title>专业写作与口头表达作业1 - petertan303</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"petertan303.github.io",root:"/",version:"1.9.4",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,follow_dnt:!0,baidu:"6a833fa5fd2900165acbe7570545a8a2",google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:"mV6pM4FkddUR4CfQioaXxMrp-9Nh9j0Va",app_key:"YvR7UmmLPsWePIigEYzEjLuy",server_url:"https://mv6pm4fk.lc-cn-n1-shared.com",path:"window.location.pathname",ignore_local:!0}},search_path:"/local-search.xml"};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><script async>if(!Fluid.ctx.dnt){var _hmt=_hmt||[];!function(){var t=document.createElement("script");t.src="https://hm.baidu.com/hm.js?6a833fa5fd2900165acbe7570545a8a2";var e=document.getElementsByTagName("script")[0];e.parentNode.insertBefore(t,e)}()}</script><meta name="generator" content="Hexo 6.3.0"></head><body><header><div class="header-inner" style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>PeterTan303</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> <span>首页</span></a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> <span>归档</span></a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> <span>分类</span></a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> <span>标签</span></a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> <span>关于</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/default.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="专业写作与口头表达作业1"></span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2023-03-16 12:57" pubdate>2023年3月16日 下午</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i>15k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i>122 分钟 </span><span id="leancloud-page-views-container" class="post-meta" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="leancloud-page-views"></span> 次</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 style="display:none">专业写作与口头表达作业1</h1><div class="markdown-body"><p><strong>截止：今晚之前</strong></p><p>要求：?</p><pre><code class="hljs">Pathology diagnostics relies on the assessment of morphology by trained experts, which remains subjective and qualitative. Here we developed a framework for large-scale histomorphometry (FLASH) performing deep learning-based semantic segmentation and subsequent large-scale extraction of interpretable, quantitative, morphometric features in non-tumour kidney histology. We use two internal and three external, multi-centre cohorts to analyse over 1000 kidney biopsies and nephrectomies. By associating morphometric features with clinical parameters, we confirm previous concepts and reveal unexpected relations. We show that the extracted features are independent predictors of long-term clinical outcomes in IgA-nephropathy. We introduce single-structure morphometric analysis by applying techniques from single-cell transcriptomics, identifying distinct glomerular populations and morphometric phenotypes along a trajectory of disease progression. Our study provides a concept for Next-generation Morphometry (NGM), enabling comprehensive quantitative pathology data mining, i.e., pathomics.
</code></pre><p>from: <a target="_blank" rel="noopener" href="https://www.nature.com/articles/s41467-023-36173-0">https://www.nature.com/articles/s41467-023-36173-0</a></p><pre><code class="hljs">Background
Image-based machine learning tools hold great promise for clinical applications in pathology research. However, the ideal end-users of these computational tools (e.g., pathologists and biological scientists) often lack the programming experience required for the setup and use of these tools which often rely on the use of command line interfaces.

Methods
We have developed Histo-Cloud, a tool for segmentation of whole slide images (WSIs) that has an easy-to-use graphical user interface. This tool runs a state-of-the-art convolutional neural network (CNN) for segmentation of WSIs in the cloud and allows the extraction of features from segmented regions for further analysis.

Results
By segmenting glomeruli, interstitial fibrosis and tubular atrophy, and vascular structures from renal and non-renal WSIs, we demonstrate the scalability, best practices for transfer learning, and effects of dataset variability. Finally, we demonstrate an application for animal model research, analyzing glomerular features in three murine models.

Conclusions
Histo-Cloud is open source, accessible over the internet, and adaptable for segmentation of any histological structure regardless of stain.
</code></pre><p>from: <a target="_blank" rel="noopener" href="https://www.nature.com/articles/s43856-022-00138-z">https://www.nature.com/articles/s43856-022-00138-z</a></p><pre><code class="hljs">Complex diseases are characterized by spatiotemporal cellular and molecular changes that may be difficult to comprehensively capture. However, understanding the spatiotemporal dynamics underlying pathology can shed light on disease mechanisms and progression. Here we introduce STARmap PLUS, a method that combines high-resolution spatial transcriptomics with protein detection in the same tissue section. As proof of principle, we analyze brain tissues of a mouse model of Alzheimer’s disease at 8 and 13 months of age. Our approach provides a comprehensive cellular map of disease progression. It reveals a core–shell structure where disease-associated microglia (DAM) closely contact amyloid-β plaques, whereas disease-associated astrocyte-like (DAA-like) cells and oligodendrocyte precursor cells (OPCs) are enriched in the outer shells surrounding the plaque-DAM complex. Hyperphosphorylated tau emerges mainly in excitatory neurons in the CA1 region and correlates with the local enrichment of oligodendrocyte subtypes. The STARmap PLUS method bridges single-cell gene expression profiles with tissue histopathology at subcellular resolution, providing a tool to pinpoint the molecular and cellular changes underlying pathology.
</code></pre><p>from: <a target="_blank" rel="noopener" href="https://www.nature.com/articles/s41593-022-01251-x">https://www.nature.com/articles/s41593-022-01251-x</a></p><pre><code class="hljs">病理学检验是诸多疾病临床诊断的金标准，利用图像处理与人工智能技术对数字病
理图像进行分析，可以实现病灶的计算机辅助检测。在全扫描切片的情境下，可以进一
步获取更丰富的与肿瘤微环境、免疫微环境相关的信息，起到改进风险分层、支持治疗
决策等目的。数字病理图像分析的挑战主要来自于全扫描切片的数据体量、组织学与图
像外观的异质性、数据标注的昂贵代价，以及模型可解释性方面的需求。本文聚焦于基
于深度学习的数字病理图像分析系统，从细分领域综述、方法学研究，以及应用探索三
个方面展开工作，主要内容如下：
1、系统地总结了近期计算病理学领域的进展，并着重介绍了其在肺癌、结直肠癌、
乳腺癌切片，以及免疫组织化学染色切片和非肿瘤切片分析中的应用。在介绍相关知识
的同时，以前景识别任务为例展示了一套完整的计算病理学模型开发流程。
2、针对来自于组织学与图像外观多样性的挑战，提出了适用于大型队列的染色模式
分析工具。通过采样、聚类、色谱距离定义与求解，以及降维的步骤，对队列内全扫描
切片的颜色模式进行可视化。进一步以该方法为工具，分析了一个计算病理学模型的开
发与测试过程，得出了若干具有实践指导意义的结论。
3、针对标注数据收集代价高的挑战，提出了将深度预编码与逻辑斯蒂回归模型相结
合的方法。由于该方法的高效性，其得以集成于主动学习框架内，成为交互式标注的解
决方案。本文在三个大型数据集上验证了所提出方法的可行性，并针对编码器与主动学
习策略进行了深入的比较性研究。
4、开发了针对具体病种的计算病理学模型，并进行了有关模型的可解释性与临床意
义的探索：
(a) 针对心内膜心肌活检组织病理图像，提出了临床心力衰竭检测模型，在训练VGG
模型实现病灶检测目的的同时，提出使用包括梯度-类别激活可视化技术、特征
空间的UMAP 降维，以及交叠式交叉验证等策略，提升模型输出的可解释性，
增强了信服力；
(b) 针对结肠腺癌组织病理切片，提出了肿瘤微环境的自动分析方法，并验证了与肿
瘤间质、坏死、淋巴细胞相关指标的预后提示意义；
(c) 针对肺癌组织病理图像，开发了基于 U-Net 的癌灶检测模型，并结合癌灶分割
结果与淋巴细胞空间分布图，提出了肿瘤与淋巴细胞交互程度的量化方法，并验
证了其预后意义。
关键词：数字病理图像，深度学习，计算病理学，计算机辅助诊断，肿瘤微环境，免
疫微环境，病灶检测
III
Abstract
Pathological examination is the golden standard of numerous diseases in clinics. Powered by
image processing and artificial intelligence techniques, modern computer-aided diagnostic
(CAD) models are able to detect lesions in histopathological images. In the context of
whole-slide images, more information such as tumor microenvironment,
immuno-microenvironment can be obtained. This information plays a crucial role in risk
stratification and may support disease management. The challenges in digital pathological
image analysis mainly include the huge data volume, the histological and apparent
heterogeneity, the cost of data annotation, and the requirement of model interpretability. This
thesis focuses on deep learning-based digital pathological image analytic systems, carries on
the investigations from three aspects. The main contents are as follows:
1. We made a systematic summary of recent advances in computational pathology, with
emphasis on its applications in lung cancer, colorectal cancer, breast cancer,
immunohistochemistry-stained slides, and non-tumor disease. At the same time, we
showed a full development procedure of a computational pathology model in the context
of a foreground segmentation task.
2. To solve the challenge of histologic and apparent heterogeneity, we propose an analytic
tool to visualize the staining pattern of large cohorts of digital slides. The method is
composed of procedures including sampling, clustering, defining and solving distances
between color spectrums, and dimensional reduction. Using this tool, we were able to
analyze the development and deployment of a CAD model, leading to several conclusions
that have practical guiding significance.
3. To deal with the expensiveness of data annotation, we propose to combine deep
pre-encoding and logistic regression models. Because of the high efficiency, it can be
integrated into an active learning framework, serving as a potential solution for interactive
data annotation. We verified the method on three large-scale datasets, and conducted
intensive comparative studies regarding the type of encoder and active learning strategy.
4. We developed a number of computational pathology models for specific diseases, and
made investigations towards model interpretability and its clinical value.
(a) We proposed a clinical heart failure detection model in endocardial myocardial biopsy
images; along with the training of VGG models for detection task, we propose to use
techniques including Grad-CAM, UMAP, and overlapped cross-validation to obtain
interpretable predictions, adding convincement of the models.
(b) We propose an automatic framework to quantify tumor microenvironment (TME) in
Abstract
IV
colon adenocarcinoma slides, and verify the prognostic value of tumor stroma,
necrosis, and lymphocytes distribution.
(c) We also propose a U-Net-based model for cancer detection in lung specimens.
Combined with the spatial distribution map of lymphocytes, we quantified the
interaction between tumor cells and lymphocytes, which turned out to has prognostic
value.
Keywords: Digital pathological images, deep learning, computational pathology,
computer-aided diagnosis, tumor microenvironment, immuno-microenvironment, lesion
detection
</code></pre><p>from:</p><pre><code class="hljs">腺癌是一种常发生于上皮腺体组织的癌症类型，在结直肠癌、前列腺癌、乳腺癌、
肺癌等多种恶性肿瘤中都十分常见。在病理形态上，腺癌的发生往往伴随着腺体结构分
化变差甚至不分化，即腺体组织呈现出异常变形扭曲、内部空腔结构被细胞核侵占致其
缩小甚至消失。这种不同程度的腺体分化直接与腺癌的恶性程度相关联。因此，在临床
病理诊断中，腺体组织结构的分化程度是病理学家确定腺癌等级乃至决策治疗方案的决
定性因素。
为了实现腺癌恶性程度的自动评估分级，本文从腺体结构分化程度这一病理诊断标
准出发：一方面，本文设计了领域特定的手工特征，提出了基于同源性分布统计表示的
前列腺癌自动格里森分级方法。该方法首先基于同源性分布算法计算病理图像的同源性
分量，通过描述腺体周围细胞核间的拓扑排列对腺体结构分化程度进行定量化；然后用
统计量对获得的同源性序列特征进行二次表征；最后采用加权K 近邻分类器算法建模
实现前列腺癌病理图像的自动分级。实验结果表明，相比无监督学习方法SSAE、有监
督方法DLGg 和传统病理组学方法MATF，本文方法分级表现更出色，特征也具有更好
的鲁棒性。而且，本文提出的特征表示方法具有生物学基础，可解释性强。
另一方面，启发于对腺体结构自动分割结果进行精确描述以实现诊断的思路，本文
提出基于多任务学习和先验知识的腺癌良恶自动评估方法。该方法首先利用特征学习骨
干网络进行特征提取，提取到的特征分别被送入分割分支和分类分支进行腺体结构自动
分割和腺癌图像的自动良恶分级；同时，分割分支的腺体结构预测作为先验知识被编码
为空间注意力融合到分类分支中以约束分级的推理偏好。实验结果验证了本文基于先验
知识约束的多任务网络模型的有效性，在腺癌测试集上达到最高97.04%的准确率和
0.9971 的AUC 值。而且，本文的先验知识约束思想同样具有解释性。
本文研究的基于病理图像分析的癌症恶性程度自动评估分级方法，立足自腺体结构
分化这一病理诊断标准，因而可以为病理医生提供可解释的辅助诊断支持。
关键词：腺癌，自动分级，同源性分布，先验知识，多任务学习
南京信息工程大学硕士学位论文
II
Abstract
Adenocarcinoma is a type of cancer that often occurs in epithelial gland tissues. It is
common in malignant tumors such as colorectal cancer, prostate cancer, breast cancer, and lung
cancer. In terms of pathological pattern, the occurrence of adenocarcinoma is often
accompanied by poor or undifferentiated gland structure. The glands are abnormally stretched
and distorted, and the cavity structures are invaded by the nuclei, causing it to shrink or even
disappear. This situation is directly related to the degree of malignancy of adenocarcinoma.
Therefore, the degree of differentiation of glandular structure is a decisive factor for
pathologists to determine the grade of adenocarcinoma and decide the treatment plan in clinical
pathological diagnosis.
In this paper, to realize the automated grading of the malignant degree of adenocarcinoma,
the study evolves from the degree of gland structure differentiation which is a pathological
diagnostic criteria. On the one hand, this paper designs domain-specific hand-crafted features
and proposes an automated gleason grading method for prostate adenocarcinoma based on the
statistical representation of homology profile. This method first calculates the homology
components of pathological images based on the homology profile algorithm, and quantifies
the degree of gland structure differentiation by describing the topological arrangement of nuclei
around the gland. Then it employs statistical methods for secondary characterization on the
obtained homology sequence characteristics. The method finally models the weighted Knearest
neighbor classifier algorithm for automated gleason grading of pathological images on
adenocarcinoma. Experimental results show that this method performs better in grading and
features robustness, compared with unsupervised learning method SSAE, supervised method
DLGg and traditional pathomics-based method MATF. In addition, the proposed homology
feature representation method has a strong biological basis and is highly interpretable.
On the other hand, inspired by the idea of accurately describing the automatic segmentation
of glandular structures for diagnosis, this paper proposes an automated assessment method for
colorectal adenocarcinoma based on multi-task learning and prior knowledge. Firstly, this
method employs the backbone network for feature extraction, and the extracted features are
respectively sent to the segmentation branch and classification branch for automated gland
structure segmentation and grading of adenocarcinoma images. Meanwhile, the automated
Abstract
III
gland structure prediction from the segmentation branch acts as the prior knowledge, and it is
encoded as spatial attention and merged into the classification branch to constrain the reasoning.
The experimental results verify the effectiveness of the prior knowledge-aware multi-task
network, achieving the highest accuracy of 97.04% and AUC value of 0.9971 on the test set.
Moreover, the idea of prior knowledge constraint in this paper is also interpretable.
The automated assessment grading methods based on pathological image analysis are
proposed for cancer malignancy. Importantly, the glandular structure differentiation acting as
the pathological diagnosis criteria is fundamental to them. The methods thus can provide
pathologists with interpretable auxiliary diagnosis support.
Key words: Adenocarcinoma, Automated grading, Homology profile, Prior knowledge, Multitask
learning
</code></pre><p>from:</p><pre><code class="hljs">病理图像分割是进行病理图像定量分析的重要基础，在疾病的研究、临床诊断、治
疗和预后中具有重要的价值。传统的分割方法一般为手动或半自动的方法，在分割效率
或准确性上远远不能满足临床需求。病理图像的分析相比于自然图像更加困难，目前的
深度学习分割模型在病理图像的分割任务中仍然存在分割的准确率和鲁棒性都比较低
的问题。造成这些问题的主要原因是一般的深度学习分割模型主要依赖于预定义的损失
函数训练机制进行训练，因此不能较好的衡量出模型输出和真实标记之间的误差并指导
模型的训练。
本文基于生成对抗网络(GAN)和条件生成对抗网络(cGAN)的基本原理在多种病理
图像分析任务中构建了组织和细胞层次的分割模型，基于分割的结果发现了许多疾病关
联的视觉或亚视觉特征，并将这些特征用于临床辅助诊断和预后。在病理图像分析任务
中，本文基于cGAN 构建了以下的分割模型和框架：(1)构建了H&amp;E 染色病理图像中的
细胞核语义分割和实例分割模型SIcGAN，该模型可以对所有的细胞核进行精确的语义
分割；(2)构建了乳腺H&amp;E 染色病理图像中上皮和间质区域的自动分割模型EPScGAN，
和当前主流的图像分割模型对比，EPScGAN 可以达到最优的分割性能；(3)针对急性髓
性白血病(AML)染色病理涂片中髓性细胞(Myeloblast)的检测和分割，构建了AMLcGAN
分割和检测的模型及框架。另外，基于成髓性细胞的分割结果提取了成髓性细胞的图像
特征来对骨髓转移治疗的有效性进行了预测。(4)为了能够精确诊断慢性髓性白血病
(CML)，构建了CML 染色病理切片中巨核细胞(Megakaryocyte)的检测和分割模型
MKcGAN，然后基于分割结果提取了巨核细胞的统计学特征对CML 进行了有效地诊断。
(5)在口腔癌的H&amp;E 染色病理图像中，构建了多细胞核(MN)的分割和检测模型
MNSDcGAN，并且在多家单位提供的总共758 个全扫描图像(WSI)病例中进行了测试，
最终发现提取的MN 特征与口腔癌病人的5 年生存率密切相关。
关键字：病理图像分析，条件生成对抗网络(GAN)
南京信息工程大学硕士学位论文
II
Abstract
The segmentation of histologic images is an important prerequisite for medical image
analysis, and has important value in disease research, clinical diagnosis, treatment and
prognosis. The traditional segmentation method is generally a manual or semi-automatic
method, which is far from meeting the clinical needs in terms of segmentation efficiency or
accuracy. Compared with natural images, pathological image recognition is more difficult. The
current deep learning segmentation model still has the problem of low segmentation accuracy
and robustness in the segmentation task of pathological images. The main reason for these
problems is that the general deep learning segmentation model mainly relies on the pre-defined
loss function training mechanism for training, so it cannot measure the error between the model
output and the true label and guide the model training.
In this paper, based on the basic principles of generative adversarial networks (GAN) and
conditional generative adversarial networks (cGAN), segmentation models at the tissue and cell
levels are constructed in a variety of pathological image analysis tasks. Based on the results of
segmentation, many disease-related visual or sub-visual Visual features, and use these features
for clinical auxiliary diagnosis and prognosis. In the pathological image analysis task, this paper
constructed the following segmentation model and framework based on cGAN: (1) Constructed
the semantic segmentation of nuclei in H &amp; E stained pathological images and the instance
segmentation model SIcGAN, which can carry out precise semantics on all nuclei Segmentation;
(2) Constructed an automatic segmentation model EPScGAN of epithelial and interstitial
regions in H &amp; E stained pathological images of breast. Compared with the current mainstream
image segmentation model, EPScGAN can achieve optimal segmentation performance;
Detection and segmentation of myeloblast (Myeloblast) in the pathological smear of leukemia
(AML), constructed the model and framework of AMLcGAN segmentation and detection, and
then extracted the image features of Myeloblast based on the segmentation result of Myeloblast
to be effective for bone marrow metastasis Sex was predicted. (4) For the diagnosis of chronic
myeloid leukemia (CML), a megakaryocyte (Megakaryocyte) detection and segmentation
model in CML stained pathological sections was constructed, and then the statistical
characteristics of Megakaryocytes were extracted based on the segmentation results. diagnosis.
摘要
III
(5) In the H &amp; E stained pathological image of oral cancer, a multi-cell nuclei (MN)
segmentation and detection model MNSDcGAN was constructed, and tested in a total of 758
full-scan image (WSI) cases provided by multiple units, and finally found The extracted MN
features are closely related to the 5-year survival rate of oral cancer patients.
Key words: Histology image analysis, conditional Generative Adversarial Network
</code></pre><ul><li>病理图像的概念</li><li>综述论文结构</li><li>病理图像分析主要方法（框图）</li><li>数据库、源代码</li></ul><h1 id="病理图像的概念"><a href="#病理图像的概念" class="headerlink" title="病理图像的概念"></a>病理图像的概念</h1><pre><code class="hljs">利用图像处理与人工智能技术对数字病理图像进行分析，可以实现病灶的计算机辅助检测。在全扫描切片的情境下，可以进一步获取更丰富的与肿瘤微环境、免疫微环境相关的信息，起到改进风险分层、支持治疗决策等目的。数字病理图像分析的挑战主要来自于全扫描切片的数据体量、组织学与图像外观的异质性、数据标注的昂贵代价，以及模型可解释性方面的需求。
</code></pre><h1 id="综述论文结构"><a href="#综述论文结构" class="headerlink" title="综述论文结构"></a>综述论文结构</h1><ul><li>介绍背景：<ul><li>领域现在的发展</li><li>仍然存在的问题</li></ul></li><li>介绍研究本身<ul><li>研究的手段</li><li>所研究的问题</li><li>研究的具体方法</li></ul></li><li>研究的意义</li><li>关键词</li></ul><h1 id="病理图像分析主要方法（框图）"><a href="#病理图像分析主要方法（框图）" class="headerlink" title="病理图像分析主要方法（框图）"></a>病理图像分析主要方法（框图）</h1><p>暂定</p></div><hr><div><div class="post-metas my-3"></div><div class="license-box my-3"><div class="license-title"><div>专业写作与口头表达作业1</div><div>http://petertan303.github.io/2023/03/16/专业写作与口头表达作业1/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>peter？</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2023年3月16日</div></div><div class="license-meta-item"><div>许可协议</div><div><a target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div></div></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>目录</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div><div class="statistics"><span id="leancloud-site-pv-container" style="display:none">总访问量 <span id="leancloud-site-pv"></span> 次 </span><span id="leancloud-site-uv-container" style="display:none">总访客数 <span id="leancloud-site-uv"></span> 人</span></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t,e){var i=Fluid.plugins.typing,n=e.getElementById("subtitle");n&&i&&i(n.getAttribute("data-typed-text"))}(window,document)</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var i=jQuery("#board-ctn").offset().top;window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-i},CONFIG.toc)),t.find(".toc-list-item").length>0&&t.css("visibility","visible"),Fluid.events.registerRefreshCallback((function(){if("tocbot"in window){tocbot.refresh();var t=jQuery("#toc");if(0===t.length||!tocbot)return;t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))}}))</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback((function(){if("anchors"in window){anchors.removeAll();var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}}))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script defer src="/js/leancloud.js"></script><script src="/js/local-search.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript><script type="text/x-mathjax-config">MathJax.Hub.Config({ tex2jax: { inlineMath: [ ["$","$"], ["\\(","\\)"] ], skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'], processEscapes: true } }); MathJax.Hub.Queue(function() { var all = MathJax.Hub.getAllJax(); for (var i = 0;
    i
    < all.length; ++i) all[i].SourceElement().parentNode.className +=' has-jax' ; });</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script></body></html>