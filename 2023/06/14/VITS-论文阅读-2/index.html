<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png"><link rel="icon" href="/img/fluid.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="author" content="peter？"><meta name="keywords" content=""><meta name="description" content="训练和推理流程如下：  方法条件推理（conditional VAE formulation）基于变分推理的对准估计（alignment estimation derived from variational inference）。 目标为一个”变分下界”，也叫证据下界（ELBO）。详细说就是“ intractable marginal log-likelihood ”棘手边缘拟合对数似然的变分下"><meta property="og:type" content="article"><meta property="og:title" content="VITS 论文阅读-2"><meta property="og:url" content="http://petertan303.github.io/2023/06/14/VITS-%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-2/index.html"><meta property="og:site_name" content="petertan303"><meta property="og:description" content="训练和推理流程如下：  方法条件推理（conditional VAE formulation）基于变分推理的对准估计（alignment estimation derived from variational inference）。 目标为一个”变分下界”，也叫证据下界（ELBO）。详细说就是“ intractable marginal log-likelihood ”棘手边缘拟合对数似然的变分下"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://petertan303.github.io/img/QQ%E6%88%AA%E5%9B%BE20230614191808.png"><meta property="og:image" content="http://petertan303.github.io/img/QQ%E6%88%AA%E5%9B%BE20230614185303.png"><meta property="article:published_time" content="2023-06-14T07:53:57.000Z"><meta property="article:modified_time" content="2023-06-14T12:18:05.601Z"><meta property="article:author" content="peter？"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="http://petertan303.github.io/img/QQ%E6%88%AA%E5%9B%BE20230614191808.png"><title>VITS 论文阅读-2 - petertan303</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var CONFIG={hostname:"petertan303.github.io",root:"/",version:"1.9.4",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"left",visible:"hover",icon:""},progressbar:{enable:!0,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,follow_dnt:!0,baidu:"6a833fa5fd2900165acbe7570545a8a2",google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:"mV6pM4FkddUR4CfQioaXxMrp-9Nh9j0Va",app_key:"YvR7UmmLPsWePIigEYzEjLuy",server_url:"https://mv6pm4fk.lc-cn-e1-shared.com",path:"window.location.pathname",ignore_local:!0}},search_path:"/local-search.xml"};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><script async>if(!Fluid.ctx.dnt){var _hmt=_hmt||[];!function(){var t=document.createElement("script");t.src="https://hm.baidu.com/hm.js?6a833fa5fd2900165acbe7570545a8a2";var e=document.getElementsByTagName("script")[0];e.parentNode.insertBefore(t,e)}()}</script><meta name="generator" content="Hexo 6.3.0"></head><body><header><div class="header-inner" style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>PeterTan303</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> <span>首页</span></a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> <span>归档</span></a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> <span>分类</span></a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> <span>标签</span></a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> <span>关于</span></a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search"><i class="iconfont icon-search"></i></a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle"><i class="iconfont icon-dark" id="color-toggle-icon"></i></a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(/img/default.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="VITS 论文阅读-2"></span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2023-06-14 15:53" pubdate>2023年6月14日 下午</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i>4.1k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i>35 分钟 </span><span id="leancloud-page-views-container" class="post-meta" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="leancloud-page-views"></span> 次</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 style="display:none">VITS 论文阅读-2</h1><div class="markdown-body"><p>训练和推理流程如下：</p><p><img src="/img/QQ截图20230614191808.png" srcset="/img/loading.gif" lazyload alt=""></p><h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><h2 id="条件推理（conditional-VAE-formulation）"><a href="#条件推理（conditional-VAE-formulation）" class="headerlink" title="条件推理（conditional VAE formulation）"></a>条件推理（conditional VAE formulation）</h2><p>基于变分推理的对准估计（alignment estimation derived from variational inference）。</p><p>目标为一个”变分下界”，也叫证据下界（ELBO）。详细说就是“ intractable marginal log-likelihood ”棘手边缘拟合对数似然的变分下界。</p><p>如图，$L<em>{\text {recon }}$，即$\left|x</em>{mel}-\hat{x}<em>{mel}\right|</em>{1}\log p<em>{\theta}(x \mid c)$的变分下界为$\mathbb{E}</em>{q<em>{\phi}(z \mid x)}\left[\log p</em>{\theta}(x \mid z)-\log \frac{q<em>{\phi}(z \mid x)}{p</em>{\theta}(z \mid c)}\right]$。</p><script type="math/tex;mode=display">L_{\text {recon }}=\left\|x_{mel}-\hat{x}_{mel}\right\|_{1}\log p_{\theta}(x \mid c) \geq \mathbb{E}_{q_{\phi}(z \mid x)}\left[\log p_{\theta}(x \mid z)-\log \frac{q_{\phi}(z \mid x)}{p_{\theta}(z \mid c)}\right]</script><p>下界：似然【数据点x的似然函数 - （近似后验分布 / 条件c下潜变量z的先验分布）的对数】</p><p>训练损失即负的ELBO。</p><p>也可以看作为重建损失 + KL散度，这在潜变量z服从近似后验分布时成立。</p><h3 id="重建损失"><a href="#重建损失" class="headerlink" title="重建损失"></a>重建损失</h3><p>作为重建损失中的目标数据点，我们使用<strong>mel频谱图</strong>而不是原始波形，由 $x<em>{mel}$ 表示。我们通过<strong>解码器</strong>将潜在变量z<strong>上采样到波形域</strong> $\hat{y}$ ，并将 $\hat{y}$ <strong>变换到融合谱图域</strong> $\hat{x}</em>{mel}$ 。然后，预测的和目标mel谱图之间的L1损失被用作重建损失：</p><script type="math/tex;mode=display">L_{\text {recon }}=\left\|x_{mel}-\hat{x}_{mel}\right\|_{1}</script><p>这可以被视为<strong>假设数据分布的拉普拉斯分布并忽略常数项</strong>的最大似然估计。我们定义了mel声谱图域中的重建损失，以通过使用近似人类听觉系统响应的mel标度来提高感知质量。注意，根据原始波形的mel谱图估计不需要可训练的参数，因为它只使用STFT和线性投影到mel标度上。<strong>此外，估计仅在训练期间使用，而不是推理。</strong>在实践中，我们不对整个潜在变量z进行上采样，而是使用部分序列作为解码器的输入，这是用于高效端到端训练的窗口生成器训练。</p><h3 id="KL收敛"><a href="#KL收敛" class="headerlink" title="KL收敛"></a>KL收敛</h3><p>先验编码器c的输入条件由从文本中提取的音素$c_{text}$和音素与潜在变量之间的对齐 A 组成。</p><p>对齐是一个硬单调注意力矩阵，其$\mid c_{text}\mid \times \mid z\mid$维度表示每个输入音素扩展到与目标语音时间对齐的长度。由于对齐没有基本事实标签，我们必须在每次训练迭代时估计对齐。</p><p>在我们的问题设置中，我们的目标是为后验编码器提供更多的高分辨率信息。因此，我们使用目标语音$x_{lin}$的线性尺度频谱图作为输入，而不是mel频谱图。注意，修改后的输入并不违反变分推理的性质。那么KL分歧是：</p><p><img src="/img/QQ截图20230614185303.png" srcset="/img/loading.gif" lazyload alt=""></p><p>“因子分解正态分布”用于参数化我们的先验和后验编码器。</p><p>我们发现，增加先验分布的表现力对于生成真实样本很重要。因此，我们应用归一化流 f ，该流允许在因子分解的正态先验分布之上，根据变量变化规则，将简单分布可逆变换为更复杂的分布。</p><h2 id="路线估计（Alignment-Estimation）"><a href="#路线估计（Alignment-Estimation）" class="headerlink" title="路线估计（Alignment Estimation）"></a>路线估计（Alignment Estimation）</h2><p>基于变分推理的对准估计（alignment estimation derived from variational inference）。</p><h3 id="单调对齐搜索（MONOTONIC-ALIGNMENT-SEARCH）"><a href="#单调对齐搜索（MONOTONIC-ALIGNMENT-SEARCH）" class="headerlink" title="单调对齐搜索（MONOTONIC ALIGNMENT SEARCH）"></a>单调对齐搜索（MONOTONIC ALIGNMENT SEARCH）</h3><p>为了估计输入文本和目标语音之间的对齐A，我们采用<strong>单调对齐搜索（MAS）</strong>。</p><p>这是一种搜索对齐的方法，其最大化了由归一化流 f 参数化的数据的可能性。</p><p>因为人类按顺序阅读文本，不跳过任何单词，候选比对（ candidate alignments）被限制为单调且不跳过。</p><p>为了找到最佳对准，Kim等人（2020）使用动态规划。在我们的这个情况下直接应用MAS是困难的，因为我们的目标是ELBO，而不是确切的对数似然。因此，我们重新定义MAS，以找到最大化ELBO的对齐。</p><p>这个过程简化为找到最大化潜在变量z的对数似然的对齐。</p><p>但事实上，无论修不修改，都可以工作。因此我们使用的是原始MAS。</p><h3 id="文本时长预测器（DURATION-PREDICTION-FROM-TEXT）"><a href="#文本时长预测器（DURATION-PREDICTION-FROM-TEXT）" class="headerlink" title="文本时长预测器（DURATION PREDICTION FROM TEXT）"></a>文本时长预测器（DURATION PREDICTION FROM TEXT）</h3><p>我们可以通过对估计的对齐$\sum<em>{j}^{} A</em>{i,j}$的每行中的所有列求和来计算每个输入token$d_i$的持续时间。但持续时间可以用来训练确定性的持续时间预测器，但它不能表达一个人每次以不同的语速说话的方式。</p><p>为了生成类似人类的语音节奏，我们设计了一个<strong>随机持续时间预测器</strong>，使其样本遵循给定音素的持续时间分布。</p><p>随机持续时间预测器是一种基于流的生成模型，通常通过最大似然估计进行训练。然而，最大似然估计的直接应用是困难的，因为每个输入音素的持续时间是</p><p>1）离散整数，其需要被去量化（dequantized）以使用连续归一化流。</p><p>2）标量，其由于可逆性而无法进行高维变换。</p><p>我们应用<strong>变分去量化</strong>和<strong>变分数据扩充</strong>来解决这些问题。</p><p>具体地说，我们引入了两个随机变量 u 和 v ，它们具有与持续时间序列 d 相同的时间分辨率和维度，分别用于变分去方程化和变分数据扩充。</p><p>我们将u的支持度限制为[0, 1），使得差$d-v$变成了一个正实数序列。</p><p>我们按通道连接 v 和 d ，以生成更高维的潜在表示。、</p><p>我们通过近似后验分布$q(u,v|d,c<em>{text})$对这两个变量进行采样。由此产生的目标是<strong>音素持续时间的对数似然的变分下界</strong>。训练损失$L</em>{dur}$是<strong>负变分下界</strong>。</p><p>我们将阻止输入梯度反向传播的”停止梯度算子”应用于输入s，保证持续时间预测器的训练不会影响其他模块的训练。</p><p>而取样程序相对简单：通过随机持续时间预测器的逆变换，从随机噪声中采样音素持续时间，然后将其转换为整数。</p><h2 id="对抗训练"><a href="#对抗训练" class="headerlink" title="对抗训练"></a>对抗训练</h2><p>提高合成质量的对抗性训练（ adversarial training for improving synthesis quality）。</p><p>为了在我们的学习系统中采用对抗性训练，我们添加了一个鉴别器D，用于区分解码器G生成的输出和实际的波形y。</p><p>在这项工作中，我们使用了两种成功应用于语音合成的损失类型：一种是<strong>对抗性训练的最小二乘损失函数</strong>，另一种是<strong>训练生成器的附加特征匹配损失</strong>。</p><p>T表示鉴别器中的层的总数，并且$D^{l}$输出具有$N_{l}$个特征的鉴别器的第l层的特征图。</p><p>值得注意的是，特征匹配损失可以被视为在<strong>鉴别器的隐藏层中测量的重建损失</strong>，该重建损失被建议作为VAE的逐元素重建损失的替代方案。</p><h2 id="最终的损失函数"><a href="#最终的损失函数" class="headerlink" title="最终的损失函数"></a>最终的损失函数</h2><p>所有损失函数直接相加。</p><h2 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h2><p>总体架构由后验编码器、先验编码器、解码器、鉴别器和随机持续时间预测器组成。后验编码器和鉴别器仅用于训练，而不用于推理。</p><h3 id="后验编码器"><a href="#后验编码器" class="headerlink" title="后验编码器"></a>后验编码器</h3><p>对于后验编码器，我们使用WaveGlow和Glow TTS中使用的非因果WaveNet残差块。</p><p>WaveNet残差块由具有多个扩张卷积层（ dilated convolutions ），每层含有门控激活单元（gated activation unit）和跳跃连接（ skip connection）。块上方的线性投影层产生正态后验分布的均值和方差。</p><p>对于多个说话人的情况，我们在残差块中使用全局条件反射（global conditioning）来添加说话人embedding。</p><h3 id="先验编码器"><a href="#先验编码器" class="headerlink" title="先验编码器"></a>先验编码器</h3><p>先验编码器包括处理输入音素$c_{text}$的<strong>文本编码器</strong>、改进先验分布的灵活性的<strong>归一化流</strong> f 。</p><p>文本编码器是一种transformer编码器（transformer encoder），它使用相对位置表示（relative positional representation）而不是绝对位置编码（absolute positional encoding）。</p><p>我们可以通过文本编码器和文本编码器上方的线性投影层，从 $c<em>{text}$ 中获得 hidden representation $h</em>{text}$ ，该线性投影层产生用于构建先验分布的均值和方差。</p><p>归一化流(normalizing flow)是仿射耦合层（affine coupling layers）堆积而成，包含 WaveNet 残差块的堆栈。为了简单起见，我们将归一化流设计为雅可比行列式为1的保体积变换（a volume-preserving transformation with the Jacobian determinant of one）。</p><p>对于多说话人设置，我们通过全局条件，将说话人embedding加入到归一化流中的残差块中。</p><h3 id="解码器"><a href="#解码器" class="headerlink" title="解码器"></a>解码器</h3><p>解码器本质上是<strong>HiFi GAN V1生成器</strong>。它由”反条件姿态卷积”堆积组成，每个卷积后面，都有一个多接收场融合模块（MRF）。</p><p>MRF的输出是具有不同感受野大小的残差块的输出之和。</p><p>对于多说话人设置，我们添加一个转换说话人embedding的线性层，并将其添加到输入潜在变量z中。</p><h3 id="判别器"><a href="#判别器" class="headerlink" title="判别器"></a>判别器</h3><p>我们遵循HiFi GAN中提出的<strong>多周期鉴别器的鉴别器架构</strong>。</p><p>多周期判别器是基于<strong>马尔可夫窗的子鉴别器的混合</strong>，每个子判别器对输入波形的不同周期模式进行操作。</p><h3 id="随机持续时间预测器"><a href="#随机持续时间预测器" class="headerlink" title="随机持续时间预测器"></a>随机持续时间预测器</h3><p>随机持续时间预测器根据条件输入的 $h_{text}$ 估计音素持续时间的分布。</p><p>为了有效地参数化随机持续时间预测器，我们将<strong>残差块</strong>，与<strong>扩张和深度可分离的卷积层</strong>叠加。我们还将神经样条流（neural spline flows）应用于耦合层，其通过使用单调有理二次样条（monotonic rational-quadratic splines）采用可逆非线性变换的形式。</p><p>与常用的仿射耦合层相比，神经样条流的参数相似数量，但提高了变换的表现力。</p><p>对于多说话人设置，我们添加了一个线性层来转换说话人embedding，并将其添加到输入 $h_{text}$ 中。</p></div><hr><div><div class="post-metas my-3"></div><div class="license-box my-3"><div class="license-title"><div>VITS 论文阅读-2</div><div>http://petertan303.github.io/2023/06/14/VITS-论文阅读-2/</div></div><div class="license-meta"><div class="license-meta-item"><div>作者</div><div>peter？</div></div><div class="license-meta-item license-meta-date"><div>发布于</div><div>2023年6月14日</div></div><div class="license-meta-item"><div>许可协议</div><div><a target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div><div class="post-prevnext my-3"><article class="post-prev col-6"></article><article class="post-next col-6"><a href="/2023/06/13/fpga-%E7%94%B5%E6%A2%AF%E9%A1%B9%E7%9B%AE/" title="fpga 电梯项目"><span class="hidden-mobile">fpga 电梯项目</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="margin-left:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i> <span>目录</span></p><div class="toc-body" id="toc-body"></div></div></aside></div></div></div><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div></main><footer><div class="footer-inner"><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div><div class="statistics"><span id="leancloud-site-pv-container" style="display:none">总访问量 <span id="leancloud-site-pv"></span> 次 </span><span id="leancloud-site-uv-container" style="display:none">总访客数 <span id="leancloud-site-uv"></span> 人</span></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",(function(){NProgress.done()}))</script><script src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t,e){var i=Fluid.plugins.typing,n=e.getElementById("subtitle");n&&i&&i(n.getAttribute("data-typed-text"))}(window,document)</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js",(function(){var t=jQuery("#toc");if(0!==t.length&&window.tocbot){var i=jQuery("#board-ctn").offset().top;window.tocbot.init(Object.assign({tocSelector:"#toc-body",contentSelector:".markdown-body",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",scrollSmooth:!0,includeTitleTags:!0,headingsOffset:-i},CONFIG.toc)),t.find(".toc-list-item").length>0&&t.css("visibility","visible"),Fluid.events.registerRefreshCallback((function(){if("tocbot"in window){tocbot.refresh();var t=jQuery("#toc");if(0===t.length||!tocbot)return;t.find(".toc-list-item").length>0&&t.css("visibility","visible")}}))}}))</script><script src="https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js"></script><script>Fluid.plugins.codeWidget()</script><script>Fluid.utils.createScript("https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js",(function(){window.anchors.options={placement:CONFIG.anchorjs.placement,visible:CONFIG.anchorjs.visible},CONFIG.anchorjs.icon&&(window.anchors.options.icon=CONFIG.anchorjs.icon);var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(window.anchors.options.class="anchorjs-link-left"),window.anchors.add(o.join(", ")),Fluid.events.registerRefreshCallback((function(){if("anchors"in window){anchors.removeAll();var n=(CONFIG.anchorjs.element||"h1,h2,h3,h4,h5,h6").split(","),o=[];for(var s of n)o.push(".markdown-body > "+s.trim());"left"===CONFIG.anchorjs.placement&&(anchors.options.class="anchorjs-link-left"),anchors.add(o.join(", "))}}))}))</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",(function(){Fluid.plugins.fancyBox()}))</script><script>Fluid.plugins.imageCaption()</script><script defer src="/js/leancloud.js"></script><script src="/js/local-search.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript><script type="text/x-mathjax-config">MathJax.Hub.Config({ tex2jax: { inlineMath: [ ["$","$"], ["\\(","\\)"] ], skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'], processEscapes: true } }); MathJax.Hub.Queue(function() { var all = MathJax.Hub.getAllJax(); for (var i = 0;
    i
    < all.length; ++i) all[i].SourceElement().parentNode.className +=' has-jax' ; });</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script></body></html>