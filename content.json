{"meta":{"title":"petertan303","subtitle":"welcome？","description":"","author":"peter？","url":"http://blog.wspdwzh.space","root":"/"},"pages":[{"title":"about","date":"2023-01-16T14:00:14.000Z","updated":"2025-10-15T13:29:30.016Z","comments":false,"path":"about/index.html","permalink":"http://blog.wspdwzh.space/about/index.html","excerpt":"","text":"本科阶段就读于信通学院电子信息工程专业，目前就读于光电技术研究所，方向暂定为光学神经网络/光通信方向。"}],"posts":[{"title":"2025年10月15日-日志","slug":"2025年10月15日-日志","date":"2025-10-15T13:42:00.000Z","updated":"2025-10-15T14:13:23.959Z","comments":true,"path":"2025/10/15/2025年10月15日-日志/","permalink":"http://blog.wspdwzh.space/2025/10/15/2025%E5%B9%B410%E6%9C%8815%E6%97%A5-%E6%97%A5%E5%BF%97/","excerpt":"","text":"近半年总结较为重要的事项： 考研初试复试 毕设 半途而废的线上实习 暑期学车 目前学费一年 8000 元，住宿费一年 1200 元，总计 9200 元。每月工资为 2500 元，包含 1500 元的 所内补贴和 1000 元的国家补贴，计划每月饮食及日常支出 控制在 1200 元，剩余 1300 元存下以备不时之需。食堂价格较高，一餐约为 15~20 元，但是 10 月 13 日以后有 8 折优惠，外卖因地处偏远，同样不便宜。尽量还是在食堂就餐。 装机装了一台 pc，能较为流畅完成日常任务和部分游戏，短期内没有购买显卡计划。配置单如下： 板 u 套装：topc 7945hx modt 平台，购于淘宝 散热器：利民 ss135，购于闲鱼 内存：32g 单条金邦巨蟹，6000c32，购于闲鱼 机箱：酷冷魔神x70，8 升小机箱，附带三个无光风扇，购于淘宝 开关：临时使用的开关，购于淘宝 硬盘：铠侠 xg8 1tb，健康度 99%，购于闲鱼 电源：先马白金 xt850，购于京东自营 开销如下： 板 u 套装：2053 元 Cpu 散热器+扣具+tf 7 硅脂：122 元 内存：560 元 机箱：174 元 开关：4 元 硬盘 xg 8：318 元 电源：333 元总计：3564 元 学习部分课程有作业，记得完成。 导师任务代码本身难度很小，因为学长已经把路铺平了。尽快增加多线程并行训练部分，尽快跑通，之后再尝试优化为 pytorch 版本。跑通后向学长汇报，学长看过后向导师展示；积极与导师、学长交流。 短期内计划 [ ] 斯格明子任务 [ ] 代码 [x] 跑通 [ ] 多线程 [ ] 移植 pytorch [ ] 汇报 [ ] 论文 [ ] 英语慕课 [ ] Tensorflow 入门 [ ] 力扣 hot100 学期内计划 学习 golang 纯好奇 需要学习新语言 学习并尝试做力扣 hot100 工作日一天一题 温习基本语法 学习常用算法和思路 娱乐计划 [ ]","categories":[],"tags":[]},{"title":"关于光学神经网络","slug":"关于光学神经网络","date":"2025-10-15T13:41:46.000Z","updated":"2025-10-15T13:41:46.938Z","comments":true,"path":"2025/10/15/关于光学神经网络/","permalink":"http://blog.wspdwzh.space/2025/10/15/%E5%85%B3%E4%BA%8E%E5%85%89%E5%AD%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"","slug":"!DOCTYPE html","date":"2025-10-14T11:51:54.353Z","updated":"2025-03-04T09:53:09.617Z","comments":true,"path":"2025/10/14/!DOCTYPE html/","link":"","permalink":"http://blog.wspdwzh.space/2025/10/14/%EF%80%BC!DOCTYPE%20html%EF%80%BE/","excerpt":"","text":"ComfyUI","categories":[],"tags":[]},{"title":"毕设相关","slug":"毕设相关","date":"2025-05-08T07:27:53.000Z","updated":"2025-05-08T09:48:12.213Z","comments":true,"path":"2025/05/08/毕设相关/","link":"","permalink":"http://blog.wspdwzh.space/2025/05/08/%E6%AF%95%E8%AE%BE%E7%9B%B8%E5%85%B3/","excerpt":"","text":"我的毕业设计基本告一段落了，在此记录一下。 是一个缝合了cnn与transformer的cvae，用于生成超透镜矩阵；用fastapi和bootstrap写了一个很简单的网站用来充当GUI。 虽然是我花了五个多月做的毕设，但仔细看看，客观上还是相当粗糙，远远谈不上完美，甚至可以说是草率。那么，我这么多时间都花在了哪里呢？ 存在的问题问题有很多很多。 其一是准备不足。模型结构的选择上我犹豫了很长时间，最终选了并不是很适合图像任务的cvae。要是准备时我多找几篇参考论文，我就会发现在超透镜逆向设计领域，cvae已经被cINN之类更先进的模型取代了。 其二是一直在试错，尝试各种魔改的模型结构，却没想过到底是不是有用。 其三是最不该犯的一个错误：没有备份程序。连git都没有使用。以往，我会将程序复制几份，或者推送到github上，但是做毕设的时候不知为什么我没有这么做。直接结果是比较成功的一份模型定义被改烂了，之后试图复现但是复现不出来。 其四是基础知识太差劲，尤其是光学。其实神经网络相关的我也没好到哪去，像素洗牌、反卷积等等我是用到了才明白其特性。 结构很简单的一个模型，是cvae，encoder部分用了conformer，并行推理cnn通道和transformer通道，提取到的特征输入一个三层的cnn进行融合，然后输出mu和logvar。decoder就是普普通通的反卷积上采样，魔改试图加上了交叉注意力用来引入条件（替代和z一起输入的方式），不过表现似乎并不好。 模型的输入是相位和参数的双通道矩阵。其实我是想做成8通道的，分别是相位、参数（一个或者两个，挖孔的会有两个）、结构种类（圆柱方柱挖孔之类的）、焦点处电磁响应（三层，三个焦点）、单元结构高度。不过，仿真只有方柱的数据，其他数据的没有仿真；电磁响应感觉我自己算出来不一定准确，没有cst仿真数据；而且一般来说单元结构都是一样高的，所以最后只有双通道的。 最成功的一版模型对细节的还原也很好，不过如上所述，被改烂了，没有复现出来。之后的模型对于细节的还原总感觉不到位。 decoder部分尝试过很多上采样，比如说像素洗牌，但是效果很烂。 decoder我试图使用了交叉注意力来引入条件，但并没有多好，甚至跟拼接的不分上下，可能是前面的就没做好，导致后面一起烂了。 我没敢使用GAN，之前尝试了但是效果不好、容易跑飞，所以就没用。但按理来说对于细节是有帮助的。现在想想感觉有点遗憾，应该试一试的。 我想过使用cst边训练边仿真，一个是用来生产数据，一个是用来验证效果并返回loss，但是算力要求太高。 另外我尝试着做了过程中可视化，把forward中的部分中间变量拿出来做可视化。虽然做出来了但我还是无法理解为什么中间变量是这么变化的。比如说倒数第二层上采样之前，图像下半部分数值高，倒数第一层突然就变均匀了。看到这个结果之后我想会不会是上采样层数太多，有点浪费了？ 损失函数折腾了很多，但是和普普通通mse差别并不是很大；我自己写的一部分损失函数甚至会劣化效果。 试错值得注意的是，我尝试过很多复杂的变种模型结构，但是效果甚至可能不如最基本的卷积+反卷积+拼接。为什么？我不理解。有不少甚至无法准确重建，或者说完全没有重建的意思。 亮点没什么亮点，或者说完全没有亮点。我的方案大概率只是别人挑剩下的方案，虽然我没有找到论文使用完全一样的方案，但一定有更好的，例如上面提到的cINN就是取代cvae的，能规避模式崩塌之类的cvae固有缺陷，客观上一定更好。 按理来说缝合cnn和transformer确实能兼顾全局和局部，但事实上conformer并没有流行开来，对比之下我认为根本不需要cnn来提取局部特征，注意力完全能够胜任兼顾所有特征的任务。 decoder部分用了交叉注意力，但是没有比FiLM的好多少，甚至不比拼接的好很多。 另外我不知道为什么在图书馆会头晕？一开始我以为是主观上昏昏欲睡，一个月之后我才确定确实会有头晕的症状。我猜测可能是屏幕太小了，长时间盯着看？或许我应该试着换一个地方？ 前几天回家用了显示屏，没有出现头晕的情况。","categories":[],"tags":[]},{"title":"qt 小程序 开发进展","slug":"qt-小程序-开发进展","date":"2025-03-03T05:45:30.000Z","updated":"2025-03-04T03:58:27.378Z","comments":true,"path":"2025/03/03/qt-小程序-开发进展/","link":"","permalink":"http://blog.wspdwzh.space/2025/03/03/qt-%E5%B0%8F%E7%A8%8B%E5%BA%8F-%E5%BC%80%E5%8F%91%E8%BF%9B%E5%B1%95/","excerpt":"","text":"目前的程序虽然实现了功能，但是相当混乱，感觉是因为代码没有按照规范编写，而且大量使用低级低效的语法。 梳理一下程序的逻辑初始化 初始化 ui 包括布局，文本框，菜单栏 加载历史 prompt 实例化 QNetworkAccessManager 等变量 读取本地保存的 api 相关数据 设定状态变量初始值 启动绘图进程需要有状态变量记录当前状态 是 sd 还是 comfyUI 还是别的什么 如果是 sd（一次 post 请求完成绘图） 连接 发送请求 和 按下按钮 连接 QNetworkAccessManager::finished（响应事件）和 显示图片 过程： 按下按钮 发送请求 方法 收到响应 处理响应 方法 显示图片 方法 这个过程中，用到了三个方法： 发送请求 输入： 需要发送的 prompt 文本 标题 处理响应 输入： 图片信息（prompt， 标题，之类的） json 响应 解码 json 响应 从 json 中提取图片数据 转化为二进制流的形式发送给显示图片的方法 显示图片 输入： 图片 设置控件 绘制图片 打开图片窗口 如果是 comfyUI（多步流程） 连接 发送请求 和 按下按钮 连接 http 网络响应 和 处理网络响应的方法 连接 websocket 网络响应 和 处理网络请求的方法 过程： 按下按钮 发送提交任务 http 请求 方法 websocket 收到特定响应 发送获取文件名 http 请求 方法 收到响应 文件名 发送获取图片 http 请求 方法 收到响应 图片数据 显示图片 方法 使用到的方法： 发送 http 请求 提交任务 获取文件名 获取图片 处理 websocket 响应 如果是结束信号 那么执行 发送 获取文件名 的 http 请求的方法 显示图片 comfyUI 功能会使用的变量 QNetworkAccessManager m_httpNetworkManager 统一的 http 请求管理器 发送 http 请求的时候使用 QWebSocket m_webSocket comfyUI 必不可少 切换到 comfyUI 模式的时候建立链接 如果断开，则试图重新连接 如果连接成功，提示连接成功 如果收到消息，判断是否是完成信号 如果是，调用方法发送 http 请求，进行后续步骤 QQueue promptId 队列 用来存储 prompt_id 存在先后顺序，所以使用队列保存 qt 有现成的队列类 QQueue QJsonObject imageInfo 保存收到的图片相关数据 包含文件名、路径等信息 ConnectionMode m_connectionMode ConnectionMode 是一个枚举类 用来记录当前的状态 为什么不直接用字符串是因为我担心打错字 想要增加 操作 UI 的方法 目前都是直接 ui-&gt;xxx-&gt;settext 之类的 业务逻辑与界面强耦合 存在的问题模式目前的话，是依靠一个 currentMode 变量识别现有的模式，问题在于发送请求接收到的时候不一定就是这个模式了。这种情况下，如果发送-接收请求中途变更了模式，那么就会出现问题。 “无状态” 这个术语可以形容 http 请求和响应没有内置关联机制。 大致想了一下关于这个问题的解决方法： 有未完成的请求时，禁止变更模式 最简单，比较有效，但是不是很灵活 如果有请求因为错误没有完成，那么永远无法切换模式 这种情况考虑添加一个手动清除请求等待队列的按钮 通过响应本身判断是哪一种模式 很复杂 修改起来很麻烦 可能存在有模式的响应无法和其他的区别开 通过时间顺序判断 否决，不一定是时间顺序一一对应 使用 QNetworkAccessManager 每个请求返回唯一的 QNetworkReply 对象 通过信号槽机制绑定响应处理 支持自定义数据附加到请求/响应对象 可以使用 connect 将不同 QNetWorkReply 对象的 &amp;QNetworkReply::finished 信号绑定到不同的方法 也可以设置自定义的 设置界面种子 和 client id 是该随机生成还是自定义？ 目前的想法是提供一个可选的选项，选择是自定义固定种子还是随机生成。client id 同理。 这需要一个单独的设置界面，设置界面应当包括： 种子 设置随机/固定 设置为固定时需要有一个文本输入框 输入框在设置为随机时应当是 deactivte 的 client id 设置随机/固定 同理 seed 对于 comfyUI 和 sd 都适用， sd 没有 client id。 问题在于要不要把 comfyui 的 seed 和 sd 的 seed 分开来设置。","categories":[],"tags":[]},{"title":"comfyUI api 相关","slug":"comfyUI-api-相关","date":"2025-03-02T05:46:15.000Z","updated":"2025-03-03T11:53:18.876Z","comments":true,"path":"2025/03/02/comfyUI-api-相关/","link":"","permalink":"http://blog.wspdwzh.space/2025/03/02/comfyUI-api-%E7%9B%B8%E5%85%B3/","excerpt":"","text":"现在，我有一个 comfyui 服务器，有了想要画的prompt，我应该怎么用起来？ 如果是 stable diffusion，直接 post /prompt 即可，回传的直接就是包含了图片链接。如果是图生图，POST /sdapi/v1/img2img 传递图片和文本 prompt，返回也是包含了图片链接。拿到链接之后，只需要 GET，就可以拿到图片。 stable diffusion 的生成能在两次请求之内完成，很有效也很简单，但当然 comfyUI 多出来的功能也有自己的作用。例如多用户管理，服务器信息监测，不过主要还是由于 comfyUI 等待队列。 （当然我很希望comfyUI能够保留一个像sd这样简单的接口，能配置的不过但能用，不过似乎没有） comfyUI api 绘图 大体流程以一个最简的文生图流程为例： 第一步 连接 websocket连接 /ws 需要传递参数 client_id 响应： 如果安装了一些插件（例如 服务器状态监控），则会有定时的响应。 如果本机（连接时和提交请求时的 client id 一致）画图完成，则会响应，但是不会返回图片，而是返回状态信息和 prompt_id。 第二步 提交任务post /prompt 需要包含 client_id 和 prompt，注意这个prompt不是文本prompt，而是json表示的工作流。 响应： 12345&#123; &quot;prompt_id&quot;: &quot;ee2b584d-175b-4d62-88ce-d6ae4aa4499e&quot;, &quot;number&quot;: 1, &quot;node_errors&quot;: &#123;&#125;&#125; prompt_id：一个任务的唯一 id number：任务序号，从 1 开始 node_errors：是否有错误，具体是哪个节点出错了 第三步 请求文件名GET /history/{prompt_id} 总而言是获得了 prompt_id。请求 /history/{prompt_id}，就会得到 prompt（节点内容），status，outputs 等，其中 outputs 是各个节点的输出，大致如下： 12345678910&quot;outputs&quot;: &#123; &quot;9&quot;: &#123; &quot;images&quot;: [ &#123; &quot;filename&quot;: &quot;ComfyUI_00065_.png&quot;, &quot;subfolder&quot;: &quot;&quot;, &quot;type&quot;: &quot;output&quot; &#125; ]&#125; 意思就是 9 节点的 图片 输出包含了图片，图片名为 filename 变量，type 和 subfolder 也比较重要。 如果是一个简单的文生图直出工作流，那确实只有一个输出；但是如果是较为复杂的（分步的，而且有多步都接 output 节点），那就需要明白哪一个输出是需要的。 第四步 获取图片GET /view 参数： filename type subfolder 也就是上一步获取到的输出。 响应： 直接响应图片。 总结文生图必须使用的 api 大致如上。也就是： websocket 连接，为的是获取完成信号和 prompt_id 提交 prompt，即 post /prompt，获取prompt_id 等待生成完成 收到生成完成信号 通过 prompt_id 请求文件名 获取文件 除此之外，comfyUI 还有很多用于管理、监控的 api，例如取消任务，获取本机存在的可用节点。 comfyUI api 概览GET /history响应格式是： graph TD; {prompt_id} --> prompt; {prompt_id} --> outputs; {prompt_id} --> status; GET /history/{prompt_id}GET /object_infoGET embeddingsGET /extensionsGET /viewGET /promptPOST /promptGET /queuePOST /queuePOST /upload/imagePOST /upload/maskPOST /interrupt","categories":[],"tags":[]},{"title":"2025年2月2日-qt程序","slug":"2025年2月2日-qt程序","date":"2025-02-02T13:00:45.000Z","updated":"2025-02-03T05:37:43.807Z","comments":true,"path":"2025/02/02/2025年2月2日-qt程序/","link":"","permalink":"http://blog.wspdwzh.space/2025/02/02/2025%E5%B9%B42%E6%9C%882%E6%97%A5-qt%E7%A8%8B%E5%BA%8F/","excerpt":"","text":"做了什么试着添加了websocket适配，现在可以切换http和websocket。 优化了图片查看器。 感想comfyui的api和我理解的不一样，我以为是有两套，一套http，一套websocket，实际上只有一套。传递大部分信息都是http，实时获取队列状态（以及一些插件，例如服务器状态实时监控）是走websocket。看了一圈，没有一个api是纯走websocket的（也没有必要都走websocket…）。 comfyui的api需要自定义工作流所有东西，这点有点麻烦。我希望的是有一个简洁明了的、效果足够好的、直接返回图片的接口。可配置项都用默认配置。 CheckpointLoaderSimple节点的模型需要自定义，万一服务器没有某个模型的话，有点难办，因为模型的效果我不知道。命名也可能不标准。 之后的工作1、comfyui api 适配现在的想法是提供一个简单但是有效的默认配置文件，单独拎出来，不要和其他api的放在一起。其中可以有一个简单的工作流，连接已经固定，只能修改其中参数。节点： 一个lora节点 一个遮罩节点 两个文本节点，即prompt 和 negative prompt 模型节点 尺寸，批次大小，即EmptyLatentImage 采样器节点，KSampler，可以配置采样器种类、种子、步数 一个上传图片、图生图的节点 其他不可配置的节点 应当通过一个单独的窗口提供可配置选项： lora名称选择 遮罩 是否有遮罩 遮罩图片上传 文本通过共用的TextEdit进行设置 模型选择 尺寸，批次大小 采样器种类、种子、步数 种子应当可以设置为随机 步数应当是一个滑动条 应当可以配置是文生图还是图生图 或者直接根据是否有参考图判断是文生图还是图生图 2、请求历史应当有一个请求历史记录列表，数据存放在output文件夹的文件中。 应当可以通过一个独立的窗口查看请求历史，并打开对应的图片、查看对应的prompt。 问题在于要如何保证请求和output文件夹中文件的一一对应。假设存储历史请求的文件不会被修改，但是可能被删除，且output中的文件可能被修改。 初步想法是通过json保存请求数据及prompt、文件名，若文件不存在则不显示且提示文件已被移除，若存在则打开。 也可以以请求为一条记录，放在数据库中。 3、图片窗口改进目前已经实现： 拖拽 滚动移动 ctrl+滚动：缩放，且以鼠标为中心 ctrl+0：查看全图 ctrl+1：恢复默认大小 右键菜单：复制、打开路径、另存为 需要实现： 空格：关闭窗口 将以往的图片窗口合并，便于在程序中查看，而不是需要转到文件资源管理器里看。 例如，左边一个侧栏，显示缩略图，page up和page down移动选择，选中的图片将会在右边的label中显示。 可能的问题：内存占用过大 可能的解决方法：程序只加载缩略图和部分图片，切换图片时从硬盘实时读取 需要在内存中保存图片名称和缩略图 图片有一个生存期，一定时间后会释放该图片所占用内存。 有一个最大内存占用，占用过大的时候会按时间倒序释放内存。 这两项可以被配置 切换到一张图片的时候，将会直接放大缩略图，显示在label中。从本地读取完成之后用读到的高清图覆盖，否则提示文件不存在。 可能的问题：卡顿 因为和硬盘交互再写入内存慢于直接从内存加载 而且缩略图制作需要时间 为此，可能需要多线程 但是多线程会占用更多资源 或许可以将其和历史记录查看器合并 分为：本次画图 和 此前的画图 在内存中载入： 缩略图 图片名称 prompt 在本地保存： 图片名称 prompt “此前的画图” 启动时加载： 本地文件 对应的图片，用于计算得到缩略图，计算完成后释放 可能占用很多资源 “本次画图” 启动时不加载任何东西，在收到响应的时候才加载缩略图，并自动保存请求到本地 4、本地数据使用数据库管理大部分数据库，包括sqlite，可以保存blob数据，也就是说可以保存图片及其缩略图。且不会像文件一样被轻易修改。 这意味着可以把图片和文本数据（例如请求时间，prompt）统一管理。 程序中需要有批量导出、删除图片数据的功能。 但是配置文件应当是一个可以方便地修改的文件。 计划 先实现comfyui api适配 数据统一使用数据库保存 增加历史请求查看功能","categories":[],"tags":[]},{"title":"2025年1月9日-qt程序添加功能","slug":"2025年1月9日-qt程序添加功能","date":"2025-01-09T11:58:19.000Z","updated":"2025-01-09T15:12:50.271Z","comments":true,"path":"2025/01/09/2025年1月9日-qt程序添加功能/","link":"","permalink":"http://blog.wspdwzh.space/2025/01/09/2025%E5%B9%B41%E6%9C%889%E6%97%A5-qt%E7%A8%8B%E5%BA%8F%E6%B7%BB%E5%8A%A0%E5%8A%9F%E8%83%BD/","excerpt":"","text":"反思我的这个程序只支持文生图。 正在想要不要添加图生图和反求prompt功能。这样可以发挥webui、comfyui的更多能力。这不会让程序太臃肿。目前的程序并不大。且计算并不是程序本身完成，程序只是调api的。 另外，现在是用json直接存储各种信息。因为json可以直接使用记事本修改，很方便，且用到的数据不会很多，数据之间的关系并不复杂。在想要不要转到使用数据库，例如sqlite。sqlite比文本文档存数据更安全，因为可以使用QSqlCipher加密；按理来说也更高效，因为自带了优化。 今日计划增加api适配画图请求 原api webui api webui api和原本的api很类似，只是增加了很多很多可配置项。 另外，可以批量生图，回传的图片将是数组而不是单张图 comfyui api 较为复杂，自带了任务队列和节点机制 程序不可能发挥出节点的全部能力 需要使用websocket api 管理不同api接受prompt的方式不同。例如，原本的api、webui的api直接接受prompt和negative prompt，而comfyui的api则是接受节点信息。显然，这样可调控的更多，但是我的程序过于简单，无法发挥comfyui的能力。 队列管理例如，comfyui自带任务队列，不会直接返回图片，而是返回任务id。目前的api是直接返回图片。因此，代码逻辑需要修改。需要使用websocket而不是目前的纯http。 方案先暂时舍弃comfyui的多功能，将输入的prompt输入默认文生图工作流。日后再增加新功能。","categories":[],"tags":[]},{"title":"2024年12月29日-qt学习","slug":"2024年12月29日-qt学习","date":"2024-12-29T08:40:13.000Z","updated":"2024-12-30T09:11:55.660Z","comments":true,"path":"2024/12/29/2024年12月29日-qt学习/","link":"","permalink":"http://blog.wspdwzh.space/2024/12/29/2024%E5%B9%B412%E6%9C%8829%E6%97%A5-qt%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"使用qtcreator写了一个简单的qt程序。记录一下。 程序整体的结构在我的程序中，一个窗口，对应一个类，对应一个命名空间，继承QWidget或者QMainWindow类。类中有信号（signals）和槽（slots），按照我的理解：槽是实际执行任务的方法，信号是能跨窗口触发槽的方法。 我的程序主要有mainWindow和starPromptWindow两个窗口，在mainwindow类中实例化了一个m_starPromptWindow，用于触发信号从而使用槽。 信号和槽例如，如果我要点击starPromptWindow的一个按钮，要改变mainWindow的一个控件内容，那我应该在starPromptWindow中定义一个信号，还要有一个触发信号的方法，在mainWindow中应该有一个目标方法来改变控件内容。我应当在mainWindow中连接这个信号和目标方法，因为我在mainWindow中实例化了一个starPromptWindow对象m_starPromptWindow。 总之就是： starPromptWindow： 按钮 信号 发出信号的方法 与按钮连接 mainWindow： 实例化一个starPromptWindow 连接信号与目标方法 目标方法（槽） 操作mainWindow中的控件 如果我反过来，要点击mainWindow中的按钮，控制starPromptWindow中的控件，那我同样应该使用信号。但是不能像这样直接调换地位： starPromptWindow： 实例化一个mainWindow 连接信号与目标方法 目标方法（槽） 操作starPromptWindow中的控件 mainWindow： 按钮 信号 发出信号的方法 与按钮连接 这是错误的（大概）。按理来说应该这么做： starPromptWindow： 信号 发出信号的方法 与mainWindow中的按钮连接 连接在mainWindow中设置 一个private槽 用于控制starPromptWindow中的控件 mainWindow： 实例化一个starPromptWindow 按钮 连接按钮与starPromptWindow的信号 不过事实上也可以不通过信号，直接使用starPromptWindow中的public槽： starPromptWindow： 一个public槽 用于控制starPromptWindow中的控件 mainWindow： 实例化一个starPromptWindow 连接到starPromptWindow的public槽 总而言之，通过信号和槽，就能间接地通过一个窗口的方法和另一个窗口的控件交互了。 窗口头文件以mainWindow为例：123456789101112131415161718192021222324252627282930313233#ifndef MAINWINDOW_H#define MAINWINDOW_H#include &quot;starPromptWindow.h&quot;#include &lt;QMainWindow&gt;namespace Ui &#123;class MainWindow;&#125;class MainWindow : public QMainWindow&#123; Q_OBJECTsignals: // ...... public slots: // ......private slots: // ......public: // ......private: Ui::MainWindow *ui; starPromptWindow *m_starPromptWindow; // StarPromptWindow 的实例 // ......&#125;;#endif按照qt（或者说是qtcreator）标准写法写的类定义，声明成员。 cpp程序以mainWindow为例：123456789101112131415161718#include &quot;mainwindow.h&quot;#include &quot;ui_mainwindow.h&quot;#include &quot;starPromptWindow.h&quot;MainWindow::MainWindow(QWidget *parent): QMainWindow(parent), ui(new Ui::MainWindow), m_starPromptWindow(new starPromptWindow(this))&#123; ui-&gt;setupUi(this); // ......&#125;MainWindow::~MainWindow()&#123; delete ui; delete m_starPromptWindow;&#125;实现功能的部分。 其中，~MainWindow()函数是退出窗口时执行的动作，这个方法在类定义的时候声明了。 不过事实上，要更改窗口关闭时的行为，我是重写了closeEvent。例如，我不希望starPromptWindow退出的时候彻底退出，我希望只是隐藏，同时保存prompt，于是我重写了closeEvent：12345void starPromptWindow::closeEvent(QCloseEvent *event) &#123; this-&gt;hide(); saveStarPrompt(); event-&gt;ignore(); // 忽略关闭事件，防止窗口被销毁&#125;对应的，要在头文件类定义中说明你重写了这个方法：12protected: void closeEvent(QCloseEvent *event) override; 主要功能：绘图：通过发送请求完成。请求的内容存储在ApiData.json中。 图片预览 通过生成并打开一个QDialog类型的、继承了mainWindow的imageDialog实现。在其中插入一个QLabel类型的imageLabel变量，通过setPixmap(QPixmap::fromImage(scaledImage))设置内容，然后layout-&gt;addWidget(imageLabel)将其插入QVBoxLayout型的layout，最后通过imageDialog-&gt;setLayout(layout)设置layout。 值得注意的是，QDialog有一个性质名为模态，model，需要通过imageDialog-&gt;setModal(false)设置为flase，否则只能聚焦在最后一个打开的QDialog上。 值得注意的是，如果不执行imageDialog-&gt;setAttribute(Qt::WA_DeleteOnClose)，imageDialog占用的内存不会释放，导致占用节节高。 图片和参数保存 图片有现成的类型QImage，QImage有现成的方法save()；文件有QFile，可以通过文本流QTextStream写入： （QFile变量名为jsonFile）12345if (jsonFile.open(QIODevice::WriteOnly)) &#123; QTextStream out(&amp;jsonFile); out &lt;&lt; QJsonDocument(jsonObj).toJson(); jsonFile.close();&#125; “上一次输入的prompt”将被自动记录，并在下一次启动时填写 同上读写json文件。 没有使用数据库是因为不方便直接编辑。 收藏prompt，查看与管理收藏的prompt 使用了starPromptWindow窗口完成。读写文件同上。和主窗口的交互详见信号量部分。 次要功能: 网络错误时会弹出提示框 使用了我自己写的专门的类ErrorDialog（继承了QDialog）。qt有专门的错误提示框QErrorMessage，用起来很方便，不过我不太喜欢ui布局所以自己写了。 clear按钮可以快速清屏右边的日志 直接将按钮连接到ui-&gt;outputTextEdit-&gt;clear函数 alt + s 是绘制的快捷键 先创建快捷方式，然后连接。就像这样12QShortcut *shortcutDraw = new QShortcut(QKeySequence(Qt::ALT | Qt::Key_S), this);connect(shortcutDraw, &amp;QShortcut::activated, ui-&gt;sendRequestButton, &amp;QPushButton::click); ctrl + s 是保存tag的快捷键（如果不手动保存的话，画完一张图后也会自动保存） 同理12QShortcut *shortcutSaveHistory = new QShortcut(QKeySequence(Qt::CTRL | Qt::Key_S), this);connect(ui-&gt;ClearButton, &amp;QPushButton::clicked, this, &amp;MainWindow::onClearButtonClicked); 响应式布局 最麻烦的一集 使用qtcreator的可视化编辑器折腾了好半天，继承QWidget的情况下，怎么都会挤成一坨。后来改成了继承MainWindow类才好。 starPromptWindow的初始化函数如下：123456789101112131415161718192021void starPromptWindow::initStarPrompts()&#123; this-&gt;setWindowTitle(&quot;Star Prompts&quot;); this-&gt;resize(600, 600); QJsonObject json = readStarPrompts(); tabWidget = new QTabWidget(this); QVBoxLayout *mainLayout = new QVBoxLayout(this); mainLayout-&gt;addWidget(tabWidget); // 遍历 JSON 对象，为每个键创建 Tab 页面 for (QString key : json.keys()) &#123; QJsonObject item = json[key].toObject(); addTabForStarPrompts(item[&quot;prompt&quot;].toString(), item[&quot;negativePrompt&quot;].toString(), key, tabWidget); &#125; // 会挤成一团 // setLayout(mainLayout); // 会挤成一团 // this-&gt;setLayout(mainLayout); ui-&gt;layoutWidget-&gt;setLayout(mainLayout); this-&gt;setAttribute(Qt::WA_DeleteOnClose);&#125;注意这里layout用的是QVBoxLayout，是具体的垂直布局，即使只有一个子控件，而不是基类QLayout（QLayout似乎并不能直接拿来用）。 setLayout(mainLayout) 和 this-&gt;setLayout(mainLayout) 都会使得控件挤成一团。不理解为什么 main函数首先实例化一个QApplication，然后实例化主窗口。 starPromptWindow不需要在这里实例化因为在mainWindow中实例化了。\"mainwindow.h\"1234567891011#include &quot;starPromptWindow.h&quot;#include &lt;QApplication&gt;int main(int argc, char *argv[])&#123; QApplication a(argc, argv); MainWindow w; w.setWindowIcon(QIcon(&quot;./icon.ico&quot;)); w.show(); return a.exec();&#125; 总结写完之后一看，大体的思路还挺清晰的。也可能是因为我的程序比较小，规模大了也可能会比较混沌也说不定 qt说难不难，感觉就像在接线，要弄清楚插头是哪个，插座是哪个，要怎么接起来。窗口之间交互依赖信号和槽，在谁里实例化谁要搞明白。之前写过pyqt，最大区别大概是connect用法不同？qt是把A的动作A1和某窗口（一般是this）的目标方法连接，pyqt是A的成员A1的方法connect直接连接目标方法。何况cpp大量使用指针，导致读的时候需要留个心眼看是直接传递的值还是传递了指针。 总而言之，功能强大，可配置的多，但是如果我不需要配置这么多的时候就显得麻烦了。极端的例子如Gradio，我想要快速创建一个能用的应用时用Gradio只需要十几行甚至几行，还提供了丰富的模板可以用，而qt大概需要哼哧哼哧写个上百行。","categories":[],"tags":[]},{"title":"Glow-TTS阅读","slug":"Glow-TTS阅读","date":"2024-10-16T13:16:18.000Z","updated":"2024-10-16T14:16:19.481Z","comments":true,"path":"2024/10/16/Glow-TTS阅读/","link":"","permalink":"http://blog.wspdwzh.space/2024/10/16/Glow-TTS%E9%98%85%E8%AF%BB/","excerpt":"","text":"Glow-TTS，前置科技点是 tacotron2，tacotron2 的前置科技点是 Waveglow。waveglow 是完全基于流模型的，可以认为tacotron2和glow-tts都是基于它改进而来。 tacotron2 利用 waveglow 实现了更好的效果，但是没有并行，也没有单调对齐（需要手动来对齐，或者需要一个自回归TTS模型作为外部对齐器，例如 FastSpeech）。glow-tts做的就是这部分工作，引入了单调对齐搜索（Monotonic Alignment Search，MAS），MAS搜索文本和语音的潜在表示之间最可能的单调对齐关系。 效果就是更快了，快了很多；而且还能多说话人。 tacotron2 和 waveglow 都是英伟达家的。pytorch 提供了范例，快速使用 tacotron2。链接","categories":[],"tags":[]},{"title":"每天一点小知识","slug":"每天一点小知识","date":"2024-10-08T13:47:16.000Z","updated":"2024-10-09T05:52:09.349Z","comments":true,"path":"2024/10/08/每天一点小知识/","link":"","permalink":"http://blog.wspdwzh.space/2024/10/08/%E6%AF%8F%E5%A4%A9%E4%B8%80%E7%82%B9%E5%B0%8F%E7%9F%A5%E8%AF%86/","excerpt":"","text":"骷髅王.jpg 查看Windows命令对应的可执行文件路径 where（cmd） Get-Command（对于powershell而言） which（类unix shell，例如git bash） reg（直接查询注册表） 查文件拓展名关联程序 assoc ftype 如何将linux命令打印的文本整体右移？通过管道符和某些命令来处理输出的文本...... 使用sed 1echo &quot;wspdwzh&quot; | sed &#x27;s/^/ /&#x27; 2.使用awk 1echo &quot;wspdwzh&quot; | awk &#x27;&#123;print &quot; &quot; $0&#125;&#x27; 3.使用bash语法 1echo &quot;wspdwzh&quot; | while IFS= read -r line; do printf &quot;%10s\\n&quot; &quot;$line&quot;; done 4.使用column 1echo &quot;wspdwzh&quot; | column -t -s $&#x27;\\t&#x27; -o &quot; &quot; 5.使用cut 这个和我想象中不太一样，是限制每行输出的字符范围。比如说，如果我要第3个字符： 1echo &quot;wspdwzh&quot; | cut -c 3 看了一圈，最好用的还是awk。虽然这只是它庞大功能中的一个邪门用法。 awk用法 MOTD: message of the day即linux启动时显示的那一大堆东西。一般来说每天显示一次，如果要关掉这个消息，可以创建/home/{你的用户名}/.hushlogin这么一个隐藏文件。空文件即可。 一般来说，显示的是 /etc/motd 这个文件或者 /usr/share/base-files/motd。可以通过特殊的语法更改输出的内容。但这个文件只能显示静态内容，因此有一些 .sh 文件来显示动态内容。 似乎可以通过 /usr/bin/landscape-sysinfo 和 run-parts /etc/update-motd.d 显示特定的系统信息。 wsl小知识登录时加载的是 .bash_profile 而不是 .bashrc。但是你可以将“source ${HOME}/.bashrc” 加到 .bash_profile。 vscode 是 code 而不是 vscode。 可以直接打开GUI程序。例如rhythmbox。 wsl默认没法使用Windows声卡，但是可以安装PulseAudio来使用Windows声卡。可以使用apt安装。配置文件在/etc/pulse。","categories":[],"tags":[]},{"title":"nga机器人后续计划","slug":"nga机器人后续计划","date":"2024-08-24T14:27:08.000Z","updated":"2024-10-04T02:55:58.726Z","comments":true,"path":"2024/08/24/nga机器人后续计划/","link":"","permalink":"http://blog.wspdwzh.space/2024/08/24/nga%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%90%8E%E7%BB%AD%E8%AE%A1%E5%88%92/","excerpt":"","text":"目前基本稳定运行了，后续计划： 后台运行字面意思地挂在后台运行。 图形界面黑框框毕竟还是不好看，操作也不方便，更不直观。 语言用的是python。我是比较熟悉Tkinter、pyqt之类图形库的，这俩用起来也能比较简单地得到想要的效果。 如果移植到C++，会比较费事情（毕竟现成的代码用不了，两个语言的特性还是有差别）；何况我不会c++。 插件化？或许可以做成现成框架的某个插件，好处是省下了搓GUI之类的问题，有了图形界面；可以稳定运行，也可以随时更新。 （只是想想而已） #","categories":[],"tags":[]},{"title":"nga机器人重写","slug":"nga机器人重写","date":"2024-07-13T09:26:01.000Z","updated":"2024-07-13T09:39:02.563Z","comments":true,"path":"2024/07/13/nga机器人重写/","link":"","permalink":"http://blog.wspdwzh.space/2024/07/13/nga%E6%9C%BA%E5%99%A8%E4%BA%BA%E9%87%8D%E5%86%99/","excerpt":"","text":"大体思路使用一个 Poster 对象处理数据、请求等问题。 Potser 类中，需要创建两个 session（来自于 request库），用于管理 cookie。两个 session 分别是和 nga 的、和 bilibili 的（数据源）。最大好处是 header、cookie等重复信息不需要重复了，可以通过 session 自动管理。 站点、cookie、api key之类的可以放在环境变量中，也可以放在文件中。差别不大。 处理逻辑部分应该是可以沿用之前的，不需要更改，只是把发送请求的方式修改一下。","categories":[],"tags":[]},{"title":"qwen2微调与使用过程","slug":"qwen2微调与使用过程","date":"2024-07-06T02:44:59.000Z","updated":"2024-10-08T14:11:51.592Z","comments":true,"path":"2024/07/06/qwen2微调与使用过程/","link":"","permalink":"http://blog.wspdwzh.space/2024/07/06/qwen2%E5%BE%AE%E8%B0%83%E4%B8%8E%E4%BD%BF%E7%94%A8%E8%BF%87%E7%A8%8B/","excerpt":"","text":"lora微调参考 文章 进行微调，得到 .pt 和 .pth 等文件（checkpoint）。 部分代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# Transformers加载模型权重tokenizer = AutoTokenizer.from_pretrained(&quot;./qwen/Qwen2-0___5B-Instruct/&quot;, use_fast=False, trust_remote_code=True)model = AutoModelForCausalLM.from_pretrained(&quot;./qwen/Qwen2-0___5B-Instruct/&quot;, device_map=&#123;&quot;&quot;: 0&#125;, torch_dtype=torch.bfloat16, max_memory=&#123;0: &quot;4GB&quot;&#125;)model.enable_input_require_grads() # 开启梯度检查点时，要执行该方法train_dataset_path = &quot;Muice-Dataset/train.jsonl&quot;# 得到训练集train_df = pd.read_json(train_dataset_path, lines=True)train_ds = Dataset.from_pandas(train_df)train_dataset = train_ds.map(process_func, remove_columns=train_ds.column_names)config = LoraConfig( # ...)model = get_peft_model(model, config)args = TrainingArguments( # ...)swanlab_callback = SwanLabCallback( # ... config=&#123; &quot;model&quot;: &quot;qwen/Qwen2_05B_Instruct&quot;, &quot;dataset&quot;: &quot;huangjintao/Muice-Dataset&quot;, &#125;)trainer = Trainer( model=model, args=args, train_dataset=train_dataset, data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True), callbacks=[swanlab_callback],)trainer.train()trainer.save_model(&quot;./trained&quot;) # 这将保存模型权重到指定目录tokenizer.save_pretrained(&quot;./trained&quot;) # 确保和模型权重保存在同一目录model.config.save_pretrained(&quot;./trained&quot;)swanlab.finish() 首先加载 tokenizer，model，然后设置trainer想要的部分参数（如 config，TrainingArguments），使用 train 方法开始训练，训练结束后保存模型 和 tokenizer。 与底模合并参考 文章，使用其中的 merge.py 合并，得到safetensor及其附属文件。 部分代码如下 1234567891011base = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.bfloat16)base_tokenizer = AutoTokenizer.from_pretrained(model_path)lora_model = PeftModel.from_pretrained( base, lora_path, torch_dtype=torch.float16, config=config)model = lora_model.merge_and_unload()model.save_pretrained(output_path)base_tokenizer.save_pretrained(output_path) 首先，加载底模 和 训练得到的对应lora（checkpoint文件），然后使用 merge_and_unload 方法 进行合并。 合并得到的是 safetensor 文件。 合并为.bin文件使用 llama.cpp 中的 convert-legacy-llama.py 进行合并。 1python ./examples/convert-legacy-llama.py G:\\Git\\qwen-tmp-1\\merged\\merged-2 --outtype f16 --outfile G:\\Git\\qwen-tmp-1\\merged\\merged-2.bin --vocab-type bpe --pad-vocab 注意最后的两个参数：—vocab-type bpe 和 —pad-vocab。 如果不添加前者，可能会出现： 1FileNotFoundError: Could not find a tokenizer matching any of [&#x27;spm&#x27;, &#x27;hfft&#x27;] 如果不添加后者，可能会出现尺寸不符：1ValueError: Vocab size mismatch (model has 151936, but G:\\Git\\qwen-tmp-1\\merged\\merged-2\\vocab.json has 151646). Add the --pad-vocab option and try again. 但是对于 qwen 来说需要使用 convert-hf-to-gguf.py 而不是 convert-legacy-llama.py。 1python ./convert-hf-to-gguf.py G:\\Git\\qwen-tmp-1\\merged\\merged-3 --outtype f16 --outfile G:\\Git\\qwen-tmp-1\\merged\\merged-3-3.bin 这个时候，就不需要后面的参数了。 后续部分照常。 .bin 文件量化依然是使用 llama.cpp。 1./bin/llama-quantize.exe G:\\Git\\qwen-tmp-1\\merged\\merged-2.bin q5_k_m 有多种量化方式可以选择。量化后，得到 .gguf 文件。当然，也可以使用 COPY， 不进行量化，只是单纯的拷贝到 gguf 文件。 1234567891011121314151617181920212223242526272829303132333435Allowed quantization types: 2 or Q4_0 : 4.34G, +0.4685 ppl @ Llama-3-8B 3 or Q4_1 : 4.78G, +0.4511 ppl @ Llama-3-8B 8 or Q5_0 : 5.21G, +0.1316 ppl @ Llama-3-8B 9 or Q5_1 : 5.65G, +0.1062 ppl @ Llama-3-8B 19 or IQ2_XXS : 2.06 bpw quantization 20 or IQ2_XS : 2.31 bpw quantization 28 or IQ2_S : 2.5 bpw quantization 29 or IQ2_M : 2.7 bpw quantization 24 or IQ1_S : 1.56 bpw quantization 31 or IQ1_M : 1.75 bpw quantization 10 or Q2_K : 2.96G, +3.5199 ppl @ Llama-3-8B 21 or Q2_K_S : 2.96G, +3.1836 ppl @ Llama-3-8B 23 or IQ3_XXS : 3.06 bpw quantization 26 or IQ3_S : 3.44 bpw quantization 27 or IQ3_M : 3.66 bpw quantization mix 12 or Q3_K : alias for Q3_K_M 22 or IQ3_XS : 3.3 bpw quantization 11 or Q3_K_S : 3.41G, +1.6321 ppl @ Llama-3-8B 12 or Q3_K_M : 3.74G, +0.6569 ppl @ Llama-3-8B 13 or Q3_K_L : 4.03G, +0.5562 ppl @ Llama-3-8B 25 or IQ4_NL : 4.50 bpw non-linear quantization 30 or IQ4_XS : 4.25 bpw non-linear quantization 15 or Q4_K : alias for Q4_K_M 14 or Q4_K_S : 4.37G, +0.2689 ppl @ Llama-3-8B 15 or Q4_K_M : 4.58G, +0.1754 ppl @ Llama-3-8B 17 or Q5_K : alias for Q5_K_M 16 or Q5_K_S : 5.21G, +0.1049 ppl @ Llama-3-8B 17 or Q5_K_M : 5.33G, +0.0569 ppl @ Llama-3-8B 18 or Q6_K : 6.14G, +0.0217 ppl @ Llama-3-8B 7 or Q8_0 : 7.96G, +0.0026 ppl @ Llama-3-8B 1 or F16 : 14.00G, +0.0020 ppl @ Mistral-7B 32 or BF16 : 14.00G, -0.0050 ppl @ Mistral-7B 0 or F32 : 26.00G @ 7B COPY : only copy tensors, no quantizing 阿里官方发布的微调模型使用的是 Q4_0 量化。 在 ollama 中使用使用 ollama create &lt;modelname&gt; -f &lt;modelfile&gt; 其中，modelname是自己指定，在 ollama run后面跟的那个名字；modelfile默认是当前目录下的 Modelfile 文件，内容应该为 FROM &lt;gguf文件路径&gt;，当然也可以通过 -f 参数指定。 然后就可以和其他模型一样使用了，使用ollama run或者通过 api 使用。 总结如果只是单纯想要训练一个lora并合并，这个过程并不复杂，不涉及模型内部层的修改。","categories":[],"tags":[]},{"title":"2024年5月5日-matlab","slug":"2024年5月5日-matlab","date":"2024-05-05T05:41:51.000Z","updated":"2024-05-06T12:21:33.418Z","comments":true,"path":"2024/05/05/2024年5月5日-matlab/","link":"","permalink":"http://blog.wspdwzh.space/2024/05/05/2024%E5%B9%B45%E6%9C%885%E6%97%A5-matlab/","excerpt":"","text":"正在编写matlab程序，以实现哈夫曼编码 思路 第一步，降序排列符号 第二步，将0和1分别分配给概率最小的两个码元 第三步，将概率最小的这两个码元进行概率相加 然后重复第一步到第三步，直到数组长度变为1 以上过程中，0和1记录在code矩阵中，code是一个N-1×N的矩阵， 第四步，从上往下读取编码后的结果，将离散的0和1串联成为01序列 其中，一到四步在循环内完成。 同时对两个数组进行排序[p_SD,reflect(i,1:M)] = sort(p_SD,&#39;descend&#39;); 这一句的意思是对 p_SD、reflect的第i行的1～M位进行排序，顺序是按照p_SD的大小降序。matlab的代码在直观性上很抽象。虽然确实很强大。 要求长度一样即可。 注意对于矩阵的一行排序的时候，其他行不会被改变。 参考代码思路梳理参考代码来自https://blog.csdn.net/weixin_46258766/article/details/117607050 原本的全部代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849%% 实验四：哈夫曼编码仿真实现clear allclc% 用户输入符号概率p = input(&#x27;请输入离散信源概率分布，例如[0.5,0.5]：\\n&#x27;);N = length(p);% 将概率排序并获得单步码字排序code = strings(N-1,N);% 初始化单步过程的码字reflect = zeros(N-1,N);% 初始化位置对应向量p_SD = p;% p_SD为每次得到的概率排序数组for i=1:N-1 % i表示排序后第几个符号 M = length(p_SD); [p_SD,reflect(i,1:M)] = sort(p_SD,&#x27;descend&#x27;);% 将概率从大到小进行排序 code(i,M) = &#x27;1&#x27;;% 概率最小的是1 code(i,M-1) = &#x27;0&#x27;;% 概率第二小的暂且定义为0 p_SD(M-1) = p_SD(M-1)+p_SD(M);% 将最后两个概率相加 p_SD(M)=[];end% 根据位置对应向量和单步过程的码字计算对应码字CODE = strings(1,N); % 初始化对应码字for i=1:N column = i; for m=1:N-1 [row,column] = find(reflect(m,:)==column); CODE(1,i) = strcat(CODE(1,i),code(m,column)); % 将最小的两个概率映射成一个 if column==N+1-m column = column-1; end endendCODE = reverse(CODE);% 计算平均码长for i=1:N L(i) = size(char(CODE(1,i)),2);endL_ave = sum(L.*p); H = sum(-p.*log2(p)); % 计算信源信息熵yita = H/L_ave; % 计算编码效率% 展示输出码字、平均码长和编码效率disp([&#x27;信号符号 &#x27;,num2str(1:N)]);disp([&#x27;对应概率 &#x27;,num2str(p)]);disp([&#x27;对应码字 &#x27;,CODE]);disp([&#x27;平均码长&#x27;,num2str(L_ave)]);disp([&#x27;编码效率&#x27;,num2str(yita)]);第一段，准备： 初始化用到的向量，矩阵，还有概率数组。12345678910clear allclc% 用户输入符号概率p = input(&#x27;请输入离散信源概率分布，例如[0.5,0.5]：\\n&#x27;);N = length(p);% 将概率排序并获得单步码字排序code = strings(N-1,N);% 初始化单步过程的码字reflect = zeros(N-1,N);% 初始化位置对应向量p_SD = p;% p_SD为每次得到的概率排序数组 第一个循环： 排序：同时排序p_SD和reflect的第i行 对code进行赋值 概率相加，最后一位消除 总之p_SD始终是从大到小的概率降序，在排序过程中，reflect会记录每一次循环中的排序结果。reflect和code都是N-1×N大小的矩阵，每一行对应循环中的一轮。12345678for i=1:N-1 % i表示排序后第几个符号 M = length(p_SD); [p_SD,reflect(i,1:M)] = sort(p_SD,&#x27;descend&#x27;);% 将概率从大到小进行排序 code(i,M) = &#x27;1&#x27;;% 概率最小的是1 code(i,M-1) = &#x27;0&#x27;;% 概率第二小的暂且定义为0 p_SD(M-1) = p_SD(M-1)+p_SD(M);% 将最后两个概率相加 p_SD(M)=[];end第二个循环： 将之前得到的code、reflect合并成为CODE。 m 对应行，i 对应列（的末尾）。i 也可以说是对应 CODE 的每一个元素，或者说是每一个码字。 中间的一层循环是对于每一行进行扫描，首先找到 reflect 的这一行中数值与 column 相同的那一列，然后根据找到的这个数据的位置，找到 code 里面对应的数据（0 或者 1），连接在 CODE 对应位置数据的尾端。 如果 column == N+1-m，也就是找到的数据位置在右边的那个对角线上，那么往左挪一格。 用文字说明起来可能很抽象。 总之就是 (m,column) 这个坐标的移动是二者的先后移动。呈现在图形上就是锯齿状的移动。每一行上，只有右对角线和左对角线上面的数据是有意义的，记录着 0 和 1。1234567891011121314% 根据位置对应向量和单步过程的码字计算对应码字CODE = strings(1,N); % 初始化对应码字for i=1:N column = i; for m=1:N-1 [row,column] = find(reflect(m,:)==column); CODE(1,i) = strcat(CODE(1,i),code(m,column)); % 将最小的两个概率映射成一个 if column==N+1-m column = column-1; end endendCODE = reverse(CODE);数据处理：1234567% 计算平均码长for i=1:N L(i) = size(char(CODE(1,i)),2);endL_ave = sum(L.*p); H = sum(-p.*log2(p)); % 计算信源信息熵yita = H/L_ave; % 计算编码效率展示：1234567% 展示输出码字、平均码长和编码效率disp([&#x27;信号符号 &#x27;,num2str(1:N)]);disp([&#x27;对应概率 &#x27;,num2str(p)]);disp([&#x27;对应码字 &#x27;,CODE]);disp([&#x27;平均码长&#x27;,num2str(L_ave)]);disp([&#x27;编码效率&#x27;,num2str(yita)]); 思路在第一轮循环中，直接记录 CODE。 即，CODE 和 table_data 等宽，table_data 第一行为码字，第二行为概率，第三行为12345的顺序。每一轮循环中，顺序的最后两个被分别赋予 0 和 1。注意不是数组的最后两个，而是table_data第三行的最小的两个。也就是 N-i（对应1） 和 N-i-1（对应0）。","categories":[],"tags":[]},{"title":"2024年4月19日","slug":"2024年4月19日","date":"2024-04-19T10:16:49.000Z","updated":"2024-04-20T09:12:07.520Z","comments":true,"path":"2024/04/19/2024年4月19日/","link":"","permalink":"http://blog.wspdwzh.space/2024/04/19/2024%E5%B9%B44%E6%9C%8819%E6%97%A5/","excerpt":"","text":"香橙派 zero2 使用的全志 H616 架构为 ARMv8，而不是 v7。安装 nomachine 成功之后会提示： 1234567891011121314(Reading database ... 84977 files and directories currently installed.)Preparing to unpack nomachine_8.11.3_3_arm64.deb ...Unpacking nomachine (8.11.3-3) over (8.11.3-3) ...Setting up nomachine (8.11.3-3) ...NX&gt; 700 Starting installation at: Fri, 19 Apr 2024 18:16:16.NX&gt; 700 Using installation profile: Ubuntu.NX&gt; 700 Installation log is: /usr/NX/var/log/nxinstall.log.NX&gt; 700 Installing nxrunner version: 8.11.3.NX&gt; 700 Installing nxplayer version: 8.11.3.NX&gt; 700 Installing nxnode version: 8.11.3.NX&gt; 700 Installing nxserver version: 8.11.3.NX&gt; 700 Installation completed at: Fri, 19 Apr 2024 18:17:19.NX&gt; 700 NoMachine was configured to run the following services:NX&gt; 700 NX service on port: 4000 而且需要注意，要想安装 nomachine，系统版本应该是桌面版本（而不是服务器版本）。不过，如果是服务器版本也问题不大，nomachine 会自动安装桌面。 和 vnc 相比，好处是可以自动启动并使用pc扫描4000端口，从而实现一样的效果；还有就是不需要操心vncserver的状态，或者端口啥的，默认状态就挺好 坏处大概是不能指定桌面（例如，我安装的xfce就不能使用） 注意 xfce 的远程桌面运行对应的进程/服务是 dbus 还有 vncserver，其中vncserver 需要手动启用一下（或者放在 bashrc 里面开机自启动） 可以用tigervnc，也可以用Windows的远程桌面，有时候两个都能用有时候其中一个不能用。 12345678vncserver -localhost yes :1# 启动，注意不要加上 -localhost yes，加了之后会拒绝除了本地之外的其他请求。vncserver -kill :1# 停止vncpasswd# 改密码 spi显示dev中的fb0和fb1：framebuffer，一段内存，作为显示的缓存，在官方文档给出的指令 fbi-vt 1-noverbose-d /dev/fb1 /boot/boot.bmp 作为显示图片的方式。 未完待续 交错战线机器人遇到了b站转发动态、长文的情况，如果是转发动态，那么旧版程序只能搬运动态本身，搬运不了转发的动态；如果是长文，从动态里只能浏览部分文本，格式会被强行压缩。 转发动态动态正文是 “modules”，转发的动态是 “orig”。因此，在处理数据的时候，只需要判断是否具有 “orig”，如果有，按照一样的方式解析即可。 其中，“orig” 底下有着和原本动态一模一样的结构，也就是说[“modules”] 可以被直接替换为 [“orig”][“modules”]用同样的方式解析，因为结构是完全一样的。 很顺利地解决了。 顺利到难以置信。居然只调试了三次…… 长文我想要一个获取 cv（专栏文章）全文的方法。 我发觉其中和 “desc” 并列有一个 “id”，如果是专栏文章，那么 “id” 就等同于 “cv” 后面的数字。例如，id，33838995，对应 cv33838995。这样就不需要正则表达式提取 cv 号码了。 不过这个 id 并不是动态id，动态id是前面那个第一层的 id_str 如果通过 id_str 和 https://api.vc.bilibili.com/dynamic_svr/v1/dynamic_svr/get_dynamic_detail?dynamic_id=920925182538809433 获取到的动态，那依旧是被裁剪过的，并不是我想要的全文。 https://api.bilibili.com/x/article/viewinfo?id=33838995 也仅仅是专栏基本信息，不包括内容。 看了一圈，b站把这个权限封死了，需要申请 https://openhome.bilibili.com/doc/4/b14b77b6-8889-8c8b-2e83-17c5a4c550fb 而且还需要被查询的用户本人授权，捏麻的。 nga 有人在和我做一样的事情 https://ngabbs.com/read.php?tid=19914874 而且是版务，五年之前就开始了。 谢谢你，陌生人。 https://github.com/sjn4048/KingOfGloryTools/tree/master/html-md2nga 长文之后还是没有用上 html2nga，自己写了转换的逻辑 大概就是先拉网页，找到正文就成功了一半。正文每一行是 &lt;p&gt;，图片在 figure 里面。和之前的逻辑基本一样，甚至还要简单很多很多。 浏览网页的文章是不需要授权的，赢。 另外，我判断如果上一行是空行，那么就加粗加大字号。很草率，但我没想到更好的判断标题的办法。 就这样吧。","categories":[],"tags":[]},{"title":"2024年4月12日","slug":"2024年4月12日-泰山派","date":"2024-04-12T05:26:59.000Z","updated":"2024-04-12T12:25:27.226Z","comments":true,"path":"2024/04/12/2024年4月12日-泰山派/","link":"","permalink":"http://blog.wspdwzh.space/2024/04/12/2024%E5%B9%B44%E6%9C%8812%E6%97%A5-%E6%B3%B0%E5%B1%B1%E6%B4%BE/","excerpt":"","text":"泰山派启动环节出了问题，启动到两秒的时候会报错重启，不断重复。以为是系统没有安装好，重新烧写了两次，还是这样子。 事实证明是不能使用电脑左边的 usb 口，而是需要右边的。应该是电压/电流问题。电压诱骗小板我没有使用。 计划（应用）我计划在上面部署一个小型的神经网络，api 用 rk 官方给出的 c++ api，程序使用 vits（tts模型）移植到 c++ 平台上。当然，已经有人完成了代码的编写，但是我希望通过自行移植学习并熟悉 c++ 的开发流程和 vits 本身。完成之后，对比我自己写的和已有的代码，加深我对于 c++ 的理解。 vits 本身及其衍生项目资料，有人做了整理：https://zhuanlan.zhihu.com/p/474601997 vits，带GAN的变分推理自编码器语音推理，实质上是一种比较成熟的思想，结合了注意力、归一化流、对抗网络实现的一个端到端语音相关项目，不光能用在tts领域，也可以做出翻唱变声之类的效果。vits 衍生模型可以说已经不局限于 vits 本身，有很多地方引入了其他的结构（例如，改变流模型的wavenet，变成cnn可以实时推理，变成transformer可以效果更好）。 tts模型能被压缩到很迷你的水准：原作者训练的模型只有14M，经过改进的 so-vits-svc-5.0 只有 202M，相对于动辄几个G十几个G的大模型而言可太小了。对于性能严重不足的 1G 版本泰山派（我暂时不想魔改），模型的大小和推理速度很重要。 https://github.com/PlayVoice/so-vits-svc-5.0 不部署 yolo5 是因为我没摄像头，搞不起来。摄像头得加钱。板子上面预留了一个 MIPI-CSI 摄像头口子，如果有摄像头那确实可以很方便地加上去。但是 1080p 的要六七十块，肉疼。（宣传说专门用于树莓派的更贵，一个摄像头顶俩泰山派） 便宜一点的也有，800万像素，三十多，加运费四十多。 看到有一家包邮 35 的，800万像素。不得不说免运费在买这种小东西上优势巨大。 有一个 25 包邮的笔记本电脑用摄像头，1080p，但是是usb口出来。 顺带一提，这板子也没有 3.5mm 孔，需要扩展板，但是有一个咪头，可以用廉价的咪头话筒/扬声器。官方提供了一个现成的音频小板，有麦有扬声器，是咪头。自己买元器件来焊少说要个两三块，省钱了。 更新：使用 aplay -l 寻找音频输出口的时候，会提示没有声卡（也就是不认这个设备），使用 arecord -l 同理。 另外，yolo 可以是只识别单张图片，不需要视频串流输入。 准备官方提供了 python 和 c 的sdk：https://github.com/airockchip/rknn-toolkit2 和例程：https://github.com/airockchip/rknn_model_zoo 官方文档：https://t.rock-chips.com/wiki/CN/tb-rk3588x/ 但是是3588版本，不过也能参考。 提供的镜像中有 rknpu2，但是版本较低。 zoo 提供的 example文字处理部分，使用了 Lite Transformer，用于嵌入式设备（低算力）的 Transformer。极限情况下能将 transformer 模型规模降低 18 倍（太抽象了）。 https://arxiv.org/abs/2004.11886","categories":[],"tags":[]},{"title":"2024年3月30日交错战线机器人","slug":"2024年3月30日交错战线机器人","date":"2024-03-30T10:23:46.000Z","updated":"2024-03-30T11:02:17.997Z","comments":true,"path":"2024/03/30/2024年3月30日交错战线机器人/","link":"","permalink":"http://blog.wspdwzh.space/2024/03/30/2024%E5%B9%B43%E6%9C%8830%E6%97%A5%E4%BA%A4%E9%94%99%E6%88%98%E7%BA%BF%E6%9C%BA%E5%99%A8%E4%BA%BA/","excerpt":"","text":"之前忘记加上附件类型的判断了。 我需要的附件类型只有两个，一个是静态图片，一个是动态图片。视频传不了，音频不会有。 而我需要保证的是传上去、正确的传上去。 nga 的附件发送需要提供附件名称、附件类型： 12attachment_file1_url_utf8_name = &quot;image_gif%2egif&quot;Content_Type = &#x27;image/gif&#x27; 很简单。 不过，除了请求体里面需要修改，还需要在文件列表中进行修改： 123files=[ (&#x27;attachment_file1&#x27;,(filename, img, Content_Type)) ] nga 的静态图片有 4M 大小上限，而动态图 gif 文件没有。","categories":[],"tags":[]},{"title":"读VITS代码","slug":"读VITS代码","date":"2024-03-29T06:04:04.000Z","updated":"2024-04-01T07:42:56.158Z","comments":true,"path":"2024/03/29/读VITS代码/","link":"","permalink":"http://blog.wspdwzh.space/2024/03/29/%E8%AF%BBVITS%E4%BB%A3%E7%A0%81/","excerpt":"","text":"总之就是读一下 vits（原论文标题：Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech）。vits， “Variational Inference with adversarial learning for end-to-end Text-to-Speech”，一个变分推理、对抗学习、端到端的 TTS 方法。论文团队给出了他们的示例代码。 概览工程包含的文件： attentions.py：关于自注意力机制的部分，定义了 transformer 的结构。 Encoder 类 定义了参数和 forward 方法 Decoder 类 定义了参数和 forward 方法 MultiHeadAttention 类 定义了参数，forward 方法，attention 方法，_matmul_with_relative_values 方法，_matmul_with_relative_keys 方法，_get_relative_embeddings 方法，_relative_position_to_absolute_position 方法，_absolute_position_to_relative_position 方法，_attention_bias_proximal 方法 FFN（前馈神经网络） 类 定义了参数，forward 方法，_causal_padding 方法，_same_padding 方法。 commons.py：公用的一些常用方法 定义了 init_weights 方法 定义了 get_padding 方法 定义了 convert_pad_shape 方法 定义了 intersperse 方法 kl_divergence 方法 rand_gumbel 方法 rand_gumbel_like 方法 slice_segments 方法 rand_slice_segments 方法 get_timing_signal_1d 方法 add_timing_signal_1d 方法 cat_timing_signal_1d 方法 subsequent_mask 方法 fused_add_tanh_sigmoid_multiply 方法：使用 @torch.jit.script 装饰 convert_pad_shape 方法 shift_1d 方法 sequence_mask 方法 generate_path 方法 clipgrad_value 方法 data_utils.py 定义了 TextAudioLoader 类 切分训练的时候使用的音频、文本 定义了 TextAudioCollate 类 批量整理文本、音频 定义了多说话者版本 TextAudioSpeakerLoader 类 类似 TextAudioLoader 但是是多说话者版本 定义了 TextAudioSpeakerCollate 类 类似 TextAudioCollate，但是是多说话者版本 定义了 DistributedBucketSampler 类 储存桶相关 losses.py：损失函数相关 feature_loss 方法 计算特征图（fmap）之间的差异 discriminator_loss 方法 计算判别器（Discriminator）的损失 generator_loss 方法 计算生成器（Generator）的损失 kl_loss 方法 计算KL散度损失，用于变分自编码器(VAE) mel_processing.py：梅尔频谱处理 dynamic_range_compression_torch 方法 动态范围压缩，乘 C、裁剪、然后取对数 dynamic_range_decompression_torch 方法 动态范围解压缩，和动态范围压缩互补 spectral_normalize_torch 方法 对幅度谱进行动态范围压缩，就是调用 dynamic_range_compression_torch 方法 spectral_de_normalize_torch 方法 同上，只是调用了一下 dynamic_range_decompression_torch 方法 spectrogram_torch 方法 作用： 计算音频信号 y 的短时傅立叶变换（STFT）谱。 参数： FFT点数 n_fft 采样率 sampling_rate 帧移 hop_size 窗长度 win_size 是否在时间轴上居中 center 先对输入信号做反射填充，然后应用 Hann 窗函数进行窗口化处理，最后计算 STFT 并取模平方根得到幅度谱。 spec_to_mel_torch 方法 作用： 将频域谱 spec 转换为 Mel 频谱。 使用全局变量 mel_basis 存储预先计算好的梅尔滤波器组矩阵，如果矩阵不存在，则会基于给定的参数计算并转换为当前设备和数据类型。 将幅度谱与梅尔滤波器组矩阵进行矩阵乘法，然后对结果进行动态范围压缩。 mel_spectrogram_torch 方法 完整流程的 Mel 频谱计算函数，包含了从原始音频信号到 Mel 频谱的全部步骤。 包括了对输入信号的检查（确保其在 [-1, 1] 范围内），计算 STFT 幅度谱，转换为 Mel 频谱并进行动态范围压缩。 models.py 模型主体结构。 每一个类是模型的一个（或者一种）组件，核心是 forward 方法。 StochasticDurationPredictor 类 随机时长预测器，论文里提到的主要创新点，使用了正态流。接收 gin_channels 参数进行调整。 forward 方法 DurationPredictor 类 时长预测器，简化版本的 StochasticDurationPredictor，不支持条件输入，没有正态流。 TextEncoder 类 继承自 torch.nn.Module，并且使用了 attentions 的 Encoder 制作成员（上面的随机时长预测器和下面几个类也用到了 torch.nn.Module，但是没有使用 attentions） forward 方法： 将文本输入通过嵌入层来获得初始的嵌入表示 将这些嵌入表示转换为适合自注意力机制的格式（三维张量，维度为批次大小、隐藏通道数和序列长度） 使用自注意力机制和卷积层来处理这些嵌入表示 通过投影层输出最终的编码表示 ResidualCouplingBlock 类 残差耦合块 其中的流变换根据 reverse 参数决定是正向还是反向，执行正向流变换的时候，输入数据会依次通过每个流变换层。每个流变换层都会更新数据，并通过残差连接将变换后的数据与原始数据相结合，这有助于避免梯度消失问题 流部分和 StochasticDurationPredictor 是一样的 PosteriorEncoder 类 后验分布编码器 在给定观测数据（如语音信号）的条件下，对潜在变量（如声谱特征）的分布进行建模 换言之就是，将观测到的语音信号编码为潜在空间的分布，使得模型能够捕捉到语音信号的复杂性和多样性，并在生成过程中保持这些特性 forward 方法： 将输入数据通过预处理卷积层来获得初始的编码表示 将这些编码表示通过扩张卷积层进行进一步的处理，扩张卷积层通过扩张率来增加感受野，捕捉更长范围内的依赖关系 通过投影卷积层输出均值和对数方差、输出可以用于后续的生成过程，如重参数化技巧，以生成新的样本。 Generator 类 从潜在空间生成频谱 forward 方法： 输入数据首先通过 conv_pre 进行处理（是一个一维的卷积核，Conv1d） 数据依次通过 ups 中的上采样层和 resblocks 中的残差块。在每一步上采样过程中，数据的分辨率逐渐增加，同时通过残差连接保持了信息的流动 通过 conv_post 生成最终的输出，这可以是语音波形或其他类型的音频特征 remove_weight_norm 方法： 移除所有卷积层中的权重归一化（weight normalization） 可能是测试使用的？ DiscriminatorP 类 GANs 的一部分，辨别器。 适合周期信号，P 指的是 Periodic，周期的（我猜的） 此处可以参考 HiFi-GAN 模型 论文解读 https://yuan1615.github.io/2022/01/21/HiFi-GAN/ 论文翻译 https://blog.csdn.net/Blackoutdragon/article/details/131766625 DiscriminatorS 类 同上， GANs 的一部分，辨别器。 适合非周期信号（文本，图像），S 指的是 Sequential，序列的（我猜的） MultiPeriodDiscriminator 类 多周期辨别器，使用了上面两种辨别器：12discs = [DiscriminatorS(use_spectral_norm=use_spectral_norm)]discs = discs + [DiscriminatorP(i, use_spectral_norm=use_spectral_norm) for i in periods] 综合二者的能力 SynthesizerTrn 类 用于训练的合成器，较为复杂，使用了上面定义的一系列模块： enc_p: PosteriorEncoder，文本编码器，用于将文本转换为嵌入表示。它使用一个自注意力编码器来处理文本输入。 dec: Generator，生成器，用于从嵌入表示生成语音信号。包含一系列上采样层和残差块，用于生成高质量的语音波形。 enc_q: TextEncoder，后验编码器，用于编码声谱特征。使用卷积层和扩张卷积来处理声谱数据。 flow: ResidualCouplingBlock，残差耦合块，用于数据的流动和变换。它包含一系列残差耦合层，用于学习声谱数据的复杂分布。 dp: StochasticDurationPredictor，持续时间预测器，用于预测语音信号的持续时间 根据 use_sdp 参数的值，它会初始化为 StochasticDurationPredictor 或 DurationPredictor。 emb_g: 一个 nn.Embedding，说话者嵌入层，用于条件生成不同说话者的语音 如果 n_speakers 大于0，这个层会被初始化。 forward 方法： 文本编码: 使用 enc_p（文本编码器）对文本输入 x 进行编码，得到文本的嵌入表示。同时，使用 x_lengths 来创建一个掩码，以便在后续步骤中忽略填充的部分。 声谱编码: 使用 enc_q（后验编码器）对目标声谱特征 y 进行编码，得到声谱的嵌入表示。同时，如果提供了说话者ID sid，则使用 emb_g（说话者嵌入层）来获取说话者嵌入，并将其加入到声谱编码中。 持续时间预测: 如果模型使用随机持续时间预测器（use_sdp 为 True），则调用 dp（持续时间预测器）来预测语音信号的持续时间。否则，使用 DurationPredictor 来预测（节约成本）。 生成路径计算: 计算生成语音的路径。这通常涉及到计算负对数似然（negative log-likelihood）和注意力机制，以便在生成过程中对齐文本和声谱特征。 生成语音波形: 使用 dec（生成器）来生成语音波形。生成器接收文本嵌入表示和声谱嵌入表示作为输入，并输出最终的语音波形。 输出: forward 方法的输出包括生成的语音波形、持续时间预测损失、注意力权重、生成的声谱片段的ID、输入文本和声谱的掩码，以及原始的嵌入表示。 输出内容： o: 生成的语音波形。 l_length: 持续时间预测损失。 attn: 注意力权重，用于显示文本和声谱特征之间的对齐情况。 ids_slice: 生成的声谱片段的ID。 x_mask, y_mask: 输入文本和声谱的掩码，用于在后续处理中忽略填充的部分。 (z, z_p, m_p, logs_p, m_q, logs_q): 原始的嵌入表示和相关的统计信息，这些信息可以用于进一步的分析和调试。 infer 方法 训练结束之后，用于推理的方法 文本编码: 与 forward 方法类似，infer 方法首先使用文本编码器 enc_p 对输入文本 x 进行编码，得到文本的嵌入表示。 声谱编码: 如果提供了说话者ID sid，则使用说话者嵌入层 emb_g 来获取说话者嵌入，并将其加入到声谱编码中。 持续时间预测: 根据模型是否使用随机持续时间预测器（use_sdp 参数），调用相应的持续时间预测器 dp 来预测语音信号的持续时间。 生成语音波形: 使用生成器 dec 来生成语音波形。在推理模式下，生成器会根据文本嵌入表示和预测的持续时间生成连续的语音波形。 注意力权重计算: 通过计算注意力权重，可以了解模型是如何在生成语音时关注输入文本的不同部分的。 输出: infer 方法的输出通常包括生成的语音波形、注意力权重和其他可能的中间结果，如声谱特征的嵌入表示。 voice_conversion 方法 用于执行说话者转换 接收源说话者的语音信号和目标说话者的标识符作为输入，然后生成具有目标说话者特征的语音信号 参数： y: 源说话者的语音信号，通常是一个三维张量，形状为 [batch_size, spec_length, spec_channels]。 y_lengths: 源语音信号的长度，用于指示每个样本中的非填充声谱的长度。 sid_src: 源说话者的标识符。 sid_tgt: 目标说话者的标识符。、 过程： 说话者嵌入获取: 使用 emb_g（说话者嵌入层）根据源说话者和目标说话者的标识符获取相应的说话者嵌入。这些嵌入将用于调整生成的语音，使其具有目标说话者的特征。 源语音编码: 使用 enc_q（后验编码器）对源说话者的语音信号 y 进行编码，得到声谱的嵌入表示。 说话者转换: 通过 flow（残差耦合块）和可能的其他变换层，将源说话者的嵌入表示转换为目标说话者的嵌入表示。这个过程可能涉及到使用说话者嵌入来调整声谱特征，以便模仿目标说话者的声音。 生成目标语音: 使用 dec（生成器）根据转换后的嵌入表示生成目标说话者的语音信号。生成器会根据调整后的声谱特征生成连续的语音波形。 输出: voice_conversion 方法的输出是转换后的语音信号，它应该具有目标说话者的声音特征，同时保持原始文本的内容不变。 输出： o_hat: 转换后的目标说话者的语音信号。 y_mask: 目标语音信号的掩码，用于在后续处理中忽略填充的部分。 (z, z_p, z_hat): 原始的嵌入表示和相关的统计信息，这些信息可以用于进一步的分析和调试。 modules.py LayerNorm 类 归一化层 ConvReluNorm 类 attention 里的一个结构 DDSConv 类 带空洞卷积（Dilated Convolution）和深度可分离卷积（Depth-Separable Convolution）的模块 WN 类 权重归一化（Weight Normalization） ResBlock1 类 和 ResBlock2 类 残差块（Residual Block），用于构建更深的网络结构 Log 类 对输入数据 x 取对数的操作 用于变分自编码器（VAE）中的变分下界 Flip 类 翻转输入/取消翻转（取决于 reverse 是 True 还是 False） ElementwiseAffine 类 逐元素的仿射变换 ResidualCouplingLayer 类 残差耦合层 用于流模型（Flow Model）中的变分推断 ConvFlow 类 基于卷积的流模型 用于生成模型或者变分推断 preprocess.py 作为主函数时： 向命令行添加参数 从指定的文件列表中读取文件路径和文本 使用指定的文本清理器清理文本 将清理后的文本写入新的文件列表 总之就是字面意思的预处理 train.py main 函数 断言检查： 使用 assert torch.cuda.is_available() 确保当前环境可以使用CUDA，因为脚本设计为仅在GPU上运行。 获取GPU数量： 通过 torch.cuda.device_count() 获取系统中可用的GPU数量，并将其存储在变量 n_gpus 中。 设置环境变量： 设置环境变量 MASTER_ADDR 和 MASTER_PORT，这些变量用于分布式训练中的进程间通信 MASTER_ADDR 被设置为 ‘localhost’，MASTER_PORT 被设置为 ‘80000’。 获取超参数： 调用 utils.get_hparams() 函数获取超参数设置 超参数通常包括： 学习率 批次大小 训练周期数 启动分布式训练： 使用 mp.spawn（mp 是 torch 的 multiprocessing） 函数启动多个训练进程，调用 run 函数 nprocs：要启动的进程数 run 函数 在 main 中被 mp.spawn 调用 函数参数： rank：当前进程的排名（ID），在分布式训练中用于区分不同的进程。 n_gpus：系统中可用的GPU数量。 hps：包含超参数的对象，这些超参数定义了模型的训练和数据配置。 判断当前进程（rank）的排名是否是0（是主进程），如果是的话： 初始化日志记录器： 调用 utils.get_logger 方法初始化日志记录器，并记录超参数 hps 的信息。这有助于监控训练过程并记录重要信息。 检查Git哈希： 调用 utils.check_git_hash 方法来验证代码的一致性，确保训练过程中使用的代码版本与预期的版本相符 一般我使用的时候需要注释掉 创建TensorBoard SummaryWriter： 创建两个 SummaryWriter 对象，一个用于记录训练过程中的信息（writer），另一个用于记录评估过程中的信息（writer_eval）。 初始化分布式训练环境： 调用 dist.init_process_group 方法初始化分布式训练环境。设置后端为 ‘nccl’，初始化方法为 ‘env://‘，世界大小（world size）为 n_gpus，当前进程的排名为 rank。 设置随机种子： 使用 torch.manual_seed 方法设置随机种子，以确保训练的可重复性。随机种子使用超参数中的 hps.train.seed 值。 设置当前使用的GPU 加载训练数据： 使用 TextAudioLoader 类加载训练数据 创建 DistributedBucketSampler 对象，用于在分布式训练中对数据进行采样 创建 DataLoader 对象，用于加载训练数据。 判断当前进程（rank）的排名是否是0（是主进程），如果是的话： 加载评估数据 创建评估数据的 DataLoader 对象。 模型： 使用 SynthesizerTrn 类构建生成器模型 net_g 使用 MultiPeriodDiscriminator 类构建鉴别器模型 net_d 优化器： 使用 torch.optim.AdamW 创建生成器优化器 optim_g、鉴别器优化器 optim_d 使用 DDP（Distributed Data Parallel）包装生成器和鉴别器模型，以支持分布式训练。 加载检查点（checkpoint）： 从检查点文件中加载生成器和鉴别器的状态 如果加载失败，则将全局步数 global_step 和当前周期 epoch_str 设置为初始值。 设置学习率调度器： 使用 torch.optim.lr_scheduler.ExponentialLR 创建学习率调度器 设置学习率衰减率。 训练和评估循环：（for epoch in …） 遍历超参数定义的训练周期 hps.train.epochs 在每个周期中，执行训练和评估过程 如果当前进程的排名为0，则调用 train_and_evaluate 函数进行训练和评估，并记录日志和TensorBoard信息 否则，只执行训练过程。 更新学习率调度器： 在每个周期结束时，更新生成器和鉴别器的学习率调度器。 即 调用 scheduler_g.step() 和 scheduler_d.step() train_and_evaluate 函数 函数参数： rank: 当前进程的排名（ID），用于分布式训练中的标识。 epoch: 当前的训练周期。 hps: 超参数设置，包含了模型训练和数据配置的所有重要参数。 nets: 一个包含生成器（net_g）和鉴别器（net_d）的列表。 optims: 一个包含生成器和鉴别器优化器的列表。 schedulers: 一个包含生成器和鉴别器学习率调度器的列表。 scaler: 梯度缩放器，用于混合精度训练中梯度的缩放。 loaders: 一个包含训练和评估数据加载器的列表。 logger: 日志记录器，用于记录训练过程中的信息。 writers: 一个包含TensorBoard的SummaryWriter对象的列表，用于记录训练和评估过程中的信息。 函数内部： 将nets、optims、schedulers中的生成器和鉴别器分别赋值给net_g、optim_g、scheduler_g和net_d、optim_d、scheduler_d。 如果writers不为None，则将写入器赋值给writer和writer_eval。 调用train_loader.batch_sampler.set_epoch(epoch)设置当前的训练周期，这对于某些采样器（如DistributedBucketSampler）来说是必要的，因为它们可能需要根据周期进行调整。 定义全局变量global_step，用于跟踪训练步数。 将生成器和鉴别器设置为训练模式（net_g.train()和net_d.train()）。 遍历训练数据加载器train_loader中的每个批次。 将批次数据移动到对应的GPU上。 使用autocast上下文管理器进行混合精度训练，如果启用了混合精度训练。 调用生成器net_g生成预测值y_hat，并计算损失。 将真实音频的频谱转换为Mel频谱y_mel。 计算鉴别器的损失loss_disc，并执行反向传播和优化器步骤。 计算生成器的损失loss_gen_all，并执行反向传播和优化器步骤。 如果当前进程是主进程（rank == 0），则记录日志和TensorBoard信息。 如果当前进程是主进程，检查是否到达了评估间隔，如果是，则调用evaluate函数进行评估，并保存检查点。 向控制台打印全局训练步数global_step。 evaluate 函数 函数参数： hps：包含超参数的对象，这些超参数定义了模型的训练和数据配置。 generator：训练好的生成器模型，用于生成语音。 eval_loader：评估数据的加载器，它提供了评估数据集的批量数据。 writer_eval：用于评估数据的TensorBoard SummaryWriter对象，用于记录评估过程中的信息。 设置模型为评估模式： 调用 generator.eval() 将模型设置为评估模式。这是必要的，因为在评估模式下，模型会关闭dropout和批量归一化等只在训练时使用的层。 禁用梯度计算： 使用 torch.no_grad() 上下文管理器来禁用梯度计算。这有助于减少内存消耗，并加速评估过程，因为在评估时不需要计算梯度。 遍历评估数据加载器： 通过 for 循环遍历 eval_loader 中的每个批次的数据。 将批次数据移动到GPU上（这里假设使用的是第一个GPU，即 cuda(0)）。 处理单个样本： 从评估批次中提取单个样本数据（这通常是通过切片操作完成的），因为评估函数可能设计为只处理单个样本。 调用 generator.module.infer 方法（注意这里使用了 .module，这可能是因为模型被包装在 nn.DataParallel 或 nn.parallel.DistributedDataParallel 中）来生成语音。 计算生成的语音的长度。 转换频谱为Mel频谱： 使用 spec_to_mel_torch 函数将真实和生成的频谱图转换为Mel频谱图。Mel频谱图是一种表示音频数据的常用方式，它更接近于人类对频率的感知。 记录评估结果： 如果当前进程的排名为0（主进程），则使用 utils.summarize 函数记录评估结果。这包括生成的Mel频谱图、音频样本以及其他可能的统计信息。 将生成的Mel频谱图和音频样本添加到 image_dict 和 audio_dict 字典中，这些字典随后被传递给 utils.summarize 函数。 如果是训练的第一步（global_step == 0），则还包括真实样本的Mel频谱图和音频样本以供参考。 恢复模型训练模式： 在评估结束后，调用 generator.train() 将模型恢复到训练模式。 train_ms.py 多说话者训练，ms 意思是 multi-speaker 总之就是多了一些多说话人相关的设置，对应的类也被换成了多说话人需要的类 除此之外，还使用了 GradScaler 来进行梯度缩放 因为我是懒狗所以直接交给 chatgpt 帮我对比了 数据加载器和处理： 第一段代码中使用了TextAudioLoader和DistributedBucketSampler来加载和处理文本和音频数据。 第二段代码中使用了TextAudioSpeakerLoader，这表明它可能在处理与说话者相关的数据，这可能是一个多说话者的TTS模型。 模型结构： 第一段代码中的模型定义较为简洁，没有提及说话者的数量。 第二段代码中的SynthesizerTrn模型在初始化时考虑了n_speakers参数，这意味着模型可能包含说话者嵌入或有说话者适应的功能。 评估函数： 第一段代码中的evaluate函数没有提供详细的实现，而第二段代码中的evaluate函数实现了对单个样本的评估，并生成了Mel频谱图和音频样本的可视化。 第二段代码中的评估还考虑了说话者（speakers参数），并且在评估时使用了generator.module.infer方法，这表明评估过程中可能使用了说话者特定的信息。 训练循环： 第一段代码中的train_and_evaluate函数实现了训练和评估的循环，但在代码片段中没有提供完整的实现。 第二段代码中的train_and_evaluate函数提供了完整的实现，包括前向传播、损失计算、反向传播和优化器步骤，以及日志记录和评估过程。 梯度缩放： 第二段代码中使用了GradScaler来进行梯度缩放，这在混合精度训练中非常有用，可以防止梯度值过大导致的数值不稳定问题。 第一段代码中没有明确提及梯度缩放。 学习率调度器： 两段代码都使用了指数衰减的学习率调度器，但是第二段代码中提供了更详细的实现。 保存检查点： 第二段代码中在每个epoch结束时保存了生成器和鉴别器的检查点，而第一段代码中没有明确提及检查点的保存。 代码结构： 两段代码都遵循了类似的结构，包括初始化、模型定义、训练循环和评估过程。 第二段代码提供了更多的细节，包括模型的具体参数、评估过程和训练循环中的日志记录。 transforms.py utils.py 流模型在程序里，ResidualCouplingBlock（残差耦合块）类和 StochasticDurationPredictor（随机时长预测器）就是使用了流模型。 流变换（Flow Transformation）是流模型（Flow-based Model）中的一个核心概念，它指的是一系列可逆的变换过程，用于将一个复杂的概率分布转换为一个更简单（通常是高斯）的概率分布，或者反过来，将一个简单的概率分布转换为一个复杂的目标分布。这些变换过程是可逆的，意味着可以从一个分布直接转换到另一个分布，并且可以精确计算转换过程中的雅各比行列式（Jacobian determinant），这对于概率密度函数的计算至关重要。 简而言之就是概率界的傅立叶变换，把一个复杂的、通用的概率模型（对应到傅立叶变换里就是一个复杂的函数）分解为标准的简单分布，例如高斯分布（对应傅立叶变换的正余弦函数），过程可逆，变换之后更加容易处理（因为都是基本分布/函数了）。 流变换的特点： 可逆性: 流变换的一个显著特点是它的双向可逆性。这意味着变换不仅可以从分布A转换到分布B，还可以从分布B转换回分布A。这种可逆性使得流模型在理论上可以精确地计算概率密度，并且可以用于生成模型，通过逆变换生成新的样本。 精确计算: 在传统的生成模型中，如生成对抗网络（GANs）或变分自编码器（VAEs），通常需要通过近似方法来估计概率密度。而流模型通过流变换，可以直接计算概率密度，这在理论上提供了更精确的估计。 雅各比行列式: 流变换过程中的雅各比行列式是关键，因为它涉及到变换的尺度和方向的变化。在流模型中，通过设计特定的变换结构（如耦合层），可以简化雅各比行列式的计算，使其在实际应用中变得可行。 流变换的发展： NICE:最初的流变换模型NICE（Non-linear Independent Components Estimation）实现了从任意分布到高斯分布的可逆变换。 RealNVP:后续的RealNVP（Real-Valued Non-Volume Preserving）模型进一步扩展了流变换的能力，实现了从任意分布到条件非高斯分布的可逆变换。 GLOW:最新的GLOW（Generative Flow with Invertible 1x1 Convolutions）模型通过引入1x1卷积，实现了从任意分布到任意其他分布的可逆变换，这使得GLOW能够处理更复杂的分布，如图像数据。 流变换的应用：流变换在生成模型中的应用非常广泛，特别是在需要精确概率估计的场景中。例如，在语音合成、图像生成、药物设计等领域，流模型可以通过流变换来生成高质量的样本，并且可以精确地计算样本的概率密度。 可以参考 https://gwylab.com/note-flow_based_model.html 和 https://www.bilibili.com/video/BV1E441137wE","categories":[],"tags":[]},{"title":"2024年3月18日","slug":"2024年3月18日","date":"2024-03-18T08:56:40.000Z","updated":"2024-03-19T05:29:47.923Z","comments":true,"path":"2024/03/18/2024年3月18日/","link":"","permalink":"http://blog.wspdwzh.space/2024/03/18/2024%E5%B9%B43%E6%9C%8818%E6%97%A5/","excerpt":"","text":"今天试着完善交错战线机器人，两个目标： 通过星火大模型 API ，补全空白标题 上传图片并使用 补全空白标题使用讯飞星火提供的官方 API 例程即可。 123456def generate_title(content=&quot;&quot;): text.clear question = getText(&quot;user&quot;, content) SparkApi.answer = &quot;&quot; SparkApi.main(appid, api_key, api_secret, Spark_url, domain, question) return str(SparkApi.answer) content 为 “向大模型提问的内容”，在这个情况下，则为 “请你为以下内容想一个标题”；这个函数会返回一段文本，即答案，即给出的标题。 上传文件/图片我如果要通过 python 上传图片，一是需要注意在上传之前需要发送一个 OPTIONS 请求，二是上传后不会返回任何内容，包括图片 url。 查看了原js，使用的是 XHR（XMLHttpRequest）提交数据。 可以使用 Object.keys() 得到一个 Object 对象的键，例如，对于 变量 asd，可以使用 Object.keys(asd) 得到键，但注意不是通过 asd.keys()。 在原本的js中，构造了一个 postfunc.thumbBinCache 方便生成图片代码，其中第七个键是完整大小的图片代码。 对于函数 postfunc.add1Attach = function (opt, time, attach,checkSum,url,isimg,thumb,utf8oname,tid,pid,aid)，有以下注释： 1234567891011121314/** * 添加一个上传好的附件 * @param &#123;*&#125; opt bit选项 &amp;1不复用当前上传elm * @param &#123;*&#125; time 时间戳(毫秒) * @param &#123;*&#125; attach 附件服务器返回的attach字符串 * @param &#123;*&#125; checkSum 附件服务器返回的checkSum字符串 * @param &#123;*&#125; url 路径 mon_\\d+开头 * @param &#123;*&#125; isimg 是否是图片 * @param &#123;*&#125; thumb thumb值 bit * @param &#123;*&#125; utf8oname * @param &#123;*&#125; tid * @param &#123;*&#125; pid * @param &#123;*&#125; aid */ 我一直在纳闷 url 参数从何而来。 url 参数被保存在 y.data.url，其中 y 是 window.script_muti_get_var_store，即 nga 的网页版页面数据。可以向控制台输入 window.script_muti_get_var_store.data.url 查询 url。 （但是少了个 ./，需要自己加上去） 那么，问题来了，应该如何在没有编辑页面的 python 程序中获取到 url？ 根据 api 文档（二哥写的），返回的数据一种形式就是开头有个 window.script_muti_get_var_store =，得到的数据就这些个格式，但内容肯定是不同的。 但是发帖后获取的返回数据中，有已上传附件、已上传附件验证码（auth）。 地精文档之前没注意到，光顾着自己尝试了。实际上二哥有详细描述应该如何上传附件。见 https://g.nga.cn/read.php?tid=6406100 的 6.1 和 6.2 节。 值得注意的是，文档是挺久之前写的，实际情况可能有变化。但也可能没变化，只是我搞错了，误以为没有返回数据。 文档中的描述是： 1234使用post(enctype=multipart/form-data)方法将如下数据上传至 6.1 中提到的数据中的附件上传地址，上传成功后服务器会返回数据。将attachments连接至发帖表单的attachments参数末尾(如有多个附件用\\t分隔)将attachments_check连接至发帖表单的attachments_check参数末尾 (如有多个附件用\\t分隔) 而发贴的时候，应当附带 attachments 附件、attachments_check 附件验证码。 我猜测 6.1 中的附件上传地址指的是一个 url，例如 http://img8.nga.cn/attach.php 之类的。 试了一下fid=823，nga 的上线游戏讨论区。 我向 https://ngabbs.com/post.php?fid=823&amp;__output=1 发送请求，返回的数据如下： 1234567891011121314151617181920212223242526272829303132&#123; &quot;data&quot;: &#123; &quot;action&quot;: &quot;new&quot;, &quot;__T&quot;: &#123; &quot;topic_misc_var&quot;: &quot;&quot; &#125;, &quot;fid&quot;: 823, &quot;auth&quot;: &quot;【字符串】&quot;, &quot;if_moderator&quot;: 0, &quot;cost_info&quot;: &quot;匿名主题50银币 匿名回复1银币 贴条回复1银币 投票10银币 版主免费 付费会员免费(每月限量)&quot;, &quot;tid&quot;: &quot;&quot;, &quot;__CU&quot;: &#123; &quot;uid&quot;: 65112288, &quot;group_bit&quot;: 98528, &quot;admincheck&quot;: 0, &quot;rvrc&quot;: 10 &#125;, &quot;__GLOBAL&quot;: &#123; &quot;_ATTACH_BASE_VIEW&quot;: &quot;img.nga.178.com/attachments&quot; &#125;, &quot;__F&quot;: &#123; &quot;bit_data&quot;: 167772160, &quot;fid&quot;: 823, &quot;name&quot;: &quot;上线游戏讨论区&quot; &#125;, &quot;attach_url&quot;: &quot;https://img8.nga.cn/attach.php&quot; &#125;, &quot;encode&quot;: &quot;gbk&quot;, &quot;time&quot;: 1710754883, &quot;debug&quot;: null&#125; 得到的结果中， &quot;attach_url&quot;: &quot;https://img8.nga.cn/attach.php&quot; 意思就是我要向这边上传文件，&quot;auth&quot;: &quot;【字符串】&quot;, 就是我需要附带的附件验证码，否则会被视为违规请求。需要的就是这个。 注意这是需要登录的（废话）。发送请求和其他基本一样，带上 Cookie 即可。 又试了一下在网页段上传文件时，会发送这么一个 POST 请求： 123456789window.script_muti_get_var_store = &#123; data: &#123; attachments: &#x27;aid~mvQ2t-64jz~ext~webp~url_utf8_org_name~RJ01078257%5fimg%5fmain%2ewebp~path~mon_202403/18~url_dscp~~size~28538~name~mvQ2t-64jzKsT1kSfk-bo.webp~tmp_file~./temp_attachments/mvQ2t-64jz.webp.tmp~tmp_shoot~./temp_attachments/mvQ2t-64jz.webp.tmp~tmp_shoot_size~28538~tmp_shoot_ext~webp~isimg~1~w~560~h~420~thumb~56&#x27;, attachments_check: &#x27;e7f78df7942303341cfc34c0947d092a&#x27;, url: &#x27;mon_202403/18/mvQ2t-64jzKsT1kSfk-bo.webp&#x27;, isImg: &#x27;1&#x27;, thumb: &#x27;56&#x27; &#125;&#125; 很显然，这是 javascript 生成的表单数据。也就是说，正常流程中发送数据，不会向服务器请求得到附件的 url，反之，是本地生成 url，再发送给服务器。 那么问题来了，本地是如何生成附件 url 的？ 按照我的理解，应该是上传文件-图片服务器响应-返回数据中提取对应 url，但我并没有看到相应的响应。 总之就是又试了一次使用 postman 制造一个请求，成功上传了，并且返回了有效数据： 123456789window.script_muti_get_var_store = &#123; data: &#123; attachments: &#x27;aid~mvQ2t-3za5~ext~jpg~url_utf8_org_name~image.png~path~mon_202403/18~url_dscp~~size~124647~name~mvQ2t-3za5ZcT3cSlc-w0.jpg~tmp_file~./temp_attachments/mvQ2t-3za5.jpg.tmp~w~768~h~1152~tmp_shoot~./temp_attachments/mvQ2t-3za5.jpg.tmp~tmp_shoot_size~124647~tmp_shoot_ext~jpg~isimg~1~thumb~120&#x27;, attachments_check: &#x27;c745093860ce606f3fe12c0c3b66e638&#x27;, url: &#x27;mon_202403/18/mvQ2t-3za5ZcT3cSlc-w0.jpg&#x27;, isImg: &#x27;1&#x27;, thumb: &#x27;120&#x27; &#125;&#125; 是的，正是之前那些；我理解有误，但无误；这些数据不是本地提交的，是远端发来的。 破案了在最终提交 post 的时候，需要在 attachments 添加对应的 attachments，而不是 attachments_check，或者 url 这是单张图片提交的情况：123456789101112action: replyfid: 275tid: 38719308post_content: [img]./mon_202403/18/7nQ2t-de3sZlT3cSlc-w0.jpg[/img]attachments: aid~7nQ2t-de3s~ext~jpg~url_utf8_org_name~00737%2d2622116886%2dfeaturelessMix%5fv30202312%2epng~path~mon_202403/18~url_dscp~~size~218093~name~7nQ2t-de3sZlT3cSlc-w0.jpg~tmp_file~./temp_attachments/7nQ2t-de3s.jpg.tmp~w~768~h~1152~tmp_shoot~./temp_attachments/7nQ2t-de3s.jpg.tmp~tmp_shoot_size~124647~tmp_shoot_ext~jpg~isimg~1~thumb~120 attachments_check: fd9a4034fe53664a801d79a2dbd9f5c4 nojump: 1lite: htmljsstep: 2这是同时提交两张图片的情况： 1234567891011action: replyfid: 275tid: 38719308post_content: [img]./mon_202403/18/7nQ2t-529pZlT3cSlc-w0.jpg[/img][img]./mon_202403/18/7nQ2t-7v3oZlT3cSlc-w0.jpg[/img]attachments: aid~7nQ2t-529p~ext~jpg~url_utf8_org_name~00737%2d2622116886%2dfeaturelessMix%5fv30202312%2epng~path~mon_202403/18~url_dscp~~size~218093~name~7nQ2t-529pZlT3cSlc-w0.jpg~tmp_file~./temp_attachments/7nQ2t-529p.jpg.tmp~w~768~h~1152~tmp_shoot~./temp_attachments/7nQ2t-529p.jpg.tmp~tmp_shoot_size~124647~tmp_shoot_ext~jpg~isimg~1~thumb~120 aid~7nQ2t-7v3o~ext~jpg~url_utf8_org_name~00737%2d2622116886%2dfeaturelessMix%5fv30202312%2epng~path~mon_202403/18~url_dscp~~size~218093~name~7nQ2t-7v3oZlT3cSlc-w0.jpg~tmp_file~./temp_attachments/7nQ2t-7v3o.jpg.tmp~w~768~h~1152~tmp_shoot~./temp_attachments/7nQ2t-7v3o.jpg.tmp~tmp_shoot_size~124647~tmp_shoot_ext~jpg~isimg~1~thumb~120 attachments_check: 11e98d076d3a6793a4128a1ac62baa51 c593cf08e0b0e1765b727342fcf3f7de nojump: 1lite: htmljsstep: 2 可以看到 图片的 attachments 之间并没有使用分号啊逗号啊什么的隔开，只是换行和空格。 2024-03-19 更正：应该是使用 \\t 进行分割，而不是使用回车或者空格，这在文档里面写出来了。 总结完成了，不复杂的一套流程。 整体来说： 调用 data_dict_get() 函数，从 api 获取 bilibili 的动态信息，筛选没有转发过的。在 github action 可以表现为每五分钟检测上一个五分钟内的新动态（由于github action每个月份额有限，改成半小时） 从调到的字典数据中获取 data_list，即存放动态内容数据的列表 考虑到半小时内可能会有多条动态，而 nga 会有 10 秒发帖时间间隔，使用一个循环依次发送帖子（绝大多数情况下只有一个） 对于每一个的动态，根据时间戳判断是否是已经发送过；也可以将文件保存到本地，对比新旧文件的差别，判断哪些动态没有被发送过 调用 generate_post(data)，其中 data 是单条动态的数据。 根据 api 回传的信息结构，分析出网页直观看到的内容、tag、图片、视频，并转化为 nga 对应的 bbscode。 标题使用讯飞星火的 api 进行生成（因为原动态总是不写标题） 图片使用 upload_img() 上传，这个函数接受的参数是一个列表，里面记录每张图的网址，因为一条动态可以有很多图片。使用 upload_one_img() 上传单个图片，使用 post_img() 上传图片，回传生成的图片 url、attachments、attachments_check 视频使用 flash=video 标签，不过不同客户端有的可能看不到。 一大问题是，有的动态是专栏文章的缩略，只会有一小段内容，然后是 “展开”，对应一个全新的页面。这种情况下的转发我还没弄明白应该怎么做。 结束之后，根据发送的帖子数量输出对应的内容。 二哥的代码、文档其实写得很清晰，井井有条。拜他所赐，我这个半吊子也能大致理解上传图片所需要的东西。遇见过的几个问题全是可以通过看文档快速解决的。","categories":[],"tags":[]},{"title":"2024年2月26日","slug":"2024年2月26日","date":"2024-02-26T11:40:12.000Z","updated":"2024-03-09T08:07:51.401Z","comments":true,"path":"2024/02/26/2024年2月26日/","link":"","permalink":"http://blog.wspdwzh.space/2024/02/26/2024%E5%B9%B42%E6%9C%8826%E6%97%A5/","excerpt":"","text":"又开学了。时间真快。 需要开始准备考研的基础复习了：数学，英语，专业课；四门课里面只有政治可以晚一点开始。 实习我认为我需要、且必需实习经历。 学校安排的那个实验课一样的实习不算。 一来是需要是成都本地：实习需要三个月以上，我希望能协调时间，不耽误学业。 二是它得要我。最现实的问题。这就涉及到我的专业水平、厂商要求门槛、以及是否对口。 投递简历的话，大厂或许成功概率比较低，小厂也可以考虑。 大厂目前正在考虑： 字节跳动：成都有不少岗位，正在考虑。 阿里巴巴集团：集中于北京、杭州，成都的极少（例如，钉钉只有一个“线上服务运营”岗位在成都）。淘宝招聘链接 腾讯：在成都有，但是希望渺茫。按照我这个水平来说的话。 京东：按照 https://www.zhihu.com/question/640513578 的回答，京东也是一个选项。不过，文中的专业方向虽然是电子信息，但本人是大数据方向，学习了java，数据库等等知识。 vivo：发了招聘通知，但是在成都本地没有岗位，且是计算机/互联网方向，不考虑。 御坂网络：之前发布过招聘通知，计算机后端方向，一是不对口二是已经过期，不考虑。 招聘相关举个例子，十四所的全部都是要求硕士及以上，来校招也是招本科生读研、招研究生和博士生工作。 学历低的本科生社招很难办，如果实在想要本科就业，只能通过校招进入企业。（秋招，春招两个批次，挨不上那就做好失去应届生资格的准备吧） 调剂研究所同样很困难：按照研途考研的说法，他们统计的调剂成功率只有10%上下，经过他们安排、策划调剂成功的也堪堪30%上下，堪比考研上岸比例。 电子信息工程就业相关","categories":[],"tags":[]},{"title":"转发机器人思路","slug":"交错战线相关","date":"2024-01-17T10:05:28.000Z","updated":"2024-03-09T07:59:56.344Z","comments":true,"path":"2024/01/17/交错战线相关/","link":"","permalink":"http://blog.wspdwzh.space/2024/01/17/%E4%BA%A4%E9%94%99%E6%88%98%E7%BA%BF%E7%9B%B8%E5%85%B3/","excerpt":"","text":"定时发饼思路继承之前方舟饼搬运思路，使用github的workflow实现免费的定时执行python程序；程序功能如下： 通过api获取官方动态，原始形式为json 进行筛选： 不需要已经搬运过的动态 不需要动态抽奖动态 论坛帖子发布： 设置action为new 设置对应fid（上线游戏讨论区）、stid（交错战线板块）。 更新 “ 已发布 ” 动态列表 在github的action部署注意requests库并不是python自带的、urllib和json是自带的；如果在requirements中写上了已经自带的库，那么会出现错误 注意隐私（Cookie）的保护 注意定时执行是按照UTC（国际标准时间）来的，换算成北京时间需要增加8小时 改进在此之前，“ 已发布 ” 动态列表是直接存储原始json文件。如果改为 “ 最后动态时间 ”，则可以大幅减少所需操作量。但是，仍然需要对仓库具有访问、修改的权限。 api获取的时间为时间戳，即形如1422979200000形式的int数据，可以较为方便的存储、对比。 当然，也可以使用目前时间戳和获取到的时间戳进行对比，判断是否是“上一次获取”之后的新动态。这样可以规避push操作。 api中获取的时间戳为pub_ts，精确到秒。在modules底下的module_author底下的avatar底下。 难点“ 已发布 ” 动态列表的更新： 是使用了github action，而不是在本地或服务器上运行，因此要想更改文件（存有json或者时间戳），需要有访问并更改本仓库内容的权限。","categories":[],"tags":[]},{"title":"nginx反代服务器的部署","slug":"nginx反代服务器的部署","date":"2023-10-18T15:39:11.000Z","updated":"2023-10-18T15:52:25.430Z","comments":true,"path":"2023/10/18/nginx反代服务器的部署/","link":"","permalink":"http://blog.wspdwzh.space/2023/10/18/nginx%E5%8F%8D%E4%BB%A3%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E9%83%A8%E7%BD%B2/","excerpt":"","text":"django 的 runserver 仅仅是用于测试，正式部署还是需要正经的服务器软件，例如 apache，nginx。如果不正式部署，服务可能会不稳定，且无法通过 80、443 等端口通信，而且处理并发问题和异常处理也可能会出问题。另外，静态文件也是需要交给服务器软件掌管，django 并没有提供可靠的相应的组件。总之就是，专业的事情，还是要交给专业的软件完成。 基本结构我选择的是 nginx，配合 uwsgi 作为中转，正式部署我 django 的程序。 三者形成一个链条结构，django 的信息被 uwsgi 接受，通过特定端口转发；通过这个特定端口，nginx 会接受 uwsgi 的信息，配合静态文件进行渲染网页的等操作，并向 80 或 443 传递最终的响应。 django 的配置和我之前所述项目一样，django 起到一个简化前后端编写的作用，实际 python 代码量并不多，但能起到大量 php 代码才能起到的作用。 首先就是收集静态文件， django collectstatic。这条指令会将所有需要的静态文件收集到一个文件夹下，即 settings.py 文件中，的 STATIC_ROOT 变量。注意，这里只能用 STATIC_ROOT 而不是 STATICFILE_DIRS 变量，当然如果手动收集，那其实无所谓。 uwsgi 的配置创建一个简单的 ini 配置文件，配置中转端口、并发数。 nginx 的配置很重要的一点是，默认的配置文件由两部分，一部分是外层，在 /etc/nginx/ 下，是 nginx.conf；另一部分是内层，在 /etc/nginx/sites_enabled/ 下。 外层中，可以设置 nginx 用户，如果权限不够，在查找静态文件的时候会报 403 错误，这个问题着实困扰了我很久很久！！ 内层就是进行一些琐碎的配置，但不多，也就一百行以内。比如说端口，静态文件位置，比如说 ssl 会用到的证书存放位置，这些。 总结很简单的一个小项目，但是被我死磕了一周，捏麻的。 话说我个硬件人怎么会跑来搞服务器部署？？？","categories":[],"tags":[]},{"title":"语音测评网站项目总结","slug":"语音测评网站项目总结","date":"2023-09-20T08:48:16.000Z","updated":"2023-09-20T11:50:37.097Z","comments":true,"path":"2023/09/20/语音测评网站项目总结/","link":"","permalink":"http://blog.wspdwzh.space/2023/09/20/%E8%AF%AD%E9%9F%B3%E6%B5%8B%E8%AF%84%E7%BD%91%E7%AB%99%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/","excerpt":"","text":"整体使用 django，配合 mysql 搭建的数据库、单独运行的测评打分模型，放在同一台服务器上跑。 django 前后端django 有 app 的概念，一个 app 里不同文件需要配置。主要是 admin, urls, models, views。而项目的文件在 app 之间共享，需要配置的工程文件有 settings, urls。 另外，还有 statics 静态文件，templates 网页模板等。 setting 的配置我使用了 ssl 来使用 https，否则会因为浏览器安全设置，无法上传音频。 要想使用 https，需要购买 ssl 证书，并和域名绑定，可以跟随阿里云的教程一步一步来。 123456789# SECURITY安全设置 - 支持http时建议开启SECURE_PROXY_SSL_HEADER = (&quot;HTTP_X_FORWARDED_PROTO&quot;, &quot;https&quot;)SECURE_SSL_REDIRECT = True # 将所有非SSL请求永久重定向到SSLSESSION_COOKIE_SECURE = True # 仅通过https传输cookieCSRF_COOKIE_SECURE = True # 仅通过https传输cookieSECURE_HSTS_INCLUDE_SUBDOMAINS = True # 严格要求使用https协议传输SECURE_HSTS_PRELOAD = True # HSTS为SECURE_HSTS_SECONDS = 60SECURE_CONTENT_TYPE_NOSNIFF = True # 防止浏览器猜测资产的内容类型 我使用了 django 提供的登录管理（因为我懒的一匹不想管那些细节）。 要想使用，需要在 templates 中给出对应模板（我后面会细说）。AUTHENTICATION_BACKENDS 是设置需要使用的验证后端。 AUTH_USER_MODEL 是用于存储学生身份信息的数据库，和models中的类对应。 AUTH_PASSWORD_VALIDATORS 用于验证修改密码的时候，密码的强度，如果太弱了就会被要求重新输入。 123456789101112131415161718192021222324252627282930313233LOGIN_REDIRECT_URL = &#x27;/profile/&#x27; # 给出登录成功之后的跳转目标LOGIN_URL = &#x27;&#x27; # 如果不设置这个，登录时会跳转到accounts/login/?next=/去,操AUTHENTICATION_BACKENDS =[ &#x27;rest_framework.authentication.TokenAuthentication&#x27;, &#x27;django.contrib.auth.backends.AllowAllUsersModelBackend&#x27;,]REST_FRAMEWORK = &#123; &#x27;DEFAULT_AUTHENTICATION_CLASSES&#x27;: [ &#x27;rest_framework.authentication.BasicAuthentication&#x27;, &#x27;rest_framework.authentication.SessionAuthentication&#x27;, &#x27;rest_framework.authentication.TokenAuthentication&#x27;, &#x27;rest_framework_simplejwt.authentication.JWTAuthentication&#x27;, ], &#x27;DEFAULT_PAGINATION_CLASS&#x27;: &#x27;rest_framework.pagination.PageNumberPagination&#x27;, &#x27;PAGE_SIZE&#x27;: 2&#125;AUTH_USER_MODEL = &#x27;project_app.stu_info&#x27;AUTH_PASSWORD_VALIDATORS = [ &#123; &quot;NAME&quot;: &quot;django.contrib.auth.password_validation.UserAttributeSimilarityValidator&quot;, &#125;, &#123;&quot;NAME&quot;: &quot;django.contrib.auth.password_validation.MinimumLengthValidator&quot;, &#125;, &#123;&quot;NAME&quot;: &quot;django.contrib.auth.password_validation.CommonPasswordValidator&quot;, &#125;, &#123;&quot;NAME&quot;: &quot;django.contrib.auth.password_validation.NumericPasswordValidator&quot;, &#125;,] DEBUG 模式的开关，DEBUG 模式下，很多地方与正式环境不同，例如最让我头痛的静态文件。DEBUG模式下，程序会自己寻找静态文件自己用，但是正式环境不会。12# SECURITY WARNING: don&#x27;t run with debug turned on in production!DEBUG = True 允许从哪一个host访问。例如，如果域名是 114514.com，那么需要在这里设置 ALLOWED_HOSTS = [‘114514.com’]1ALLOWED_HOSTS = [ ] INSTALLED_APPS 配置已安装的 app，包括你写的，也包括django给出、需要使用的。12345678910111213141516# Application definitionINSTALLED_APPS = [ &quot;project_app&quot;, # &#x27;project_app.ProjectNLPAppConfig&#x27;, &quot;django.contrib.admin&quot;, &quot;django.contrib.auth&quot;, &quot;django.contrib.contenttypes&quot;, &quot;django.contrib.sessions&quot;, &quot;django.contrib.messages&quot;, &quot;django.contrib.staticfiles&quot;, # 用于管理静态文件 &quot;django.contrib.sites&quot;, &quot;django.contrib.redirects&quot;, &quot;sslserver&quot;, &#x27;rest_framework&#x27;,] 如果不设置 SITE_ID，可能会产生 502 错误。1SITE_ID = 1 所谓中间件，中间件是 Django 请求/响应处理的钩子框架。它是一个轻量级的、低级的“插件”系统，用于全局改变 Django 的输入或输出。 每个中间件组件负责做一些特定的功能。例如，Django 包含一个中间件组件 AuthenticationMiddleware，它使用会话将用户与请求关联起来。 他的文档解释了中间件是如何工作的，如何激活中间件，以及如何编写自己的中间件。Django 具有一些内置的中间件，你可以直接使用。它们被记录在 built-in middleware reference 中。 ————来自 django 官方文档。12345678910MIDDLEWARE = [ &quot;django.middleware.security.SecurityMiddleware&quot;, &quot;django.contrib.sessions.middleware.SessionMiddleware&quot;, &quot;django.middleware.common.CommonMiddleware&quot;, &quot;django.middleware.csrf.CsrfViewMiddleware&quot;, # &quot;django.middleware.csrf.CsrfResponseMiddleware&quot;, &quot;django.contrib.auth.middleware.AuthenticationMiddleware&quot;, &quot;django.contrib.messages.middleware.MessageMiddleware&quot;, &quot;django.middleware.clickjacking.XFrameOptionsMiddleware&quot;,] 字面含义，是否每次请求都更新一次session，设置session使用的引擎。123SESSION_SAVE_EVERY_REQUEST = TrueSESSION_ENGINE = &#x27;django.contrib.sessions.backends.signed_cookies&#x27; # 引擎,加密 对网页模板的一些配置，会自动生成。1234567891011121314151617181920# 模板TEMPLATES = [ &#123; &quot;BACKEND&quot;: &quot;django.template.backends.django.DjangoTemplates&quot;, &quot;DIRS&quot;: [ os.path.join(BASE_DIR, &#x27;templates&#x27;), ], &quot;APP_DIRS&quot;: True, &quot;OPTIONS&quot;: &#123; &quot;context_processors&quot;: [ &quot;django.template.context_processors.debug&quot;, &quot;django.template.context_processors.request&quot;, &quot;django.contrib.auth.context_processors.auth&quot;, &quot;django.contrib.messages.context_processors.messages&quot;, &quot;django.template.context_processors.static&quot;, ], # &quot;builtins&quot;:[&quot;django.templatetags.static&quot;],# 让模板不需要手动添加static &#125;, &#125;,]数据库的配置，设置种类帐号密码ip端口。12345678910DATABASES = &#123; &#x27;default&#x27;: &#123; &#x27;ENGINE&#x27;: &#x27;django.db.backends.mysql&#x27;, &#x27;NAME&#x27;: &#x27;exam&#x27;, &#x27;USER&#x27;: &#x27;root&#x27;, &#x27;PASSWORD&#x27;: &#x27;123123&#x27;, &#x27;HOST&#x27;: &#x27;127.0.0.1&#x27;, &#x27;PORT&#x27;: 3306 &#125;&#125; 语言和时区，注意时区很重要，默认并不是使用电脑的时区，而是使用芝加哥时区；这个配置甚至没有在 settings 里默认生成。123456789LANGUAGE_CODE = &quot;en-us&quot;# TIME_ZONE = &quot;UTC&quot;USE_TZ = FalseTIME_ZONE = &#x27;Asia/Shanghai&#x27;USE_I18N = True# 多語言静态文件相关的一些设置，指引 django 应该去哪里寻找静态文件。 总之就是我到现在还没摸透，能跑就行，捏马的。1234567STATIC_URL = &quot;/static/&quot; # 不需要拼接前面的路径,这边的事相对路径STATIC_ROOT = os.path.join(BASE_DIR, &#x27;static&#x27;)STATICFILES_FINDERS = [&#x27;django.contrib.staticfiles.finders.FileSystemFinder&#x27;, &#x27;django.contrib.staticfiles.finders.AppDirectoriesFinder&#x27;, ] urls 的设置urls 其实可以有多个，工程一个，每个app一个。 urls.py 中，重点设置的只有 urlpatterns 这个列表： 123456urlpatterns = [ path(&quot;admin/&quot;, admin.site.urls), path(&quot;favicon.ico&quot;, RedirectView.as_view(url=staticfiles_storage.url(&quot;favicon.ico&quot;)),), url(&quot;&quot;, include(&#x27;project_app.urls&#x27;)), # path(&#x27;api-auth/&#x27;, include(&#x27;rest_framework.urls&#x27;))] 如上所示， `path(&quot;admin/&quot;, admin.site.urls)`：设置管理员后台。 `path(&quot;favicon.ico&quot;, RedirectView.as_view(url=staticfiles_storage.url(&quot;favicon.ico&quot;)),)`：设置网站图标。 `url(&quot;&quot;, include(&#39;project_app.urls&#39;)),`：将 app 的 urls 拼接到自己后面。 App 中 models 的设置models 是 django 和数据库的对接，里面的每一个类都对应一张表单。 未完待续 App 中 views 的设置这是重头戏，前端的呈现和逻辑都在这里完成。 未完待续 statics 和 templates网页模板，本质是在 html 中插入形如 &#123;&#123; for i in list &#125;&#125;、&#123;% static \"asd/asd/asd\" %&#125; 之类的模板语法，通过 django 的 render（渲染）函数，配合传递的参数，生成一个标准 html 页面。 传递的参数是一个字典，组织方式类似于变量和值的一一对应；其中的变量可以是绝大多数 python 支持的变量，但似乎不支持自己定义的类。 未完待续 数据库由 models 定义绝大多数使用到的表单，包括但不限于成绩存储，学生帐号信息，题库。 表单的定义未完待续 初始化未完待续 中途调整未完待续 在 views.py 中增删查改（访问）数据未完待续 总结未完待续 打分测评模型另一位同学负责的部分，具体表现为一个时刻监控数据库的神经网络模型程序。 django 完成一次测评，向一张表单中写入测评数据；打分模型检测到表单新增数据，则会自动处理。处理完成后，会向该学生对应的表中写入数据，如果表不存在，则创建表格。 输出的分数有两种情况，视题型而定，可能是单个分数，可能是四个分数。 前端读取到数据时会判断题型，在计算均分时，会对只有一个分数的题型特殊处理。 未完待续 部署通过 https 方式启动 django 的大致指令：1python3 ./project/manage.py runsslserver 0.0.0.0:8000 --certificate /etc/apache2/ssl/xxx.com.crt --key /etc/apache2/ssl/xxx.com.key 如果是 DEBUG 状态，可以加入 --no-static 参数。 0.0.0.0:8000 是广播的目标地址，意思是对所有 ip 通过 8000 端口广播。值得注意的是，如果改为 443，80 等https，http默认端口，则会和本地服务器程序冲突。要想通过 443、80 广播，应当使用 nginx 之类的反向代理应用。 --certificate 和 --key 都是 ssl 所需参数。 总结未完待续","categories":[],"tags":[]},{"title":"Django 学习","slug":"2023年8月10日","date":"2023-08-10T14:45:07.000Z","updated":"2023-08-16T07:53:35.503Z","comments":true,"path":"2023/08/10/2023年8月10日/","link":"","permalink":"http://blog.wspdwzh.space/2023/08/10/2023%E5%B9%B48%E6%9C%8810%E6%97%A5/","excerpt":"","text":"正在学习 Django，和半吊子 mysql。 顺便练习键盘盲打……之前一直是一指禅野路子，现在眼睛也离不开键盘。 命令行里面使用就是 django-admin，注意不是django。python包是django （正在看网课 前端+MySQL+Django） 顺带一提，Windows快速切换桌面是 win+ctrl+方向 各个文件分工asgi 和 wsgi涉及请求，一个同步一个异步，一般来说不需要更改。 urls对应python函数和网站的url，使用比较频繁。 假设有一个 app 名为 sims，那么，在外层的 urls 中， url 和文件是这样对应的：12345678from django.contrib import adminfrom django.urls import pathfrom django.conf.urls import url, includeurlpatterns = [ path(&#x27;admin/&#x27;, admin.site.urls), url(r&#x27;^sims/&#x27;, include(&#x27;sims.urls&#x27;))]也就是使用 urlpatterns 这个列表，里面的 path 和 url 方法来进行对应。其中，path 只管 admin，其他都是 url 来的。urls 后面接 include， 在 app ，即 sims 内层，urls.py 是这样对应的： 12345678910# coding=utf-8from django.conf.urls import urlfrom . import viewsurlpatterns = [ url(r&#x27;^$&#x27;, views.index), url(r&#x27;^add/$&#x27;, views.add), url(r&#x27;^edit/$&#x27;, views.edit), url(r&#x27;^delete/$&#x27;, views.delete)] 首先需要导入 app 里面的 settings配置文件，需要连接数据库，注册app，等等操作。 initmanage和其他的不在一起，在外面。 最常用的文件。 APP的概念大型项目中的某些功能。不同app可以拥有独立的表结构，html模板，css，不会相互影响。 但是一般来说多app的项目就是比较复杂的了。 可以通过 python manage.py startapp app01 这种形式来创建应用。新应用回合项目本体一样有自己的文件夹。 apps不需要更改 tests单元测试用的 views用于和 urls.py 里面的函数对应，所谓视图函数。 models专门操作数据库，使用orm，可以取代pymysql。 admin默认提供后台管理功能，一般不使用。 主要就是 views 和 models 这两个基本使用步骤 首先需要创建并注册 app：在setting的installed_apps这个列表里面注册，具体来说就是添加字符串，内容为形如 app01.apps.app01config 之类的类，这个类里面应该包含 app01 所需要的注册信息。 然后编写一个 urls 和 apps 的对应关系：编写 urls 文件。 然后编写一个视图函数 views，需要有一个函数 （例如index），这个函数 index 必须有一个参数 request 。这个函数中，可以使用httpresponse()之类的方法返回文字信息，也可以通过更加复杂的方法返回其他信息。 启动 django 程序：使用 python manage.py runserver 总结一下就是一般网站配置 urls 和 views 即可，如果需要访问数据库则需要 models。每一个 url 可以对应一个函数。 模板，和静态文件templates 模板的使用： views文件的函数返回render()，参数为request和html模板文件名，例如return render(request,”asd.html”) 其中，默认情况下，程序会在app的templates目录下寻找html模板文件。如果setting里面配置了TEMPLATES里面的DIRS，则会改变。 静态文件：例如CSS，图片，js静态文件放在app 目录底下的 static 文件夹底下 一般来说， static 文件夹底下还会有css，img，plungins，js等等细分文件，方便管理 注意少使用绝对路径，可以使用 { % load static % } 之类的 #","categories":[],"tags":[]},{"title":"VITS 论文阅读-3","slug":"VITS-论文阅读-3","date":"2023-06-14T15:49:51.000Z","updated":"2023-06-14T16:58:42.498Z","comments":true,"path":"2023/06/14/VITS-论文阅读-3/","link":"","permalink":"http://blog.wspdwzh.space/2023/06/14/VITS-%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-3/","excerpt":"","text":"VITS 本质是一个以最大化变分下界为目标的条件VAE. 这个变分下界表达式为 \\log p_{\\theta}(x \\mid c) \\geq \\mathbb{E}_{q_{\\phi}(z \\mid x)}\\left[\\log p_{\\theta}(x \\mid z)-\\log \\frac{q_{\\phi}(z \\mid x)}{p_{\\theta}(z \\mid c)}\\right]={似然函数}[log{数据点 x 的似然函数} - log({近似后验分布} / {条件c下潜变量z的先验分布})] 条件VAE公式（a conditional VAE formulation） 目标:”变分下界”，证据下界（ELBO） 重建损失 KL收敛 基于变分推理的对准估计（alignment estimation derived from variational inference）- 提高合成质量的对抗性训练（adversarial training for improving synthesis quality） 总损失函数是各个损失函数相加. 条件VAE公式输入语料 $x_{mel}$ ，提取 x 的 mel 频谱(梅尔语谱图, 用于音频处理). (人耳对频率的感受是对数的(logarithmic), 因此不能线性处理, 需要梅尔语谱图) 通过解码器将潜在变量 z 上采样, 转到波形域 $\\hat{y}$.将 $\\hat{y}$ 变换到 mel 频谱 $\\hat{x}_{mel}$ . 对比 $x{mel}$ 和 $\\hat{x}{mel}$ ,差值就是重建损失. 这个重建损失可以看作一个拉普拉斯分布, 但这个估计不需要可训练的参数，因为它只使用 STFT(短时傅立叶变换) 和线性投影到 mel 标度上; 估计仅在训练期间使用，推理不需要. 重建损失需要求一个变分下界, \\mathbb{E}_{q_{\\phi}(z \\mid x)}\\left[\\log p_{\\theta}(x \\mid z)-\\log \\frac{q_{\\phi}(z \\mid x)}{p_{\\theta}(z \\mid c)}\\right]训练需要保证这个下界最大. 先验编码器 c 的输入条件, 由 从文本中提取的音素$c_{text}$, 和 音素与潜在变量之间的对齐 A 组成。 变分推理的对准估计对抗性训练训练过程有 $x_{mel}$ , 有潜变量 z, 可以得到重建损失.","categories":[],"tags":[]},{"title":"VITS 论文阅读-2","slug":"VITS-论文阅读-2","date":"2023-06-14T07:53:57.000Z","updated":"2023-06-25T14:56:53.744Z","comments":true,"path":"2023/06/14/VITS-论文阅读-2/","link":"","permalink":"http://blog.wspdwzh.space/2023/06/14/VITS-%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-2/","excerpt":"","text":"方法所提出的方法主要在前三小节中描述： 条件VAE公式（a conditional VAE formulation） 基于变分推理的对准估计（alignment estimation derived from variational inference） 提高合成质量的对抗性训练（adversarial training for improving synthesis quality） 图1a和1b分别显示了我们方法的训练和推理过程。从现在起，我们将把我们的方法称为端到端文本到语音（VITS），具有对抗性学习的变分推理。 训练和推理流程如下： 条件推理（conditional inference）条件VAE公式（a conditional VAE formulation）。 目标为一个”变分下界”，也叫证据下界（ELBO）。详细说就是“intractable marginal log-likelihood ”棘手边缘拟合对数似然的变分下界。 如图，$\\log p{\\theta}(x \\mid c)$的变分下界为$\\mathbb{E}{q{\\phi}(z \\mid x)}\\left[\\log p{\\theta}(x \\mid z)-\\log \\frac{q{\\phi}(z \\mid x)}{p{\\theta}(z \\mid c)}\\right]$。 L_{\\text {recon }}=\\left\\|x_{mel}-\\hat{x}_{mel}\\right\\|_{1}下界：似然【数据点x的似然函数 - （近似后验分布 / 条件c下潜变量z的先验分布）的对数】 训练损失即负的ELBO。 也可以看作为重建损失 + KL散度，这在潜变量z服从近似后验分布时成立。 重建损失作为重建损失中的目标数据点，我们使用mel频谱图而不是原始波形，由 $x{mel}$ 表示。我们通过解码器将潜在变量z上采样到波形域 $\\hat{y}$ ，并将 $\\hat{y}$ 变换到融合谱图域 $\\hat{x}{mel}$ 。然后，预测的和目标mel谱图之间的L1损失被用作重建损失： L_{\\text {recon }}=\\left\\|x_{mel}-\\hat{x}_{mel}\\right\\|_{1}这可以被视为假设数据分布的拉普拉斯分布并忽略常数项的最大似然估计。我们定义了mel声谱图域中的重建损失，以通过使用近似人类听觉系统响应的mel标度来提高感知质量。注意，根据原始波形的mel谱图估计不需要可训练的参数，因为它只使用STFT和线性投影到mel标度上。此外，估计仅在训练期间使用，而不是推理。 在实践中，我们不对整个潜在变量z进行上采样，而是使用部分序列作为解码器的输入，这是用于高效端到端训练的窗口生成器训练。 KL收敛先验编码器c的输入条件由从文本中提取的音素$c_{text}$和音素与潜在变量之间的对齐 A 组成。 对齐是一个硬单调注意力矩阵，其$\\mid c_{text}\\mid \\times \\mid z\\mid$维度表示每个输入音素扩展到与目标语音时间对齐的长度。由于对齐没有基本事实标签，我们必须在每次训练迭代时估计对齐。 在我们的问题设置中，我们的目标是为后验编码器提供更多的高分辨率信息。因此，我们使用目标语音$x_{lin}$的线性尺度频谱图作为输入，而不是mel频谱图。注意，修改后的输入并不违反变分推理的性质。那么KL分歧是： “因子分解正态分布”用于参数化我们的先验和后验编码器。 我们发现，增加先验分布的表现力对于生成真实样本很重要。因此，我们应用归一化流 f ，该流允许在因子分解的正态先验分布之上，根据变量变化规则，将简单分布可逆变换为更复杂的分布。 路线估计（Alignment Estimation）基于变分推理的对准估计（alignment estimation derived from variational inference）。 单调对齐搜索（MONOTONIC ALIGNMENT SEARCH）为了估计输入文本和目标语音之间的对齐A，我们采用单调对齐搜索（MAS）。 这是一种搜索对齐的方法，其最大化了由归一化流 f 参数化的数据的可能性。 因为人类按顺序阅读文本，不跳过任何单词，候选比对（ candidate alignments）被限制为单调且不跳过。 为了找到最佳对准，Kim等人（2020）使用动态规划。在我们的这个情况下直接应用MAS是困难的，因为我们的目标是ELBO，而不是确切的对数似然。因此，我们重新定义MAS，以找到最大化ELBO的对齐。 这个过程简化为找到最大化潜在变量z的对数似然的对齐。 但事实上，无论修不修改，都可以工作。因此我们使用的是原始MAS。 文本时长预测器（DURATION PREDICTION FROM TEXT）我们可以通过对估计的对齐$\\sum{j}^{} A{i,j}$的每行中的所有列求和来计算每个输入token$d_i$的持续时间。但持续时间可以用来训练确定性的持续时间预测器，但它不能表达一个人每次以不同的语速说话的方式。 为了生成类似人类的语音节奏，我们设计了一个随机持续时间预测器，使其样本遵循给定音素的持续时间分布。 随机持续时间预测器是一种基于流的生成模型，通常通过最大似然估计进行训练。然而，最大似然估计的直接应用是困难的，因为每个输入音素的持续时间是 1）离散整数，其需要被去量化（dequantized）以使用连续归一化流。 2）标量，其由于可逆性而无法进行高维变换。 我们应用变分去量化和变分数据扩充来解决这些问题。 具体地说，我们引入了两个随机变量 u 和 v ，它们具有与持续时间序列 d 相同的时间分辨率和维度，分别用于变分去方程化和变分数据扩充。 我们将u的支持度限制为[0, 1），使得差$d-v$变成了一个正实数序列。 我们按通道连接 v 和 d ，以生成更高维的潜在表示。、 我们通过近似后验分布$q(u,v|d,c{text})$对这两个变量进行采样。由此产生的目标是音素持续时间的对数似然的变分下界。训练损失$L{dur}$是负变分下界。 我们将阻止输入梯度反向传播的”停止梯度算子”应用于输入s，保证持续时间预测器的训练不会影响其他模块的训练。 而取样程序相对简单：通过随机持续时间预测器的逆变换，从随机噪声中采样音素持续时间，然后将其转换为整数。 对抗训练提高合成质量的对抗性训练（ adversarial training for improving synthesis quality）。 为了在我们的学习系统中采用对抗性训练，我们添加了一个鉴别器D，用于区分解码器G生成的输出和实际的波形y。 在这项工作中，我们使用了两种成功应用于语音合成的损失类型：一种是对抗性训练的最小二乘损失函数，另一种是训练生成器的附加特征匹配损失。 T表示鉴别器中的层的总数，并且$D^{l}$输出具有$N_{l}$个特征的鉴别器的第l层的特征图。 值得注意的是，特征匹配损失可以被视为在鉴别器的隐藏层中测量的重建损失，该重建损失被建议作为VAE的逐元素重建损失的替代方案。 最终的损失函数所有损失函数直接相加。 模型架构总体架构由后验编码器、先验编码器、解码器、鉴别器和随机持续时间预测器组成。后验编码器和鉴别器仅用于训练，而不用于推理。 后验编码器对于后验编码器，我们使用WaveGlow和Glow-TTS中使用的非因果WaveNet残差块, “the non-causal WaveNet residual blocks”。 WaveNet残差块由具有多个扩张卷积层（ dilated convolutions ），每层含有门控激活单元（gated activation unit）和跳跃连接（ skip connection）。块上方的线性投影层产生正态后验分布的均值和方差。 对于多个说话人的情况，我们在残差块中使用全局条件反射（global conditioning）来添加说话人embedding。 先验编码器先验编码器包括处理输入音素$c_{text}$的文本编码器、改进先验分布的灵活性的归一化流 f 。 文本编码器是一种transformer编码器（transformer encoder），它使用相对位置表示（relative positional representation）而不是绝对位置编码（absolute positional encoding）。 我们可以通过文本编码器和文本编码器上方的线性投影层，从 $c{text}$ 中获得 hidden representation $h{text}$ ，该线性投影层产生用于构建先验分布的均值和方差。 归一化流(normalizing flow)是仿射耦合层（affine coupling layers）堆积而成，包含 WaveNet 残差块的堆栈。为了简单起见，我们将归一化流设计为雅可比行列式为1的保体积变换（a volume-preserving transformation with the Jacobian determinant of one）。 这个变换来自于 GLOW. https://arxiv.org/abs/1807.03039 对于多说话人设置，我们通过全局条件，将说话人embedding加入到归一化流中的残差块中。 解码器解码器本质上是HiFi GAN V1生成器。它由”反条件姿态卷积”堆积组成，每个卷积后面，都有一个多接收场融合模块（MRF）。 MRF的输出是具有不同感受野大小的残差块的输出之和。 对于多说话人设置，我们添加一个转换说话人embedding的线性层，并将其添加到输入潜在变量z中。 判别器我们遵循HiFi GAN中提出的多周期鉴别器的鉴别器架构。 多周期判别器是基于马尔可夫窗的子鉴别器的混合，每个子判别器对输入波形的不同周期模式进行操作。 随机持续时间预测器随机持续时间预测器根据条件输入的 $h_{text}$ 估计音素持续时间的分布。 为了有效地参数化随机持续时间预测器，我们将残差块，与扩张和深度可分离的卷积层叠加。我们还将神经样条流（neural spline flows）应用于耦合层，其通过使用单调有理二次样条（monotonic rational-quadratic splines）采用可逆非线性变换的形式。 与常用的仿射耦合层相比，神经样条流的参数相似数量，但提高了变换的表现力。 对于多说话人设置，我们添加了一个线性层来转换说话人embedding，并将其添加到输入 $h_{text}$ 中。 个人理解训练过程使用了： 后验编码器 先验编码器 解码器 鉴别器 随机持续时间预测器 也就是所有部件。 $x_{lin}$ 为线性频谱, 通过后验编码器, flow, 解码器, 输出预测的原始波形 $\\hat{y}$ . $c{text}$ 为从文本中提取的音素, 通过文本编码器得到 $h{text}$ , 投影到 z 所服从的正态分布, 正态分布的两个参数是 $\\mu{\\theta}$ 和 $\\sigma{\\theta}$ . 然后使用单调对齐搜索( MAS )估计潜在变量之间的对齐 A ,最大化由归一化流 f 参数化的数据的可能性. 对齐 A 是一个硬单调注意力矩阵，其$\\mid c{text}\\mid \\times \\mid z\\mid$维度, 表示每个输入音素$c{text}$扩展到与目标语音时间对齐的长度。 核心的 flow 是一堆 z 和一堆对应的 $fz(z)$ .对于 $\\theta$ 层的 $z$, 服从的正态分布系数是 $\\mu{\\theta}$ 和 $\\sigma_{\\theta}$ , $f_{\\theta}(z)$ , 推理过程使用了： 先验编码器 解码器 随机持续时间预测器 也就是不使用后验编码器和判别器。 $c_{text}$ ，phoneme（音素），作为输入。 经过text encoder，文本编码器，和线性投影层，得到 $h_{text}$ ，hidden representation，和投影。 $h_{text}$ 使用随机时间预测器，逆变换，从随机噪声中提取持续时间。 取样程序：通过随机持续时间预测器的逆变换，从随机噪声中采样音素持续时间，然后将其转换为整数，得到向量 $d$ 。 然后投入先验编码器，先验编码器包括文本编码器和归一化流，文本编码器是一个transformer，归一化流进行估计，参数化对先验概率q的逼近。 涉及的论文与概念归一化流本质是一个生成模型。一个基于可能性的生成模型。 （自回归模型, 生成对抗网络(GAN)的一部分, 变分自动编码器（VAE）也是自回归模型。） Flow 将简单分布（易于采样和评估密度）映射到复杂分布（通过数据学习）。但是方便起见，实际使用时就是想办法得到一个encoder将输入x编码为隐变量z，并且使得z服从标准正态分布。 得益于flow模型的精巧设计，这个encoder是可逆的，从而我们可以立马从encoder写出相应的decoder（生成器）出来，因此，只要encoder训练完成，我们就能同时得到decoder，完成生成模型的构建。 x 和 z 应该有以下关系： 首先， $X=f(Z)$ ， $Z=f^{-1}(X)$ 。也就是说从 Z 映射到 X ，这个映射确定而可逆。 然后有： 变量变换定理(change of variable theorem): 有 $p_z(z)$ 和 $p_x(x)$ ,有 $f(z)=x$ ,如果要通过 $f$ 建立 $p_z(z)$ 和 $p_x(x)$ 之间的关系，可以将 $p_z(z)$ 和 $p_x(x)$ 使用微分方法借取一小段，直接计算一小段的体积，并对比，并按照体积的比例进行缩放，缩放函数在每个点上组合起来就是 $f(z)=x$ 。 p_x(x)=p_z(z) ( f^{-1}(x)) \\mid {det}( \\frac{\\partial f^{-1}(x)}{\\partial x} =p_z(z) ( f^{-1}(x)) \\mid {det}( \\frac{\\partial f(x)}{\\partial x}^{-1} ) \\mid其中，由于可逆矩阵 $det(A^{-1})=det(A)^{-1}$ 。因此对于 $z=f^{-1}(x)$ ，有： p_x(x)=p_z(z) \\mid {det}( \\frac{\\partial f(z)}{\\partial z} ) \\mid对于 $\\frac{\\partial f^{-1}(x)}{\\partial x}$ ，这是一个 n 维矩阵。这个矩阵记做雅可比矩阵。 保体积： $\\mid {det}( \\frac{\\partial f(z)}{\\partial z} ) \\mid =1$ ，则从 z 到 x 的映射是保体积的。换言之，变换后的 $p_x$ 和 原始的 $p_z$ 有同样的体积，或者说volume。 (体积指的就是行列式.) 流模型核心条件： 模型可逆 对应的雅可比行列式容易计算 因此本文将其设计为雅可比行列式为1的保体积变换（a volume-preserving transformation with the Jacobian determinant of one） 有“边界可能性” $p_x(x)$ ，满足 p_x(x;\\theta )=p_z(f_{\\theta }^{-1}(x)) \\mid {det}( \\frac{\\partial f_{\\theta }^{-1}(x)}{\\partial x} ) \\mid名称“归一化流”可以解释如下： “归一化”意味着变量的变化在应用可逆变换后给出归一化密度（normalized density）。 “流”意味着可逆变换可以相互组合，以创建更复杂的可逆变换。 存在多个隐变量 z, 存在对应数量的变换函数 f(z), 而最后一个 z 对应出来就是 x. 优化函数: logp_k(x^i)=logp_z(z^i)+\\sum_{h=1}^{K}log\\mid det(J_{G^{-1}})\\mid =logp_z(G^{-1}(x^i))+\\sum_{h=1}^{K}log\\mid det(J_{G^{-1}})\\mid这是 $G^{-1}$ 训练的目标: 最大化这个式子的值即可. 实际使用 G, 将其逆转即可. 平面流vits使用的流模型the non-causal WaveNet residual blocks used in WaveGlow (Prenger et al., 2019) and Glow-TTS (Kim et al., 2020).","categories":[],"tags":[]},{"title":"fpga 电梯项目","slug":"fpga-电梯项目","date":"2023-06-13T05:17:56.000Z","updated":"2023-06-13T07:20:34.254Z","comments":true,"path":"2023/06/13/fpga-电梯项目/","link":"","permalink":"http://blog.wspdwzh.space/2023/06/13/fpga-%E7%94%B5%E6%A2%AF%E9%A1%B9%E7%9B%AE/","excerpt":"","text":"累死我了。昨天下午到今天中午。 累不累不要紧，主要是这是期末复习周。分秒寸金的复习周。 吐槽两句调试：vivado，verilog的开发方式和其他语言不太一样。调试的话，要么仿真，要么建立一个debug core调试核，要么下板。一开始，觉得很快就能做完；觉得编写仿真文件，或者现学调试不合算，我选择直接下板。然后被这个反复下板浪费的时间折磨到了。 而且三阶段，一个是分析，一个是硬件，一个是比特流，每一项都花时间，每一项都走不开，不能像是“让程序慢慢跑，吃个饭先”之类的。 下次一定仿真。 暂时不要相信gpt的复杂代码水平基于python或c或go之类的几十行一两百行还好，这种复杂的程序真的是难为gpt这种泛用模型了。尤其是verilog还是个非主流语言。 而且，我这个项目，是网络上已经有不少现成的，gpt是将它们按照我的要求缝在了一起。有的地方缝错位了，有的地方不该缝的缝上了。还有有的地方我以为缝错了其实缝对了。导致修改花了绝大多数时间。 不过，要我自己从零写，不知道要花多少时间。我没这个时间也没这个精力再写一次。 遗憾：fpga开发板贵的一批。学校给了我使用的机会，但我没有珍惜。 下次一定。 基本架构有以下几个部分： top：顶层文件 key_debounce：按键消抖 matrix_key：矩阵键盘。实际使用四个键，属于是卵用没有，只能添乱。 switch_control：拨码开关控制（并输出floor查看运行状态） clk_div：理论有用但实际没用，全他妈用的是自己分频…………这个模块对我的唯一贡献，是给led_control模块塞了一个花了我好长时间的bug…… seg_control：控制数码管显示。大改过。 led_control：控制led和电梯上下楼，名副其实的灵魂模块。 beep_control：一个意义不明的模块，我不知道gpt本来是想做什么，反正它在我这里就是一个运行指示器。 top里面重要的reg： row行信号，设置为1110 一开始设的是0001，纳闷了好久。 几个led灯 key_in和key_out floor和floor_out floor是寄存器，作为模块输入，不能作为输出。 要改变floor的值，需要通过一个wire，floor_out来转接。 我在top里面加了一句always @(posedge clk) floor&lt;=floor_out; endmodule，用来将这两个直接相连。 模块介绍top：顶层文件模块例化，将floor_out和floor链接。 `timescale 1ns / 1ps不知道有没有用，总之加上就是了。之前因为这一句翻过车。 总之就是要把各个变量对应好，不要出现什么时钟频率错误，in和out变量错误什么的。 key_debounce：按键消抖基本原理是检测到按键按下，然后等20个时钟周期再看看，如果还是按下，那就真的按下了，输出按键信息。 switch_control：拨码开关控制（并输出floor查看运行状态）其实也是个没卵用的模块，把二位的led_status分割成一个rst一个start。我是不知道为什么我不在xdc里面直接定义rst和start……可能是闲得蛋疼。 但是我还是保留了，毕竟能正常工作，还能加点其他功能，不在其他模块碍眼。例如打印floor状态。 clk_div：理论有用但实际没用，全他妈用的是自己分频…………这个模块对我的唯一贡献，是给led_control模块塞了一个花了我好长时间的bug……字面意思，理论上应该用这个控制所有时钟分频，但是我的模块用分频的少，所以都自己分了。 seg_control：控制数码管显示。大改过。大改指的是把本来的全部注释掉然后重写。 主要是因为我改了matrix_key，没用，导致编码从8421变成了独热码。而且我的floor只有两位，按键四个，不需要那么复杂的东西。 两个数码管，交替选择，选择时显示内容。 如果不使用分频，会导致残影。理论上需要专门的方法去除，但是我懒狗，我是把频率降一下就当没看到残影。我是用的是1000hz。 led_control：控制led和电梯上下楼，名副其实的灵魂模块。首先是判断key_in，如果非零，那就说明按键按下。在这个情况下，需要根据floor和key的内容选择新的floor。 松开按键，则key就会归零，于是针对key我使用了一个key_reg保存上一次的输入。所有判断都是在计时器计满之后执行的；都是基于上一次key的输入来选择判断。 好吧，实际用到key_reg的只有一处，控制led灯那里。要求是： 1234567891011121314151617181920led_out0：按下KEY0键，若电梯不在1楼，则LED0亮；电梯到达1楼后，LED0指示灯灭掉由于按下key0，电平会从高变低，因此是：若为一楼停靠：00：led0灭，为0若为二楼停靠，或者其他状态：key0取反led_out1：按下KEY1键, 若电梯不在2楼，则LED1亮,电梯到达2楼后，LED1指示灯灭掉.由于按下key1，电平会从高变低，因此是：若为一楼停靠，或其他状态：key1取反，若key1按下，则为1，若未按下，则为0若为二楼停靠：01：led1灭，为0led_out2：电梯在2楼，按KEY2键, 则LED2亮，电梯到1楼后LED2灭01、11：key2取反00、10：设0led_out3：电梯在1楼，按KEY3键, 则LED3亮，电梯到2楼后LED3灭。00、10：key3取反（一楼、一楼到二楼）01、11：设0 本来有很多用了key_reg的，砍掉了。 还有就是运行时灯的流动，12led_reg，五个灯，0.1秒移动一次，在电梯运行时移动。led_reg则是对应G5～T4，从左到右分别01234代码:122&#x27;b10: led_reg &lt;= &#123;led_reg[3:0],led_reg[4]&lt;=1&#125;; //如果电梯上行，LED11至LED7从左到右轮流点亮2&#x27;b11: led_reg &lt;= &#123;led_reg[0]&lt;=1,led_reg[4:1]&#125;; //如果电梯下行，LED11至LED7从右到左轮流点亮注意不是流水灯，但大差不差。 beep_control：一个意义不明的模块，我不知道gpt本来是想做什么，反正它在我这里就是一个运行指示器。改了，改成了到站叫一声。 使用了一个timer_start一个beep_enable来分别控制counter和timer，timer控制时长，counter控制频率。","categories":[],"tags":[]},{"title":"Transformer(Attention机制)论文阅读-2","slug":"Transformer-Attention机制-论文阅读-2","date":"2023-06-13T05:16:37.000Z","updated":"2023-06-14T11:21:49.785Z","comments":true,"path":"2023/06/13/Transformer-Attention机制-论文阅读-2/","link":"","permalink":"http://blog.wspdwzh.space/2023/06/13/Transformer-Attention%E6%9C%BA%E5%88%B6-%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-2/","excerpt":"","text":"结构编码器encoder包含了6个相同的层组成的“stack”，每层两个子层，一个是多头自注意力机制，一个是“simple, positionwise fully connected feed-forward network”简单的、互联的前馈网络。 在每子层的周围使用残差连接、层归一化。“We employ a residual connection around each of the two sub-layers, followed by layer normalization.”，也就是每层的输出为 LayerNorm(x + Sublayer(x))。 所有层被标准化为512维的输出。 解码器decoder同样包含了6个相同的层组成的“stack”，但每层三个子层，一个是多头自注意力机制，一个是多头编码器-解码器注意力机制，“performs multi-head attention over the output of the encoder stack”，一个是简单的、互联的前馈网络。 其中的自注意力层和编码器有所不同，不会关注当前位置后面的位置。 和编码器相同，在每子层的周围使用残差连接、层归一化。“We employ a residual connection around each of the two sub-layers, followed by layer normalization.”，也就是每层的输出为 LayerNorm(x + Sublayer(x))。所有层被标准化为512维的输出。 注意力机制本质是将查询（query）和一组键值对（a set of key-value pairs，是键和值）映射到输出。 换言之，这个键和这个值是配对的，查询是额外的。 输出是值的加权和，权重由查询和对应关键字兼容性函数确定。（weight assigned to each value is computed by a compatibility function of the query with the corresponding key.） 将三种向量各自组成查询（Q），键（K），值（V），然后三个矩阵变一个Output。 其中，求权重的“Scaled Dot-Product Attention”的公式为： 即计算QKV三者输出。假设Q和K等长，长度dk，V长度dv，计算过程： 求QK余弦相似度：求夹角余弦值，相当于判断向量夹角，角度越小越相似。 余弦相似度除(dk)^(1/2)（长度） softmax得到权重，即是attention。 attention权重和V相乘，每一行就是需要的输出。 Scaled Dot-Product Attention属于点乘注意力机制，并在一般点乘注意力机制的基础上，加上了scaled。scaled是指对注意力权重进行缩放，以确保数值的稳定性。 常用注意力机制有additive attention、dot-product (multiplicative) attention，加性注意力和点积注意力。Scaled Dot-Product Attention属于点积注意力，但Scaled Dot-Product Attention 比传统的点积注意力多了一个根号dk的部分。 加性注意力使用具有单个隐藏层的前馈网络来计算兼容性函数。 虽然加与乘注意力两者在理论复杂性上相似，但点积注意力在实践中要快得多，而且更节省空间，因为它可以使用高度优化的矩阵乘法代码来实现。 引入根号dk的原因：弥补点积注意力相对于加法注意力的缺陷：对于较大的dk值，点积的大小会变大，从而将softmax函数推向具有极小梯度的区域。根号dk可以抵消这个影响。 多头注意力从“performing a single attention function with dmodel-dimensional keys, values and queries” 到“linearly project the queries, keys and values h times with different, learned linear projections to dk, dk and dv dimensions, respectively，On each of these projected versions of queries, keys and values we then perform the attention function in parallel, yielding dv-dimensional output values. These are concatenated and once again projected, resulting in the final values.” （projected，含预计和投影的意思。） 翻译一下就是，本来是单头注意力，只有一个注意力函数。 而多头注意力是用不同的、通过机器学习学到的线性投影，将查询、键和值（三个向量）分别线性投影到dk、dk和dv维度h次，也就是h个注意力头。然后在查询、键和值的每个投影版本上，我们并行执行注意力函数，生成dv维输出值。这些被连接起来，组成多头，并再次投影，得到最终值。 多头注意力允许模型联合关注来自不同位置的不同表示子空间的信息。对于一个单一的注意力头而言，做不到，因为单头注意力使用的平均会抑制这种情况。 “头”指的是某次线性投影得到的注意力。 团队在测试的时候使用了八个头，h=8，QK长度均为64，d(model)则是h与64相乘。 总计算成本比较低，因为每个头的维数并不高，而且还可以并行计算。 Transformer中注意力机制的使用编码器-解码器注意力在解码器中使用。 查询来自上一个解码器层，键和值来自编码器的输出。 这种机制模仿了序列到序列模型中的典型编码器-解码器注意力机制，允许解码器中的每一个位置关注输入序列中的所有位置。 编码器自注意力所有的键、值和查询都来自同一个地方，也就是是编码器中前一层的输出。 这种机制允许编码器中的每个位置关注编码器的前一层中的所有位置。 解码器自注意力基本同编码器，但是解码器只能关注半边的信息，“prevent leftward information flow in the decoder to preserve the auto-regressive property” 位置前馈网络Position-wise Feed-Forward Networks每层都包含一个全连接神经网络。“applied to each position separately and identically”，分别且相同地应用于每个位置。 这个网络包含了两个线性变换，一个是relu激活。 不同层网络结构相同但参数不同。 这个网络也可以看作是一个卷积核大小为1的两个卷积。实验者设置的输入和输出的维度为dmodel=512，内层的维度为dff=2048。 Embeddings and Softmaxembedding含义为嵌入层，可以把信息选择性保留，缩小矩阵大小（稀疏矩阵）抽象但更容易处理，即降维；也可以升维。 transformer中的embedding是输入token和输出token转换为维度为dmodel的向量，还使用普通线性变换和softmax函数，将解码器的输出转换为预测的下一个token概率。 transformer中两个嵌入层和预softmax线性变换之间共享相同的权重矩阵。在embedding层中，将这些权重和根号dmodel相乘。 位置编码positional encodings只用注意力机制，不使用卷积和递归，因此需要引入相关位置信息，计算序列中的token。 每层的复杂度、顺序操作、最大路径长度 n是序列长度，d是表示维度，k是卷积的核大小，r是限制自注意中邻域的大小。 transformer将位置编码和“编码器和解码器堆栈底部的‘输入embedding’”结合。（指编码器解码器都有多层，这里是加到最底下一层的embedding子层） 位置编码与embedding具有相同的维度dmodel，因此可以将两者进行直接处理。有多种位置编码可以选择，可以选择让机器学习编码，也可以直接使用固定方式。而本文使用的是不同频率正余弦函数。 输入参数中，pos是位置，i是尺寸。 可以理解为将每个位置和频域上的冲激相对应起来。之所以选择正余弦函数，是对pos的任何偏移，都可以将函数转化为没有偏移的正余弦函数。 自注意力机制和递归、卷积对比三个方面： 每层的总计算复杂度可以并行化的计算量网络中长程依赖项之间的路径长度（path length between long-range dependencies in the network）网络需要学习长程依赖关系，而影响学习这种依赖性的能力的一个关键因素是前向和后向信号在网络中必须经过的路径的长度，越短就越容易学习。 研究时统计了由不同层类型组成的网络中任意两个输入和输出位置之间的最大路径长度： 每层的复杂度、顺序操作、最大路径长度 n是序列长度，d是表示维度，k是卷积的核大小，r是限制自注意中邻域的大小。12345自关注层通过恒定数量的顺序执行操作连接所有位置，而递归层需要O（n）个顺序操作。就计算复杂性而言，当序列长度n小于表示维度d时，自注意层比递归层更快，这在机器翻译中最先进的模型使用的句子表示中最为常见，例如分词[38]和字节对[31]表示。为了提高涉及非常长序列的任务的计算性能，可以将自注意限制为仅考虑输入序列中以相应输出位置为中心的大小为r的邻域。这将使最大路径长度增加到O（n＝r）。我们计划在未来的工作中进一步研究这种方法。核宽度k＜n的单个卷积层并不连接所有输入和输出位置对。在连续核的情况下，这样做需要O（n=k）个卷积层的堆栈，或者在扩张卷积的情况下需要O（logk（n））[18]，从而增加网络中任意两个位置之间最长路径的长度。卷积层通常比递归层贵k倍。然而，可分离卷积[6]将复杂性显著降低到O（k n d+n d2）。然而，即使k=n，可分离卷积的复杂性也等于自注意层和逐点前馈层的组合，这是我们在模型中采用的方法。作为副作用，自我关注可以产生更多可解释的模型。我们从我们的模型中检查注意力分布，并在附录中给出和讨论示例。个体注意力负责人不仅清楚地学会了执行不同的任务，而且许多人似乎表现出与句子的句法和语义结构有关的行为。 自注意力层：通过恒定数量的顺序执行操作连接所有位置 递归层：需要O（n）个顺序操作 当序列长度n小于表示维度d时，自注意层比递归层更快 为了提高涉及非常长序列的任务的计算性能，可以将自注意限制为仅考虑输入序列中以相应输出位置为中心的大小为r的邻域。这将使最大路径长度增加到O（n＝r）。我们计划在未来的工作中进一步研究这种方法。 核宽度k＜n的单个卷积层并不连接所有输入和输出位置对。在连续核的情况下，这样做需要O（n=k）个卷积层的堆栈，或者在扩张卷积的情况下需要O（logk（n））[18]，从而增加网络中任意两个位置之间最长路径的长度。卷积层通常比递归层贵k倍。然而，可分离卷积[6]将复杂性显著降低到O（k n d+n d2）。然而，即使k=n，可分离卷积的复杂性也等于自注意层和逐点前馈层的组合，这是我们在模型中采用的方法。 另外，自注意力可以产生更多可解释的模型。 我们从我们的模型中检查注意力分布，并在附录中给出和讨论示例。单个的注意力头不仅清楚地学会了执行不同的任务，而且许多注意力头似乎表现出与句子的句法和语义结构有关的行为。 训练使用BLEU评价效果。","categories":[],"tags":[]},{"title":"VITS论文阅读","slug":"VITS论文阅读","date":"2023-06-12T06:53:17.000Z","updated":"2023-06-12T08:25:00.512Z","comments":true,"path":"2023/06/12/VITS论文阅读/","link":"","permalink":"http://blog.wspdwzh.space/2023/06/12/VITS%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","excerpt":"","text":"概览VITS，Variational Inference with adversarial learning for end-to-end Text-to-Speech，一个很牛逼的变分推理 + 对抗学习的端到端 TTS 网络。 基于《Attention is all you need》中的Transformer结构，额外添加了一个持续时长预测器。 基本结构基于 transformer，也有编码器，解码器。但是编码器做了文本编码器、先验编码器、后验编码器的区分。 基本组成部分： • 文本编码器（Text Encoder）：将输入的文本序列转换为文本特征序列，使用transformer的编码器结构。 • 后验编码器（Posterior Encoder）：将文本特征序列和真实的语音特征序列（如梅尔频谱）作为输入，使用transformer的编码器结构，输出一个后验潜变量分布。 • 先验编码器（Prior Encoder）：将文本特征序列作为输入，使用transformer的编码器结构，并在每个层后面加入一个标准化流层（Normalizing Flow Layer），输出一个先验潜变量分布。 • 语音解码器（Speech Decoder）：将文本特征序列和从先验或后验分布中采样得到的潜变量作为输入，使用transformer的解码器结构，并在最后一层后面加入一个对抗损失层（Adversarial Loss Layer），输出一个语音特征序列。 • 持续时间预测器（Duration Predictor）：将文本特征序列作为输入，使用一个全连接层和一个softmax层，输出一个持续时间序列，表示每个文本单元对应的语音帧数。 VITS的模型训练过程包含以下几个损失函数： • 重建损失（Reconstruction Loss）：衡量语音解码器输出的语音特征序列和真实的语音特征序列之间的差异，使用L1损失或MSE损失。 • 对抗损失（Adversarial Loss）：衡量语音解码器输出的语音特征序列是否能够被一个判别器（Discriminator）区分出真假，使用Wasserstein距离或GAN损失。 • KL散度损失（KL Divergence Loss）：衡量后验潜变量分布和先验潜变量分布之间的差异，使用KL散度公式。 • 持续时间损失（Duration Loss）：衡量持续时间预测器输出的持续时间序列和真实的持续时间序列之间的差异，使用MSE损失或二值交叉熵损失。 训练过程的网络12345671.将输入的文本序列和真实的语音特征序列（如梅尔频谱）通过文本编码器和后验编码器得到后验潜变量分布，并从中采样得到后验潜变量。2.将输入的文本序列通过先验编码器得到先验潜变量分布，并从中采样得到先验潜变量。3.将文本特征序列和后验潜变量或先验潜变量通过语音解码器得到重建的语音特征序列，并通过判别器判断其真假。4.根据重建损失、对抗损失、KL散度损失和持续时间损失对模型参数进行更新。 总结一下，即 文本序列，真实语音序列作为输入，通过文本编码器、后验编码器，输出后验潜变量分布，采样得后验潜变量。 文本序列作为输入，通过先验编码器，得到先验潜变量分布，采样得到先验潜变量。 “文本特征序列”+后验潜变量通过语音解码器，得到重建语音特征序列。 “文本特征序列”+先验潜变量通过语音解码器，得到重建语音特征序列。 重建语音特征序列输入判别器，判断真假。 计算所有损失，求和，并进行模型参数更新。 但是VITS将本来的编码器换成了VAE，又加了个标准化流，变成了Glow模型。 推理过程的网络VITS的模型推理过程如下： • 将输入的文本序列通过文本编码器得到文本特征序列。 • 将文本特征序列通过先验编码器得到先验潜变量分布，并从中采样得到潜变量。 • 将文本特征序列和潜变量通过语音解码器得到语音特征序列。 • 将语音特征序列通过一个声码器（Vocoder）得到最终的语音波形。","categories":[],"tags":[]},{"title":"Transformer 在 VITS 中的应用","slug":"Transformer-在-VITS-中的应用","date":"2023-06-12T06:29:03.000Z","updated":"2023-06-12T06:46:23.218Z","comments":true,"path":"2023/06/12/Transformer-在-VITS-中的应用/","link":"","permalink":"http://blog.wspdwzh.space/2023/06/12/Transformer-%E5%9C%A8-VITS-%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/","excerpt":"","text":"VITS，Variational Inference with adversarial learning for end-to-end Text-to-Speech，使用了 transformer 作为基本的架构，但是在后验编码器和先验编码器之间额外添加了变分推理和标准化流。 Transformer的结构一个编码器，一个解码器。 编码器解码器各自是一个相对完整的神经网络，每层含子层，子层分别为注意力和前馈神经网络。处理查询（query）、 键（key）或值（value）（都是向量）。 VITS的结构和原版Transformer的对应文本编码器（Text Encoder）：transformer的编码器结构，将输入的文本序列转换为文本特征序列。 后验编码器（Posterior Encoder）：transformer的编码器结构，将文本特征序列和真实的语音特征序列（如梅尔频谱）作为输入，输出一个后验潜变量分布。 先验编码器（Prior Encoder）：transformer的编码器结构，将文本特征序列作为输入，并在每个层后面加入一个标准化流层（Normalizing Flow Layer），输出一个先验潜变量分布。 语音解码器（Speech Decoder）：transformer的解码器结构，将文本特征序列和从先验或后验分布中采样得到的潜变量作为输入，并在最后一层后面加入一个对抗损失层（Adversarial Loss Layer），输出一个语音特征序列。 以及额外添加的： 持续时间预测器（Duration Predictor）：将文本特征序列作为输入，使用一个全连接层和一个softmax层，输出一个持续时间序列，表示每个文本单元对应的语音帧数。","categories":[],"tags":[]},{"title":"Transformer(Attention机制)论文阅读-1","slug":"Transformer-Attention机制-论文阅读","date":"2023-06-09T13:06:38.000Z","updated":"2023-06-13T05:16:54.986Z","comments":true,"path":"2023/06/09/Transformer-Attention机制-论文阅读/","link":"","permalink":"http://blog.wspdwzh.space/2023/06/09/Transformer-Attention%E6%9C%BA%E5%88%B6-%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","excerpt":"","text":"业界典中典之《Attention Is All You Need》，影响世界格局的注意力机制，和“Transformer”。你甚至可以在 维基百科的transformer 页面看到它的大名。 论文原链接为https://arxiv.org/abs/1706.03762 和 https://arxiv.org/pdf/1706.03762.pdf。方便起见，我在文末会嵌入论文pdf页面。 首先问问new bing怎么说：1234567891011121314151617《Attention Is All You Need》是一篇于2017年发表在NIPS会议上的论文，由Google Brain和Google Research的8位作者共同撰写 。这篇论文提出了一种新的基于注意力机制的网络架构，叫做Transformer，它完全摒弃了循环神经网络和卷积神经网络，只使用注意力机制来编码和解码序列。这篇论文的主要贡献有以下几点：• 提出了一种新的注意力函数，叫做缩放点积注意力（Scaled Dot-Product Attention），它可以计算一个查询向量和一组键值对之间的相关性，并输出相应的值向量的加权和。• 提出了一种新的注意力模块，叫做多头注意力（Multi-Head Attention），它可以将输入向量分成多个子空间，并在每个子空间上分别进行缩放点积注意力，然后将结果拼接起来。• 提出了一种新的位置编码方式，叫做正弦余弦位置编码（Sinusoidal Positional Encoding），它可以给输入序列中的每个位置添加一个固定的向量，用来表示位置信息。• 提出了一种新的网络结构，叫做Transformer，它由一个编码器和一个解码器组成，每个编码器和解码器都包含若干层，每层都由多头注意力、前馈神经网络、残差连接和层归一化组成。• 在两个机器翻译任务上，分别是WMT 2014英德翻译和WMT 2014英法翻译，展示了Transformer的优越性能，分别达到了28.4 BLEU和41.8 BLEU的单模型最佳结果。• 在一个英语成分句法分析任务上，展示了Transformer的泛化能力，无论是在大规模还是小规模的训练数据上，都能取得不错的效果。这篇论文对于自然语言处理领域有着深远的影响，它开创了基于自注意力机制的序列建模和转换的范式，并为后续的许多工作提供了灵感和基础。例如BERT、GPT、XLNet等预训练语言模型都是基于Transformer或其变体构建的。 总结一下，新提出的有以下： 神经网络架构 Transformer，核心是注意力机制 由一个编码器和一个解码器组成 每个编码器和解码器都包含若干层，每层都由多头注意力、前馈神经网络、残差连接和层归一化组成 注意力函数 名为缩放点积注意力（Scaled Dot-Product Attention） 计算一个查询向量和一组键值对之间的相关性，并输出相应的值向量的加权和 注意力模块 多头注意力（Multi-Head Attention） 将输入向量分成多个子空间，并在每个子空间上分别进行缩放点积注意力，然后将结果拼接起来 位置编码方式 正弦余弦位置编码（Sinusoidal Positional Encoding） 给输入序列中的每个位置添加一个固定的向量，用来表示位置信息 总之就是注意力，围绕注意力机制展开的一系列工作。 论文摘要为：1234567891011基于复杂的循环或卷积神经网络的编码器-解码器配置的主导序列转换模型。最佳性能的模型还通过注意力机制连接编码器和解码器。我们提出了一种新的简单网络架构，Transformer，它完全基于注意力机制，完全摒弃了循环和卷积。两个机器翻译任务上的实验表明，这些模型在质量上优于其他模型，同时更易于并行化，并且需要显著更少的时间来训练。我们的模型在WMT 2014英德翻译任务上实现了28.4 BLEU的单一模型最佳结果，在现有最佳结果（包括集成）上提高了2 BLEU以上。在WMT 2014英法翻译任务上，我们的模型在8个GPU上训练3.5天后建立了41.8 BLEU的单一模型最新水平BLEU分数，这是文献中最佳模型训练成本的一小部分。我们展示了Transformer对其他任务具有很好的泛化能力，通过将其成功应用于英语成分句法分析，在大规模和有限训练数据上都取得了不错的效果。（其实什么都没说，就是效果好，好的离谱。） 根据搜索结果，本文Transformer中的各个组成模块分别是： • 缩放点积注意力（Scaled Dot-Product Attention）：这是一种注意力函数，它计算一个查询向量和一组键值对之间的相关性，并输出相应的值向量的加权和。它的公式是： \\text{Attention}(Q,K,V)=\\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V其中，$Q$是查询矩阵，$K$是键矩阵，$V$是值矩阵，$d_k$是键向量的维度。分母上的$\\sqrt{d_k}$是为了缩放点积的结果，避免过大或过小的数值影响梯度传播。 • 多头注意力（Multi-Head Attention）：这是一种注意力模块，它将输入向量分成多个子空间，并在每个子空间上分别进行缩放点积注意力，然后将结果拼接起来。它的公式是： \\text{MultiHead}(Q,K,V)=\\text{Concat}(\\text{head}_1,\\dots,\\text{head}_h)W^O其中，$\\text{head}_i=\\text{Attention}(QW_i^Q,KW_i^K,VW_i^V)$，$W_i^Q,W_i^K,W_i^V,W^O$都是可学习的参数矩阵。多头注意力可以让模型同时关注不同的表示子空间和不同的位置信息。 • 正弦余弦位置编码（Sinusoidal Positional Encoding）：这是一种位置编码方式，它给输入序列中的每个位置添加一个固定的向量，用来表示位置信息。它的公式是： \\text{PE}{(pos,2i)}=\\sin(pos/10000^{2i/d{\\text{model}}})\\text{PE}{(pos,2i+1)}=\\cos(pos/10000^{2i/d{\\text{model}}})其中，$pos$是位置索引，$i$是维度索引，$d_{\\text{model}}$是模型维度。正弦余弦位置编码可以让模型捕捉到相对位置和绝对位置的信息，并且具有平移不变性。 • Transformer：这是一种网络结构，它由一个编码器和一个解码器组成，每个编码器和解码器都包含若干层，每层都由多头注意力、前馈神经网络、残差连接和层归一化组成。编码器用来将输入序列编码成一个高维向量表示，解码器用来根据编码器的输出和自身的输入生成目标序列。 以上就是本文Transformer中各个组成模块的简要解释。如果你想了解更多细节，请参考原文 https://www.electricalclassroom.com/parts-of-a-transformer/ 或其他相关资料。 也就是 • 缩放点积注意力（Scaled Dot-Product Attention）：注意力函数 计算一个查询向量和一组键值对之间的相关性，并输出相应的值向量的加权和 • 多头注意力（Multi-Head Attention）：注意力模块 将输入向量分成多个子空间，并在每个子空间上分别进行缩放点积注意力，然后将结果拼接起来 • 正弦余弦位置编码（Sinusoidal Positional Encoding）：位置编码方式 给输入序列中的每个位置添加一个固定的向量，用来表示位置信息 • Transformer：网络结构 由一个编码器和一个解码器组成，每个编码器和解码器都包含若干层，每层都由多头注意力、前馈神经网络、残差连接和层归一化组成。编码器用来将输入序列编码成一个高维向量表示，解码器用来根据编码器的输出和自身的输入生成目标序列。 神经网络架构 Transformer 编码器 将输入序列编码成一个高维向量表示 若干层 多头注意力 前馈神经网络 残差连接 层归一化 解码器 根据编码器的输出和自身的输入生成目标序列 若干层 多头注意力 前馈神经网络 残差连接 层归一化 注意力函数 缩放点积注意力（Scaled Dot-Product Attention） 计算一个查询向量和一组键值对之间的相关性 输出相应的值向量的加权和 注意力模块 多头注意力（Multi-Head Attention） 将输入向量分成多个子空间 在每个子空间上分别进行缩放点积注意力 然后将结果拼接起来 位置编码方式 正弦余弦位置编码（Sinusoidal Positional Encoding） 给输入序列中的每个位置添加一个固定的向量，用来表示位置信息 transformer 是一个网络结构，它包含了缩放点积注意力、多头注意力和正弦余弦位置编码等部分。 自注意力机制（Self-Attention Mechanism）是一种注意力机制，它计算一个序列中不同位置的元素之间的相关性，并输出相应的元素的加权和。它的公式是： \\text{Attention}(Q,K,V)=\\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V其中，$Q$是查询矩阵，$K$是键矩阵，$V$是值矩阵，$d_k$是键向量的维度。分母上的$\\sqrt{d_k}$是为了缩放点积的结果，避免过大或过小的数值影响梯度传播。 自注意力机制的本质可以被描述为一个查询（query）到一系列（键key-值value）对的映射，其中查询和键值对都来自于同一个序列。 自注意力机制可以让序列中的每个元素都与其他元素进行交互，从而捕捉序列内部的结构和依赖关系。 自注意力机制有多种变体，例如多头注意力（Multi-Head Attention），它将输入向量分成多个子空间，并在每个子空间上分别进行自注意力，然后将结果拼接起来。 自注意力机制被广泛应用于基于深度学习的自然语言处理任务中，例如机器翻译、文本摘要、语义分析等。 如果你想了解更多关于自注意力机制的原理和应用，请参考以下资源： • 《Attention Is All You Need》 ：这是一篇经典的论文，提出了基于自注意力机制的Transformer网络结构，在机器翻译任务上取得了显著的效果。 • 《Illustrated: Self-Attention》 ：这是一篇通俗易懂的博客文章，用图解的方式介绍了自注意力机制的计算过程和意义。 • 《The Transformer Attention Mechanism》 ：这是一篇详细的教程文章，介绍了Transformer中使用的不同类型的自注意力机制，以及如何用Python实现它们。 《Attention Is All You Need》是一篇于2017年发表在NIPS会议上的论文，由Google Brain和Google Research的研究人员合作撰写。 该论文提出了一种新的神经网络架构，称为Transformer，它完全基于注意力机制（attention mechanism），摒弃了循环（recurrence）和卷积（convolution）。 注意力机制是一种将一个查询（query）和一组键值对（key-value pairs）映射到一个输出（output）的函数，其中查询、键、值和输出都是向量。 Transformer利用了两种注意力机制：自注意力（self-attention）和编码器-解码器注意力（encoder-decoder attention）。 自注意力允许模型在同一个序列中的不同位置之间建立联系，编码器-解码器注意力允许模型在不同序列之间建立联系。 Transformer由一个编码器（encoder）和一个解码器（decoder）组成，每个部分都包含多个相同的层（layer）。 每个层都有两个子层（sub-layer），一个是多头注意力（multi-head attention），另一个是前馈神经网络（feed-forward neural network）。 此外，每个子层都有残差连接（residual connection）和层归一化（layer normalization）。 Transformer在机器翻译任务上取得了优异的性能，超过了当时的最佳模型，包括集成模型。它在WMT 2014英德翻译任务上达到了28.4 BLEU，比最佳结果提高了2 BLEU以上。它在WMT 2014英法翻译任务上达到了41.8 BLEU，创造了新的单模型最高纪录。Transformer还能很好地泛化到其他任务，例如英语成分句法分析（English constituency parsing）。 捋清思路注意力的本质是处理“查询”和“键值对”并输出的函数。操作对象都是向量。 多头注意力，包含两种注意力机制，一种是自注意力，另一种是编码器-解码器注意力。 自注意力用于在同一序列、不同位置之间建立联系。可以让模型学习到序列内部的依赖关系，无论他们相隔多远。 编码器-解码器注意力用于在不同序列之间建立联系。可以让模型关注到编码器输出中和当前解码器输入相关的部分。 Transformer架构如下： transformer 编码器：包含多个相同的层，每层包含两个子层。 层：包含两个子层 多头注意力 残差连接 层归一化 前馈神经网络 残差连接 层归一化 解码器：包含多个相同的层，每层包含两个子层。 层：包含两个子层 多头注意力 残差连接 层归一化 前馈神经网络 残差连接 层归一化 自然语言处理中： 序列（sequence）：句子 序列中的不同位置（position）：单词，或者子词。 Transformer网络的目标是解决序列到序列（sequence-to-sequence）的任务，例如机器翻译（machine translation），即将一个源语言序列转换为一个目标语言序列。 Transformer网络的工作过程可以分为以下几个步骤： 首先，将源语言序列和目标语言序列都进行编码（encoding），即将每个单词或子词转换为一个固定长度的向量（vector），通常使用词嵌入（word embedding）或者位置编码（position encoding）来实现。 然后，将源语言序列的向量输入到编码器（encoder）中，编码器由多个层（layer）组成，每个层都包含一个多头自注意力（multi-head self-attention）子层和一个前馈神经网络（feed-forward neural network）子层。多头自注意力子层可以让每个位置的输出都包含了输入序列中所有位置的信息，从而捕捉到序列中的依赖关系。前馈神经网络子层可以对每个位置的输出进行非线性变换，从而增加模型的表达能力。 接着，将目标语言序列的向量输入到解码器（decoder）中，解码器也由多个层组成，每个层都包含一个多头自注意力子层、一个多头编码器-解码器注意力（multi-head encoder-decoder attention）子层和一个前馈神经网络子层。多头自注意力子层可以让每个位置的输出都包含了目标语言序列中所有位置的信息，从而捕捉到序列中的依赖关系。多头编码器-解码器注意力子层可以让每个位置的输出都包含了编码器输出序列中所有位置的信息，从而实现了源语言序列和目标语言序列之间的对齐。前馈神经网络子层可以对每个位置的输出进行非线性变换，从而增加模型的表达能力。 最后，将解码器输出的向量进行解码（decoding），即将每个向量转换为一个单词或子词，通常使用线性变换（linear transformation）和softmax函数来实现。这样就得到了最终的目标语言序列。 多头注意力层： 可以将输入序列分成多个子序列，然后对每个子序列应用不同的注意力函数，最后将各个子序列的输出拼接起来。这样可以让模型同时关注到不同的特征和信息。自注意力和编码器-解码器注意力都是一种注意力函数，只是应用的对象不同。自注意力是在同一个序列中的不同位置之间进行计算，编码器-解码器注意力是在不同序列之间进行计算。 在编码器自注意力中，查询（query）和键（key）、值（value）都来自于输入序列； 在编码器-解码器注意力中，查询（query）来自于解码器的输出序列，而键（key）和值（value）来自于编码器的输出序列。 编码器自注意力和编码器-解码器注意力的主要区别在于它们的查询（query）来源。 编码器-解码器注意力是一种注意力机制，它用于编码器-解码器模型中。 在这种模型中，编码器将输入序列编码为一个固定长度的向量，然后解码器使用这个向量来生成输出序列。编码器-解码器注意力允许解码器在生成输出序列时直接访问编码器的输出。 在编码器-解码器注意力中，查询（query）来自于解码器的输出序列，而键（key）和值（value）来自于编码器的输出序列。这种机制允许解码器根据输入序列中不同位置的相关性来分配不同的权重，从而更好地捕捉序列中不同位置之间的关系。 自注意力（Self-Attention）是一种注意力机制，它用于捕捉序列中不同位置之间的关系。 与传统的注意力机制不同，自注意力减少了对外部信息的依赖，更擅长捕捉数据或特征的内部相关性。 在自注意力中，查询（query）、键（key）和值（value）都来自于输入序列。这种机制允许模型根据输入序列中不同位置的相关性来分配不同的权重，从而更好地捕捉序列中不同位置之间的关系。 在自注意力机制中，查询（query）、键（key）和值（value）都来自于输入序列。查询（query）表示请求的内容，键（key）表示被请求的内容，值（value）表示被请求内容的实际值。通过计算查询（query）和键（key）之间的点积来确定每个值（value）的权重，然后对所有值（value）进行加权求和来得到输出。 在编码器-解码器注意力机制中，查询（query）来自于解码器的输出序列，而键（key）和值（value）来自于编码器的输出序列。查询（query）表示请求的内容，键（key）表示被请求的内容，值（value）表示被请求内容的实际值。 与自注意力机制类似，编码器-解码器注意力机制通过计算查询（query）和键（key）之间的点积来确定每个值（value）的权重，然后对所有值（value）进行加权求和来得到输出。不同之处在于，查询（query）来自于解码器的输出序列，而键（key）和值（value）来自于编码器的输出序列。 自注意力机制中，Transformer首先将输入序列转化为查询（query）、键（key）和值（value），然后通过自注意力机制进行处理并输出。 编码器-解码器注意力机制中，编码器首先将输入序列编码为一个固定长度的向量，然后解码器使用这个向量来生成输出序列。在生成输出序列时，解码器会根据输入序列中不同位置的相关性来分配不同的权重，从而更好地捕捉序列中不同位置之间的关系。 在Transformer网络中，编码器和解码器是两个分开的部分，它们之间通过编码器-解码器注意力机制进行交互。 编码器将输入序列编码为一个固定长度的向量，然后解码器使用这个向量来生成输出序列。在生成输出序列时，解码器会使用编码器-解码器注意力机制来直接访问编码器的输出。这种机制允许解码器根据输入序列中不同位置的相关性来分配不同的权重，从而更好地捕捉序列中不同位置之间的关系。 多头注意力是Transformer网络中编码器和解码器共有的子层。它允许模型同时关注多个位置，从而更好地捕捉序列中不同位置之间的关系。在多头注意力中，查询（query）、键（key）和值（value）被分成多个头，每个头分别进行自注意力或编码器-解码器注意力计算，然后将所有头的结果拼接起来作为最终输出。 Q：在运行过程中，编码器和解码器的层是同一层吗？换句话说，能不能认为，transformer是一个大型网络，不存在编码器解码器的分别，只是transformer网络中的每一层，可以看出有两个部分，一部分负责编码一部分负责解码？ A：在Transformer网络中，编码器和解码器是两个分开的部分，它们由多个层组成。编码器和解码器的层数可以相同，也可以不同。 编码器将输入序列编码为一个固定长度的向量，然后解码器使用这个向量来生成输出序列。编码器和解码器都由多个层组成，每个层都包含多头注意力子层和前馈神经网络子层。在编码器中，多头注意力子层使用自注意力机制来捕捉输入序列中不同位置之间的关系。在解码器中，多头注意力子层既使用自注意力机制来捕捉输出序列中不同位置之间的关系，也使用编码器-解码器注意力机制来直接访问编码器的输出。 因此，Transformer网络可以看作是一个大型网络，它由编码器和解码器两个部分组成。每个部分都由多个层组成，每个层都包含多头注意力子层和前馈神经网络子层。编码器和解码器之间通过编码器-解码器注意力机制进行交互。 亦即是说解码器和编码器确实是分开的，两个网络，毕竟层数都可以不一样。 但也没有分那么开，联系相当紧密。 Q：我复述一遍，你看看对不对。序列进入transformer时，首先是进入编码器，通过所有层，而不是只通过某一层，最终生成的是编码后的向量。这个向量再被放入解码器，得到输出序列。那么，我有一个问题。编码器输出的向量，是query、key和value中的哪一个？解码器的各个层中的编码器-解码器注意力，使用的query、key和value是解码器的前一层的输出，还是编码器的输出？ A：您的理解是正确的。序列进入Transformer时，首先进入编码器，通过所有层，最终生成编码后的向量。这个向量再被放入解码器，得到输出序列。 编码器输出的向量不是查询（query）、键（key）或值（value），而是编码后的向量，它表示输入序列的固定长度表示。在解码器中，每个层的编码器-解码器注意力子层使用的查询（query）来自于解码器的前一层的输出，而键（key）和值（value）来自于编码器的输出。 Q：你说解码器的键（key）和值（value）来自于编码器的输出，又说编码器输出的向量不是查询（query）、键（key）或值（value），而是编码后的向量。编码后的向量和键（key）、值（value）有什么关系？请详细介绍。 A：编码器输出的向量是输入序列的固定长度表示，它由编码器的最后一层输出。在解码器中，每个层的编码器-解码器注意力子层使用的键（key）和值（value）来自于编码器的输出，也就是说，它们来自于编码器的最后一层输出的编码后的向量。 在编码器-解码器注意力子层中，查询（query）、键（key）和值（value）都是通过将输入序列中的每个元素与不同的权重矩阵相乘来计算得到的。查询（query）来自于解码器的前一层的输出，而键（key）和值（value）来自于编码器的最后一层输出的编码后的向量。 因此，编码后的向量和键（key）、值（value）之间的关系是：编码后的向量是输入序列的固定长度表示，它由编码器的最后一层输出；而键（key）和值（value）则是通过将编码后的向量与不同的权重矩阵相乘来计算得到的。 亦即是说，编码器确实是执行完所有层，才会输出句子对应的向量。 这个向量经过与不同的权重矩阵相乘来计算，得到键（key）和值（value）。 键（key）和值（value）会传递给解码器，解码器第一层会将目标序列转化为查询（query）向量，传递给下一层；之后的每一层会输出向量，作为下一层的查询（query）输入。 Q：解码器的输入是“目标序列”，那么，这个“目标序列”是怎么转化为查询（query）的？ A：在解码器中，每个层的编码器-解码器注意力子层使用的查询（query）来自于解码器的前一层的输出。在解码器的第一层中，查询（query）来自于目标序列。 目标序列首先被转化为嵌入表示，然后与位置编码相加来表示序列中每个元素的位置信息。这个嵌入表示就是解码器第一层的输入，也就是查询（query）。 在解码器的每个层中，查询（query）都是通过将输入序列中的每个元素与权重矩阵相乘来计算得到的。在解码器的第一层中，输入序列就是目标序列的嵌入表示。 Q：详细解释权重矩阵是哪里来的。是transformer神经网络自带的吗？键（key）和值（value）在解码器的每一层中是如何处理的？ A：权重矩阵是Transformer网络的参数之一，它们在训练过程中被学习得到。查询（query）、键（key）和值（value）都是通过将输入序列中的每个元素与不同的权重矩阵相乘来计算得到的。 在解码器的每一层中，查询（query）来自于解码器的前一层的输出，而键（key）和值（value）来自于编码器的输出。多头注意力子层将查询（query）、键（key）和值（value）分成多个头，每个头分别进行自注意力或编码器-解码器注意力计算，然后将所有头的结果拼接起来作为最终输出。 在编码器-解码器注意力计算中，首先计算查询（query）和键（key）之间的点积来确定每个值（value）的权重，然后对所有值（value）进行加权求和来得到输出。这样，解码器就可以根据输入序列中不同位置的相关性来分配不同的权重，从而更好地捕捉序列中不同位置之间的关系。 因此，在解码器的每一层中，键（key）和值（value）都是通过编码器-解码器注意力计算来处理的。它们用于确定每个值（value）的权重，并对所有值（value）进行加权求和来得到输出。 transformer的训练产物是权重矩阵。","categories":[],"tags":[]},{"title":"更加完善的爬虫 plus","slug":"更加完善的爬虫-plus","date":"2023-05-28T13:54:38.000Z","updated":"2023-05-28T15:10:45.964Z","comments":true,"path":"2023/05/28/更加完善的爬虫-plus/","link":"","permalink":"http://blog.wspdwzh.space/2023/05/28/%E6%9B%B4%E5%8A%A0%E5%AE%8C%E5%96%84%E7%9A%84%E7%88%AC%E8%99%AB-plus/","excerpt":"","text":"算上注释，和一些意义不明的回车，大概五百行。 总之就是： 使用controller控制页面的切换，实现了return，而且不用像之前一样重复实例化多个窗口（在connect里面实时实例化）。 优化了UI的布局。 进行了exe打包 增加了功能： 使用jieba进行分词 使用word2vec进行 句子-词向量 的转化 使用pandas将测到的结果写入csv文件 Controller 控制器核心是Qt的信号量机制。1234567891011121314151617181920212223242526# 利用一个控制器来控制页面的跳转class Controller: def __init__(self): pass # 跳转到 main 窗口 def show_main(self): self.main = mainpage() self.main.switch_window1.connect(self.show_add_url) # 信号量关联 self.main.switch_window2.connect(self.show_crawler) self.main.show() # 跳转到search窗口, 注意关闭原页面 def show_add_url(self): self.add_url = addurl() self.add_url.switch_window1.connect(self.show_main) self.add_url.switch_window1.connect(self.add_url.close) self.main.close() self.add_url.show() #跳转到 DisFac 窗口, 注意关闭原页面 def show_crawler(self): self.crawler = crawler() self.crawler.switch_window1.connect(self.show_main) self.crawler.switch_window1.connect(self.crawler.close) self.main.close() self.crawler.show()可以看到，函数中调用的self.xxx.switch_window1是原类中的一个pyqtSignal()对象，本质是Qt使用的信号量。在类的开头进行实例化：1switch_window1=pyqtSignal()实例化后就可以调用其中的emit()方法，在这里，方便起见，我另外设置了一个方法来调用。 具体内容为：12def return_to_main(self): self.switch_window1.emit() 而与之对应，在主页面也有对应方法，用于和对应的跳转按钮对应起来：12345678910switch_window1=pyqtSignal()switch_window2=pyqtSignal()def jump_to_add_url(self): print(&#x27;jump to add url&#x27;) self.switch_window1.emit()def jump_to_crawler(self): print(&#x27;jump to crawler&#x27;) self.switch_window2.emit()总之就是，使用pyqtSignal()对象中的emit()方法进行跳转。在Controller内，这个pyqtSignal()对象应该和形如show_add_url的方法对应起来。 UI的优化主页： 添加url： 爬取： exe打包使用了pyinstaller，值得注意的是，当前虚拟环境（我用了anaconda）里，没有用到的包似乎也会被一并打包，导致最终的exe巨大一个。 要是需要小一点的exe，可以新建虚拟环境，并尽量少地安装包。 readline 和 rstrip(“\\n”) 和 split(‘ ‘)readline真的是只读一行，读到回车为止。 rstrip是一个字符串的方法，可以删去字符串首尾的多余字符。例如skipwords[i] = skipwords[i].rstrip(&quot;\\n&quot;) split也是一个字符串的方法，可以以参数为界，将字符串切割为列表。 forcutwordslist += [word for word in jieba.cut(word_read, cut_all=False) if word not in skipwords] C for A in B，用中括号括起来就是一个列表，甚至可以用if进行跳过。很神奇。 eval 和 dict理论上dict可以将字符串转化为字典，但是我从来没使用成功过，反倒是一直在用eval。 jieba 分词cutwordslist += [word for word in jieba.cut(word_read, cut_all=False) if word not in skipwords] jieba.cut方法，输入需要切割的字符串，指定切割模式，返回一个列表。 word2vec首先加载模型，w2v_model = Word2Vec.load(&#39;aaa.model&#39;) 然后，由于我使用的向量是一百二十八维的（主要是因为模型就是这个维数），所以需要更新大小。 vec = numpy.zeros(size).reshape((1, size)) 要想获得一句话的词向量，只需要将词汇的词向量全部相加。 vec += w2v_model.wv[word].reshape((1, size)) 获得vec之后写入即可。 pandas 写入 csvpandas使用的数据类型叫做DataFrame，初始化的时候需要提供数据和标签，data和columns。 data=pandas.DataFrame(data=[j for j in range(128)],columns=[&#39;index&#39;]) 写入新数据是data[line]=vec[0]，其中line为句子本身的字符串，作为索引，vec是一个列表套列表所以不能直接用，需要vec[0]。 如果vec维数不够128维就会出现报错，以防万一，使用if判断，然后data[line]=[0 for k in range(128)]进行补零。 最后写入：data.to_csv(&#39;data_final_&#39;+self.site+&#39;.csv&#39;)。","categories":[],"tags":[]},{"title":"有GUI的爬虫plus","slug":"有GUI的爬虫plus","date":"2023-05-22T06:27:45.000Z","updated":"2023-05-22T07:00:08.817Z","comments":true,"path":"2023/05/22/有GUI的爬虫plus/","link":"","permalink":"http://blog.wspdwzh.space/2023/05/22/%E6%9C%89GUI%E7%9A%84%E7%88%AC%E8%99%ABplus/","excerpt":"","text":"代码比较多，优化空间也很大，就不放上来了。 聊聊写的时候碰到的问题和解决。 QT使用的基本思路首先实例化组件：1234self.label_name = QLabel(&#x27;name&#x27;)self.edit_name = QComboBox()self.label_num = QLabel(&#x27;page num&#x27;)self.edit_page_num = QComboBox()层：1self.lay_h1=QHBoxLayout()向层中添加组件：12345678910self.lay_h1.addWidget(self.label_name)self.lay_h1.addWidget(self.label_num)self.lay_h1.addWidget(self.label_url)self.lay_h2.addWidget(self.edit_name)self.lay_h2.addWidget(self.edit_page_num)self.lay_h2.addWidget(self.edit_url)self.lay_h3.addWidget(self.btn_crawl)self.lay_h3.addWidget(self.btn_update)self.lay_h3.addWidget(self.btn_exit)向窗口添加层:1234self.lay_v1=QVBoxLayout()self.lay_v1.addLayout(self.lay_h1)self.lay_v1.addLayout(self.lay_h2)self.lay_v1.addLayout(self.lay_h3)定义按钮行为:1234self.btn_crawl.clicked.connect(self.crawl)# self.btn_exit.clicked.connect(main.show)self.btn_update.clicked.connect(self.update)self.btn_exit.clicked.connect(self.close)设置下拉框等等：123# 下拉框self.edit_name.addItems(list(url_dict.keys())) # 认列表，不认字典self.edit_page_num.addItems(str(i) for i in range(1,11)) # 好事情最后完成窗口设置：1self.setLayout(self.lay_v1) 如何多py文件开发？我也不清楚这个应该怎么称呼，总之就是多个源文件，但源文件之间可以使用其他文件的代码。要称呼的话应该是“工程”。 如果需要使用其他文件里的代码，在文件开头import文件名即可，就当作库来使用。 主函数也就是if __name__ == &#39;__main__&#39;:这句话，__name__是自带变量，获取文件名。 使用pyqt窗口需要实例化，即123456app = QApplication(sys.argv)addurl_test=addurl()crawl_test=crawler()main = mainpage(addurl_test,crawl_test)main.show()sys.exit(app.exec_())实例化了几个窗口，在实例化时，会调用__init__方法，但是没有调用show方法，所以并不会显示。 关于窗口切换一开始是试着通过调用close和show实现窗口切换，但是发现类的方法之间并不能使用主函数中实例化的窗口，需要传送参数，但是connect方法传参会出现TypeError: argument 1 has unexpected type &#39;NoneType&#39;的问题，于是不了了之。 后面参考其他同学的代码，发现他们是通过在分页面的类内插入形如12switch_window1=QtCore.pyqtSignal()self.switch_window1.emit()的语段来实现。 在主界面似乎并没有这种语段。 需要更改父类的方法直接写就是覆盖，如果需要在父类方法中插入语句，可以 123def show(self): super().show() print(self.__class__.__name__) 使用super()。 QT自带计时器123timer=QTimer(self)timer.start(5000)timer.stop() 计时器也是一个对象（毕竟面向对象），是需要实例化的。 “抓取成功”提示","categories":[],"tags":[]},{"title":"爬虫 plus","slug":"Python-爬虫-plus","date":"2023-05-18T02:34:08.000Z","updated":"2023-05-18T03:14:22.592Z","comments":true,"path":"2023/05/18/Python-爬虫-plus/","link":"","permalink":"http://blog.wspdwzh.space/2023/05/18/Python-%E7%88%AC%E8%99%AB-plus/","excerpt":"","text":"3123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869# 导入所需模块import requestsfrom bs4 import BeautifulSoupfrom os import _exit,path,remove,systemfrom time import ctime# import jsoncookie = &#x27;this is cookies&#x27; cookies = &#123;i.split(&quot;=&quot;)[0]:i.split(&quot;=&quot;)[-1] for i in cookie.split(&quot;; &quot;)&#125;headers = &#123;&#x27;User-Agent&#x27;:&#x27;this is User-Agent&#x27;&#125;site_url=open(&#x27;site.txt&#x27;,&#x27;r+&#x27;,encoding=&#x27;utf-8&#x27;) # 可读可写url_read=site_url.read()url_dict=eval(url_read) # 转化为字典# site=set(url_dict) # 这样会输出集合，不方便遍历site=list(url_dict.keys()) # 需要从dict_key强转为listdef add_site(): print(url_dict) url_dict[input(&#x27;输入站点代号：&#x27;)]=input(&#x27;请输入站点url：&#x27;) print(url_dict) site_url.seek(0) site_url.write(str(url_dict))while 1: # system(&#x27;cls&#x27;) print(&#x27;-1.add new site&#x27;) print(&#x27;0.quit&#x27;) for i in range(len(url_dict)): print(str(i+1)+&#x27;.&#x27;+site[i]) num=int(input(&#x27;请输入站点编号：&#x27;)) if num==0: site_url.close() _exit(0) if num==-1: add_site() site_url.seek(0) url_read=site_url.read() site=list(url_dict.keys()) # 需要从dict_key强转为list continue page_num=int(input(&#x27;请输入抓取页数：&#x27;)) file_path = &#x27;data&#x27;+&#x27;_&#x27;+site[num-1]+&#x27;.txt&#x27; if path.exists(file_path): remove(file_path) f=open(file_path, &#x27;a&#x27;, encoding=&#x27;utf-8&#x27;) f.write(&#x27;抓取时间：&#x27;+ctime()+&#x27;\\n&#x27;) f.close() for page in range(page_num): f=open(file_path, &#x27;a&#x27;, encoding=&#x27;utf-8&#x27;) f.write(&#x27;\\n\\n第&#x27;+str(page+1)+&#x27;页：\\n&#x27;) f.close() url = url_dict[site[num-1]]+str(page+1) print(url) response = requests.get(url, headers=headers,cookies=cookies) soup = BeautifulSoup(response.text, &#x27;lxml&#x27;) for each in soup.find_all(&#x27;tbody&#x27;): title = each.find(&#x27;a&#x27;,class_ = &#x27;topic&#x27;).get_text(strip=True) f=open(file_path, &#x27;a&#x27;, encoding=&#x27;utf-8&#x27;) f.write(&#x27;\\n&#x27;.join([title])) f.write(&#x27;\\n&#x27;) f.close() print(&#x27;response.status_code ==&#x27;,response.status_code)site_url.close() 改进增加了通过文件读写来更新site即站点列表； 增加了交互式查询的功能； 增加了抓取时间和抓取页面的页数（如果是用于数据分析，那这个属于是多余，但如果爬出来的结果是给人看的，那就显得很有必要了。） 注意点文件的打开方式只介绍我用到的两种，和试图用的一种 ‘r+’：可读可写 ‘a’：追加内容 ‘w+’：打开即清空 前两种的差别在于文件指针初始位置： ‘r+’初始在文件头，read操作将其挪到文件尾，导致第二次read就读不出东西。这种时候就可以通过seek()方法更改文件指针位置，例如seek(0)就是挪到文件开头。 ‘a’初始在文件尾，因此我们需要if path.exists(file_path): remove(file_path)来进行伪覆写。 ‘w+’不是很讲理，将打开的文件视作全新文件，即使没有任何操作也会清空文件内容。 python各种对象和字符串对象的转化其实字符串也是对象，但字符串比较偏朴素，和花里胡哨的dict、list、set什么的完全比不了。 其他对象可以使用str()转化为字符串，字符串也可以通过list()（列表）、eval（字典）等方法转化为其它类型的对象。 其他类型的强制类型转化也是类似，例如字符串可以转化为整型数，’1’可以转化为 1。 对 C 语言起手的人来说堪称魔法。 获取目前时间使用time库的ctime()方法。 连缀&#39;\\n&#39;.join([title])，意思是通过换行符号将join里字符串序列连接起来。 收回前言，python字符串也挺花里胡哨的。 python中的for看上去和 C 里的 for(i=0;i&lt;n;i++);很像，但这里的意思是选取系列中的元素，对所有元素进行以下操作。 如果把系列，也就是soup.find_all(&#39;tbody&#39;)换成range()，那就和 C 类似了。 另外，python的for是可以使用else的。312for each in soup.find_all(&#x27;tbody&#x27;): title = each.find(&#x27;a&#x27;,class_ = &#x27;topic&#x27;).get_text(strip=True)果然面向过程到面向对象的思维转化是个艰难的过程。 从右向左执行url_dict[input(&#39;输入站点代号：&#39;)]=input(&#39;请输入站点url：&#39;)，会先让你输入url，再输入站点代号。反正我觉得没差，就没动它了。","categories":[],"tags":[]},{"title":"Python爬虫构建","slug":"Python爬虫构建","date":"2023-05-17T15:47:40.000Z","updated":"2023-05-17T16:11:27.665Z","comments":true,"path":"2023/05/17/Python爬虫构建/","link":"","permalink":"http://blog.wspdwzh.space/2023/05/17/Python%E7%88%AC%E8%99%AB%E6%9E%84%E5%BB%BA/","excerpt":"","text":"3123456789101112131415161718192021# 导入所需模块import requestsfrom bs4 import BeautifulSoupcookie = &#x27;this is cookies&#x27; cookies = &#123;i.split(&quot;=&quot;)[0]:i.split(&quot;=&quot;)[-1] for i in cookie.split(&quot;; &quot;)&#125;headers = &#123;&#x27;User-Agent&#x27;: &#x27;this is user-agent&#x27;,&#125;for page in range(10): url = &#123;&quot;ng2&quot;:&#x27;https://bbs.nga.cn/thread.php?fid=-447601&amp;page=%s&#x27; %page, &quot;ark&quot;:&#x27;https://bbs.nga.cn/thread.php?fid=-34587507&amp;page=%s&#x27; %page&#125; response = requests.get(url[&#x27;ark&#x27;], headers=headers,cookies=cookies) soup = BeautifulSoup(response.text, &#x27;lxml&#x27;) for each in soup.find_all(&#x27;tbody&#x27;): title = each.find(&#x27;a&#x27;,class_ = &#x27;topic&#x27;).get_text(strip=True) f=open(&#x27;data&#x27;+&#x27;_&#x27;+&#x27;ark&#x27;+&#x27;.txt&#x27;, &#x27;a&#x27;, encoding=&#x27;utf-8&#x27;) f.write(&#x27;\\n&#x27;.join([title])) f.write(&#x27;\\n&#x27;) f.close() print(&#x27;response.status_code ==&#x27;,response.status_code) 关于爬虫本质是一个访问网站，提取某些信息的程序。 “爬取”这个动词描述获取数据的过程。其实比起爬取，爬虫的行为更像是递交一个申请表，申请到一本html文件，然后对着这本html文件写了一篇摘要呈现给用户。 理论上说，人来通过浏览器手动记录数据本质和爬虫一样，但爬虫效率高，容易把服务器爬出问题。 关于我这个爬虫用来爬ngabbs.com的某些版面帖子标题，用于数据分析，绝对不是干什么坏事。 解读首先我是使用了beautifulsoup4和request库。不得不说python的库是真的方便。312import requestsfrom bs4 import BeautifulSoup然后我需要清理一下之前生成的残留文件，因此我需要os来获取当前路径下的文件并移除：312345import ospath = &#x27;data&#x27;+&#x27;_&#x27;+&#x27;ark&#x27;+&#x27;.txt&#x27;if os.path.exists(path): os.remove(path)然后是构建请求。 请求需要Cookies，否则会报403错误（无权限）； Cookies不能直接提交，需要转换为字典； 请求需要请求头，也就是headers，里面包含User-Agent。一开始我不知道，把Cookies也放在了里面。事实上Cookies应该单独提交； 请求需要url，因为我需要不同版面，不同页数的数据，因此构建了一个字典，使用助记词对应url。令我惊叹的、很人性化的一点是，可以使用%s和追加%page来实现变参的作用； 最后，我们调用了get方法，得到的是response。 然后使用BeautifulSoup对其进行解码，得到soup。312345678910cookie = &#x27;this is cookies&#x27; cookies = &#123;i.split(&quot;=&quot;)[0]:i.split(&quot;=&quot;)[-1] for i in cookie.split(&quot;; &quot;)&#125;headers = &#123;&#x27;User-Agent&#x27;: &#x27;this is user-agent&#x27;,&#125;for page in range(10): url = &#123;&quot;ng2&quot;:&#x27;https://bbs.nga.cn/thread.php?fid=-447601&amp;page=%s&#x27; %page, &quot;ark&quot;:&#x27;https://bbs.nga.cn/thread.php?fid=-34587507&amp;page=%s&#x27; %page&#125; response = requests.get(url[&#x27;ark&#x27;], headers=headers,cookies=cookies) soup = BeautifulSoup(response.text, &#x27;lxml&#x27;)然后是写入文件，这部分折磨了我好久。我一开始的版本是：3123456for each in soup.find_all(&#x27;tbody&#x27;): title = each.find(&#x27;a&#x27;,class_ = &#x27;topic&#x27;).get_text(strip=True) with open(&#x27;data&#x27;+&#x27;_&#x27;+&#x27;ark&#x27;+&#x27;.txt&#x27;, &#x27;w&#x27;, encoding=&#x27;utf-8&#x27;) as f: f.write(&#x27;\\n&#x27;.join([title])) f.write(&#x27;\\n&#x27;) f.close()但这样写会让文件的写入覆盖前一个，也就是说，无数轮循环结束，文件里只能保留最后一个标题。 但我不知道为什么，怀疑是with open(&#39;data&#39;+&#39;_&#39;+&#39;ark&#39;+&#39;.txt&#39;, &#39;w&#39;, encoding=&#39;utf-8&#39;) as f:的问题。我将其改成了f = open(&#39;data&#39;+&#39;_&#39;+&#39;ark&#39;+&#39;.txt&#39;, &#39;w&#39;, encoding=&#39;utf-8&#39;)，但还是同样的问题。 其实我的怀疑是对的，但没怀疑到点子上。 事实上是这个： 31with open(&#x27;data&#x27;+&#x27;_&#x27;+&#x27;ark&#x27;+&#x27;.txt&#x27;, &#x27;a&#x27;, encoding=&#x27;utf-8&#x27;) as f: 注意到区别了吗？ ‘a’ 和 ‘w’。 我应该再多读读文件操作那章的。31print(&#x27;response.status_code ==&#x27;,response.status_code)这句不用多说，是打印状态值。一开始疯狂报403、411，终于稳定报200之后，我真的是甚是欣慰。 爬取的成果如下：（碍于篇幅，只展示第一页的）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[公告] [四周年活动第一弹]分享罗德岛的年度工作报告，赢版面声望！(抽30位幸运坛友赠送周边一份！)[ROLL] 明日方舟四周年庆典签到活动 抽取iPad手办京东卡等周边大奖[剧情讨论] [闲谈交流] 关于“坠落的星星”，我发现一个华点黄铁峡谷18：“弑君者III：狼牙”+“源石环境：活性III”[可能火星]如果下个月是异格阿葬的话，他就是第77个六星[全新开业]龙门茶馆 - 一盅两盏，畅所欲言[提问]新人放入坑，有一堆疑问汐斯塔扭蛋广场[安科/安价]出场文物是各位干员的泰拉博物馆奇妙夜(博士升任司岁台头头)[失智安科]博士发现了一个奇怪的法阵[博all]随机挑选一个男干员当小妈，但是博士想追求自己的小妈[随缘安科][棘流勇境]极境是要成为魔法帝的男人！[ex8突袭]令人绝望的场景[ROLL] 来roll送一块手工小莫流麻！帮助选择困难症萌新回忆一些老cp的发展，非常主观莱塔尼亚大图书馆[同人文] 《边缘》明日方舟x死亡空间[短篇同人](阿米娅向)雷姆必拓的兔子们[渣文笔][同人文]凯尔希之家[葬博] [送葬人氵] 试图坚持三十天每日一葬[提问] 对萌新来说，这次活动商店兑换优先级是什么样的[闲谈交流] 保全派驻的一点正体验(仅限模拟器)[保全氵]太恶心了[破事氵]虽然不是什么特别的数字，但怎么总觉得这龙门币在骂我自己[氵]突然在想，为什么谢拉格二期的中心不能是崖心呢？为啥突袭0—1这么难啊，把我关了陈陈陈陈陈陈是否还有第二异格形态的可能？保全任务是不是有bug和海愿绝配[闲谈交流]各圈各平台最火CP一览，方舟上榜[剧情讨论] 所以老干猫到底有没有自我意识越来越喜欢叔叔了 因为我加班一个月了才发现明日方舟干员列表的背景不是白色而是透明的保全派驻是明日方舟最弱智最失败的模式，没有之一。有没有基建大佬展示一下顶配基建收益3月后入坑的人，没有夜刀玩肉鸽是不是很难受？黄票不足 要换小火龙吗卡西米尔竞技场[突袭cws4](已过审)无限定，6人带阿消，操作简单，大部分时间在挂机[泰拉记事社] #吉姆波顿 # 特里蒙晚间电波秀[孤星]CW-S-1-AB到CW-S-4突袭摆完挂机，不过是小猪！[中坚寻访]中坚甄选：05月18日 04:00 - 06月01日 03:59[剧情氵]霍尔海雅与缪尔赛思人物对比分析[攒抽氵]小刻也能看懂的零氪攒抽记录--《从大哥到缪缪》[微考据][小车氵]Friston？神经科学？是你！——Friston 在现实世界的致敬/原型[考据氵][抛砖引玉氵]谈“孤星”剧情中的科幻Neta(已更新DLC)[活动奖励干员]重装-铁卫 Friston-3[活动奖励服饰] //竞技之梦改装 - 正义骑士号","categories":[],"tags":[]},{"title":"2023年5月5日","slug":"2023年5月5日","date":"2023-05-04T15:54:15.000Z","updated":"2023-05-05T08:07:44.559Z","comments":true,"path":"2023/05/04/2023年5月5日/","link":"","permalink":"http://blog.wspdwzh.space/2023/05/04/2023%E5%B9%B45%E6%9C%885%E6%97%A5/","excerpt":"","text":"关于阿里云服务器让一个七个月的云服务器烂在手里还是太可惜了。 github上看到一个很有意思的项目，https://github.com/jaywcjlove/reference，似乎非常非常适合镜像到自己的服务器上，作为时时刻刻、随时随地的便利参考。 好奇还有什么类似的项目。 关于云服务器直接部署页面……部署了wordpress博客，搭建了数据库，但是不会使用，不会操作，所以这么长时间就放任它烂在了手里。感觉对不起这个云服务器……属于是倒了大霉碰上了我。 另外，我的服务器是2G+2G配置，据同学说，这个配置跑 MC 似乎还是比较吃力的。 关于VITS论文还在读，笔记做的是纸质的。学习完成之后，打算一股脑传上来。 关于课业 1、信号与系统作业 2、电磁场与波作业 3、美术鉴赏ppt 4、神经网络导论期末大作业 5、信号与系统课程设计 6、python语言课程作业 关于勾选框的使用方法：使用 hexo 的勾选框 6、python语言课程作业 12345678&#123;% cb 6、python语言课程作业,false %&#125;&#123;% cb text, checked?, incline? %&#125;text：显示的文字checked：默认是否已勾选，默认 falseincline: 是否内联（可以理解为后面的文字是否换行），默认 false&#123;% cb false %&#125; 也可以只传入一个参数，文字写在后边（这样不支持外联）内联就是不换行，外联就是换行。 使用 md 自带的勾选框 [ ] 这是未选择 [x] 这是选择 123- [ ] 这是未选择- [x] 这是选择注意空格和 “ - ” 关于 hexo 博客的评论功能开启评论需要在主题配置中开启并指定评论模块： post: comments: enable: true type: disqus 然后在下方还要设置对应评论模块的参数，比如 disqus 对应设置： disqus: shortname: fluid 当前支持的评论插件如下： Valine (opens new window):基于 LeanCloud Waline (opens new window): 从 Valine 衍生而来，额外增加了服务端和多种功能 Gitalk (opens new window): 基于 GitHub Issues Utterances (opens new window): 基于 GitHub Issues Disqus (opens new window): 基于第三方的服务 畅言 (opens new window): 基于第三方的服务 来必力(Livere) (opens new window): 基于第三方的服务 Remark42 (opens new window): 需要自托管服务端 Twikoo (opens new window): 基于腾讯云开发 Cusdis (opens new window): 基于第三方服务或自托管服务 Giscus (opens new window): 基于 GitHub Discussion 使用方式和参数设置请点击上面链接查看各自的文档。 若想自己添加新的评论插件，可通过自定义功能加入 &lt;script&gt;，并判断是否存在 #comments 元素进行挂载。 TIP 国内用户推荐使用 Valine、Waline 或者 twikoo 如果设置后评论模块没有显示，说明配置没有完成，或者配置有误出现报错（请在浏览器控制台查看具体报错） 如果想在某个文章页关闭评论，或者想在某个自定义页面开启评论，可以通过在 Front-matter (opens new window)设置 comment: bool 来控制评论开关，或者通过 comment: &#39;type&#39; 来开启指定的评论插件。 例如在关于页开启并指定评论插件： 12345678---title: 关于页layout: aboutindex_img: /img/example.jpgdate: 2019-10-10 10:00:00comment: &#x27;valine&#x27;---以下是正文内容 总结一下就是 主题内配置开启与参数。 高级用户可以通过自己的script客制化。 可以在页面的开头设置本页面是否开启评论、开启哪种方式的评论。 使用 gittalk 评论12345678910111213gitalk: enable: true #启用gitalk github_id: #github帐号 例：CodeHaotian id: location.pathname #此设置参照下文常见问题说明 repo: #存放评论的仓库名称 client_id: #application的id，即上文Client ID client_secret: #application的密码，即上文Client Secret admin_user: #页面显示联系**初始化评论 例：CodeHaotian distraction_free_mode: true # Facebook-like distraction free mode # Gitalk&#x27;s display language depends on user&#x27;s browser or system environment # If you want everyone visiting your site to see a uniform language, you can set a force language value # Available values: en | es-ES | fr | ru | zh-CN | zh-TW language: zh-CN 这种方法需要一个github application，一个github repo，一个github账号。","categories":[],"tags":[]},{"title":"Numpy 和 Matplotlib 的使用","slug":"Numpy-和-Matplotlib-的使用","date":"2023-04-26T10:41:49.000Z","updated":"2023-05-04T15:51:45.561Z","comments":true,"path":"2023/04/26/Numpy-和-Matplotlib-的使用/","link":"","permalink":"http://blog.wspdwzh.space/2023/04/26/Numpy-%E5%92%8C-Matplotlib-%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"","text":"首先，import一下：123import numpy as npimport matplotlibimport matplotlib.pyplot as plt NumpyNumpy是Python的一个科学计算的库，提供了矩阵运算的功能，其一般与Scipy、matplotlib一起使用。其实，list已经提供了类似于矩阵的表示形式，不过numpy为我们提供了更多的函数。 操作的对象有两种，一种是 N 维数组对象 ndarray，另一种是矩阵 matrix。 数据类型也很多，虽然不需要像C一样指定，但数据确实是有数据类型的。 创建一个 ndarry 对象123456789101112131415161718numpy.array(object, dtype = None, copy = True, order = None, subok = False, ndmin = 0)# 必须的只有object，也就是数组对象，新建的 ndarry 内容和 object 完全一致。# 可以输入多个 object，这样会被视为多维度 ndarry。# numpy.empty(shape, dtype = float, order = &#x27;C&#x27;)numpy.asarray(a, dtype = None, order = None)numpy.frombuffer(buffer, dtype = float, count = -1, offset = 0)numpy.fromiter(iterable, dtype, count=-1)numpy.arange(start, stop, step, dtype)np.linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None)np.logspace(start, stop, num=50, endpoint=True, base=10.0, dtype=None)","categories":[],"tags":[]},{"title":"2023年4月23日","slug":"2023年4月23日","date":"2023-04-23T15:14:53.000Z","updated":"2023-04-23T15:52:00.664Z","comments":true,"path":"2023/04/23/2023年4月23日/","link":"","permalink":"http://blog.wspdwzh.space/2023/04/23/2023%E5%B9%B44%E6%9C%8823%E6%97%A5/","excerpt":"","text":"关于so-vits-svc首先，这是一个很牛逼的项目，极大简化了训练和音色迁移的过程，随着团队的接手，他们甚至加上了webUI。 但是。 他们把项目存了档，我不知道是什么让他们这么做的，但他们就是这么干了。我的评价是这是一个极其弱智且不负责任的行为，因为随着项目的存档，关于该项目的所有issue全部丢失。issue堪称这个项目的贡献者与使用者浓度最高的聚居地，绝大多数讨论都是在issue内进行，只有极少部分有典型性的问题会被搬运到其他平台。 关了之后，当人们碰到问题，或试图参与开发时，想上网寻找相关资料，在搜索引擎里敲入相关字眼，引入眼帘的永远是已经关闭了的issue。 无论如何，项目是他们的，我没有参与贡献，我只是一个学习者，他们确确实实有权决定这个项目的一切。 不过我也确确实实的很不爽。 然后，黑泥结束，让我来夸夸这个项目。 VITS是一个文字转语音的网络，最大的特征是对抗学习和时长预测。论文涉及到不少我本人知识范围以外的东西，在在试着读透。 我在AutoDL上租了一块GPU进行训练。 开始的时候，我以为本地并不足以支持音色迁移的工作完成，所以音色迁移都是交给云端来完成的，现在想想浪费了不少资源。 后来，我开始训练翎羽的语音资料。 解释一下，翎羽是游戏明日方舟的一个角色，有中、日、韩、英四国语音，各有33条。一开始，我是使用日文语音进行训练的，日文语音总时长在三分钟左右。总共运行了63500步，然后我认为，仅仅三分钟的语音不足以构建出色的模型，于是停止了训练，导入了新的语音。 但是事实上，在这个项目中，模型和训练数据集语音直接挂钩，甚至可以说是一一对应，连顺序都不能替换。但我并没有意识到这一点，也没有人和我说，于是，我放弃了现有的训练数据集，后面的事情可想而知。 我跑了六万步的模型尚未完成，卡在不能训练和不能用之间，或者说，在我随机排列32条语音找到正确顺序之前，我无法对其进行进一步训练；同时由于训练步数原因，产生的音频电流声巨大，完全不能使用。 更糟糕的是，我使用的新训练集是四国语音复合的，也就是说实际上是四个人的语音素材。新训练集跑了三万多步，实际效果可谓是一团浆糊。 而我花了很久才意识到这一点。 关于VITS论文于三年前发表，属于是经典之一。正在读论文。 关于其他类似项目DDSP-SVC。 按照介绍，这是一个针对低显存设备进行特别优化的项目。我本人的笔记本电脑是惠普的战99，使用的是nvidia t600入门级专业卡，内存只有可怜的4G。 要不然我为什么要租显卡…… 还没用，但很期待。","categories":[],"tags":[]},{"title":"2023年4月19日","slug":"2023年4月19日","date":"2023-04-19T11:07:00.000Z","updated":"2023-04-19T14:19:56.152Z","comments":true,"path":"2023/04/19/2023年4月19日/","link":"","permalink":"http://blog.wspdwzh.space/2023/04/19/2023%E5%B9%B44%E6%9C%8819%E6%97%A5/","excerpt":"","text":"亲爱的日记：关于vits前几天发现了autodl这个GPU租用平台，于是充了15块钱，拿来跑vits。 至于原因，我之前一直觉得，自家电脑环境有问题、显存也不够，不足以支撑运算。于是租了三块，每块用多少扣多少钱，一个小时0.78元，可以说是相当便宜。 刚刚回忆了一下，之前监控的内存占用，是不是只有2G多，还有快到离谱（训练一分钟歌曲只需要零点几秒）的速度，又想起还有conda这个环境管理器，于是在自己电脑上试了试。 事实证明，能跑，而且，对显存要求很低。大概只占用了1G多。虽然确实慢了不少，78秒的音频文件，使用了61秒跑完。尽管确实很慢，但比我想象中还是快太多了。 这下不需要忧心忡忡等GPu空闲了。也不需要开着filezilla等着文件传输的完成。更不需要熄灯后用手机热点慢慢传数据了。 但是训练模型，应该还是需要更牛逼的GPU来干。 关于spleeter这是一个分割音频中人声、伴奏的开源工程，只有11M左右。GUI版本甚至更小，只有10M。 我正在试图解读。 还是关于vitsvits和so-vits-svc有本质区别，虽然我把这俩混为一谈。vits，很小，只有14m；so-vits-svc，更小，小的超乎想象，只有9m。 但是事实上这俩确实是两码事。vits比较大可能是因为自带了测试样品。 so-vits-svc，SoftVC VITS Singing Voice Conversion。 vits，VITS，Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech。 这是VITS的论文。 https://arxiv.org/abs/2106.06103 https://petertan303.github.io/img/2106.06103.pdf 关于hexo博客插入pdf在线预览https://lizhening.github.io/posts/7d20ce7f/ 简单概括就是： hexo-pdf插件。通过npm安装，注意是在hexo根目录下执行该语句。npm install --save hexo-pdf &#123;% pdf 链接 %&#125;的形式插入即可，例如&#123;% pdf http://7xov2f.com1.z0.glb.clouddn.com/bash_freshman.pdf %&#125; 那么，我这个就是: 另外注意pdf可以直接放在source文件夹里面。似乎并不可以……还是放在img文件夹里得了。 好吧，还是有点问题。现在好了。真不错。 正事 [x] py作业 [ ] it英语作业 [ ] 体测：周四 [ ] 数字系统实验报告（纸质） [ ] 实际实验 [ ] 仿真实验：延时灯 [ ] 交通灯 [x] 美术鉴赏作业 [ ] 复习 [ ] 人工智能基础 [ ] 电磁场与波 不是正事希望可以找时间解决了…… [ ] VITS论文阅读 [ ] VITS代码阅读 [ ] so-vits-svc代码阅读","categories":[],"tags":[]},{"title":"关于香橙派显示屏","slug":"关于香橙派显示屏","date":"2023-04-11T10:33:01.000Z","updated":"2024-04-19T06:48:11.922Z","comments":true,"path":"2023/04/11/关于香橙派显示屏/","link":"","permalink":"http://blog.wspdwzh.space/2023/04/11/%E5%85%B3%E4%BA%8E%E9%A6%99%E6%A9%99%E6%B4%BE%E6%98%BE%E7%A4%BA%E5%B1%8F/","excerpt":"","text":"香橙派店家资料LCD 显示屏和开发板的接线方式如下所示 （注意香橙派是 26pin 而不是 24pin） 对应到手头的显示屏 TFT SPI 模块引脚 开发板26pin 对应的引脚 GPIO — GPIO num 3.3v VCC 1 号引脚 GND GND 6 号引脚 T_CS CS 24 号引脚 RST RESET 7 号引脚 PC9 — 73 AO(LCD_RS) D/C 11 号引脚 PC6 — 70 MOSI/SDI SDI(MOSI) 19 号引脚 SDK SCK 23 号引脚 BL(Back Light) LED 13 号引脚 PC5 — 69 MISO SDO(MISO) 21 引脚 (注意表格前面需要两个空行) 显示屏店家资料 解释 16 14 12 10 8 6 4 2 电路板 T_CLK NC MOSI NC CS SCK NC GND 原理图 T_CLK - T_MOSI - LCD_CS LCD_SCL - GND 解释 时钟？ - 输入 - 片选信号 时钟信号 - 地 - 15 13 11 9 7 5 3 1 电路板 T_CS PEN MISO SDI AO RST BL 3.3V 原理图 T_CS T_PEN T_MISO LCD_SDI LCD_RS LCD_RST IO_BK 3.3v 解释 片选信号 ？ 输出 传递数据 命令/数据 重置 显示屏背光 电源 一般来说是标准七脚，分别是GND，VCC，D0，D1，RES，DC，CS GND：接地 VCC：供电 DO：Master input slave output，MISO， DI：Master output slave input，MOSI， RES：RST，复位 DC：RS，在只有MOSI的情况下控制写入数据还是命令，这个时候没有MISO CS：CE，SSEL，SS，片选信号 SCLK：时钟信号 放在这块显示屏上，则是 GND：接地 VCC：供电 DO：T_MISO DI：T_MOSI，LCD_SDI RES：LCD_RST DC：LCD_RS CS：T_CS SCLK：T_CLK，LCD_SCL 公用的有 GND 3.3v IO_BK LCD开头的有 LCD_CS LCD_SCL（CLK） LCD_SDI（MOSI） LCD_RS LCD_RST T开头的有 T_CLK T_MOSI T_MISO T_CS T_PEN 公用三个，T开头LCD开头各五个，共计16个，三个NC 基本参数： 240 X RGB X 320 驱动：fb_ili9341 驱动：fb_st7789v 使用ssh传输文件：123scp root@192.168.3.29:/boot/boot.bmp .scp &quot;burythelight2 (online-audio-converter.com).rar&quot; root@192.168.3.29:/.","categories":[],"tags":[]},{"title":"嵌入式操作系统","slug":"嵌入式操作系统","date":"2023-04-11T09:13:57.000Z","updated":"2023-04-11T23:58:20.592Z","comments":true,"path":"2023/04/11/嵌入式操作系统/","link":"","permalink":"http://blog.wspdwzh.space/2023/04/11/%E5%B5%8C%E5%85%A5%E5%BC%8F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/","excerpt":"","text":"现有嵌入式操作系统Mobile operating systems DIP DOS on Atari Portfolio Embedded Linux (see also Linux for mobile devices) Android CalyxOS DivestOS EMUI Flyme OS GrapheneOS LineageOS MIUI Replicant See also List of custom Android distributions Firefox OS KaiOS Ångström distribution Familiar Linux Mæmo based on Debian deployed on Nokia’s Nokia 770, N800 and N810 Internet Tablets. OpenZaurus webOS from Palm, Inc., later Hewlett-Packard via acquisition, and most recently at LG Electronics through acquisition from Hewlett-Packard[39] Access Linux Platform bada Openmoko Linux OPhone MeeGo (from merger of Maemo &amp; Moblin) Mobilinux MotoMagx Qt Extended Sailfish OS Tizen (earlier called LiMo Platform) Ubuntu Touch PostmarketOS Inferno (distributed OS originally from Bell Labs) Magic Cap MS-DOS on Poqet PC, HP 95LX, HP 100LX, HP 200LX, HP 1000CX, HP OmniGo 700LX NetBSD Newton OS on Apple MessagePad Palm OS from Palm, Inc; now spun off as PalmSource PEN/GEOS on HP OmniGo 100 and 120 PenPoint OS Plan 9 from Bell Labs PVOS Symbian OS EPOC Windows CE, from Microsoft Pocket PC from Microsoft, a variant of Windows CE Windows Mobile from Microsoft, a variant of Windows CE Windows Phone from Microsoft DSPnano RTOS iOS watchOS tvOS iPod software iPodLinux iriver clix OS RockBox BlackBerry OS PEN/GEOS, GEOS-SC, GEOS-SE Palm OS Symbian platform (successor to Symbian OS) BlackBerry 10 HarmonyOS - Routers CatOS – by Cisco Systems Cisco IOS – originally Internetwork Operating System by Cisco Systems DNOS – by DriveNets Inferno – distributed OS originally from Bell Labs IOS-XR – by Cisco Systems JunOS – by Juniper Networks LCOS – by LANCOM Systems[40] Linux OpenWrt DD-WRT LEDE Gargoyle LibreCMC Zeroshell FTOS – by Force10 Networks FreeBSD m0n0wall OPNsense pfsense List of wireless router firmware projects - Other embedded Apache Mynewt ChibiOS/RT Contiki ERIKA Enterprise eCos NetBSD Nucleus RTOS[41] NuttX Minix NCOS freeRTOS, openRTOS, safeRTOS Fuchsia OpenEmbedded (or Yocto Project) OpenHarmony pSOS (Portable Software On Silicon) QNX – Unix-like real-time operating system, aimed primarily at the embedded systems market.[42] REX OS – microkernel; usually an embedded cell phone OS RIOT ROM-DOS TinyOS ThreadX RT-Thread DSPnano RTOS Windows IoT – formerly Windows Embedded Windows CE Windows IoT Core Windows IoT Enterprise Wind River VxWorks RTOS.[17] Wombat – microkernel; usually real-time embedded Zephyr LEGO Mindstorms brickOS leJOS 介绍1234567An embedded operating system is an operating system for embedded computer systems. Embedded operating systems are computer systems designed to increase functionality and reliability for achieving a specific task.[1] Resource efficiency comes at the cost of losing some functionality or granularity that larger computer operating systems provide, including functions that may not be used by the specialized applications run. Depending on the method used for multitasking, this type of OS is frequently considered a real-time operating system or RTOS. Embedded systems are mostly used as Real-time operating systems.All embedded systems contain a processor and software. There must be a place for embedded software to store the executable code and temporary storage for run-time data manipulations. These take the form of ROM and RAM, respectively. All embedded systems must also contain some form of inputs and outputs to function. Within the exception of these few common features, the rest of the embedded hardware is usually unique and varies from application to application.[2] The hardware running an embedded operating system can be very limited in resources; therefore the embedded design of these operating systems may have a narrow scope tailored to a specific application to achieve the desired operation under these constraints. The embedded operating system that organizes and controls the hardware usually determines the rest of the embedded hardware needed.To take better advantage of the processing power of the CPU, software developers may write critical code directly in assembly. This machine efficient language can potentially result in gains in speed and determinism at the cost of portability and maintainability. Often, embedded operating systems are written entirely in more portable languages, like C, however.An important difference between most embedded operating systems and desktop operating systems is that the application, including the operating system, is usually statically linked into a single executable image. Unlike a desktop operating system, the embedded operating system does not load and execute many applications.[3] This means that the system is only able to run a few application(s). 种类，构成，应用","categories":[],"tags":[]},{"title":"用 Python 读取&解析 json","slug":"2023年4月8日","date":"2023-04-08T09:32:42.000Z","updated":"2024-03-09T08:05:11.135Z","comments":true,"path":"2023/04/08/2023年4月8日/","link":"","permalink":"http://blog.wspdwzh.space/2023/04/08/2023%E5%B9%B44%E6%9C%888%E6%97%A5/","excerpt":"","text":"用 Python 读取&amp;解析 jsonjson 范例：123456789&#123; &quot;name&quot;: &quot;United States&quot;, &quot;population&quot;: 331002651, &quot;capital&quot;: &quot;Washington D.C.&quot;, &quot;languages&quot;: [ &quot;English&quot;, &quot;Spanish&quot; ]&#125;JSON以键值对的形式传递数据，类似XML，XML示例：12345678910&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;country&gt; &lt;name&gt;United States&lt;/name&gt; &lt;population&gt;331002651&lt;/population&gt; &lt;capital&gt;Washington D.C.&lt;/capital&gt; &lt;languages&gt; &lt;language&gt;English&lt;/language&gt; &lt;language&gt;Spanish&lt;/language&gt; &lt;/languages&gt;&lt;/country&gt;众所周知，Python原生支持JSON数据，json模块是标准库的一部分，无序手动解析。 可以将JSON数据从JSON格式转换到等效的Python对象，例如dictionary和list。JSON模块还可以将Python对象转换为JSON格式。 具体使用：将json字符串转化为字典传入：字符串格式的 json 数据。 123456import json# 导入json包country = &#x27;&#123;&quot;name&quot;: &quot;United States&quot;, &quot;population&quot;: 331002651&#125;&#x27;# 定义字符串，json，countrycountry_dict = json.loads(country)# 使用json.loads()方法处理country 结果country_dict是字典。 注意，json内数据类型和Python内有一一对应的关系。 JSON Python object dict array list string str number (integer) int number (real) float true True false False null None 将json文件转化为字典使用open()方法导入文件，然后使用json.loads()处理读入的字符串。123456import jsonwith open(&#x27;united_states.json&#x27;) as f: data = json.load(f)print(type(data))测试结果： python 字典单向读取，打印时呈现json格式。 用 Python 调用 api12345import requestsdef request_data(url): req = requests.get(url, timeout=30) # 请求连接 req_jason = req.json() # 获取数据 return req_jason 也就是通过requests包里的requests.get(url,timeout)进行获取内容，这个方法会返回一个字符串。 Python 正则模块 reQ：如何将非标准json数据（例如nga的api）掐头去尾？ A：使用re的findall()模块 12345678# 处理形如ashdasbdh(# 中间是json# );import redt = re.findall(r&#x27;[(](.*?)[)]&#x27;, text)data_json = json.loads(dt[0])print(dt)print(data_json) vscode json 自动排版使用json tools工具内的 ctrl+alt+M快捷键","categories":[],"tags":[]},{"title":"专业认知与探索期末作业","slug":"专业认知与探索期末作业","date":"2023-03-16T02:58:26.000Z","updated":"2023-04-23T15:21:49.342Z","comments":true,"path":"2023/03/16/专业认知与探索期末作业/","link":"","permalink":"http://blog.wspdwzh.space/2023/03/16/%E4%B8%93%E4%B8%9A%E8%AE%A4%E7%9F%A5%E4%B8%8E%E6%8E%A2%E7%B4%A2%E6%9C%9F%E6%9C%AB%E4%BD%9C%E4%B8%9A/","excerpt":"","text":"截止时间：周五，也就是明天晚上 要求： 期末题目：用TX-1C学习板实现下列题目中的一个，每人独立完成。 必须完成基本要求，其它功能可以自行添加。 用学习板和超声模块实现超声测距，并用点阵或液晶显示。基本要求：使用超声测距模块进行距离测试，用点阵显示超声波测试的距离，距离越近，点阵中亮的点越少；距离越远，点阵中亮的点越多。（超声测距模块需要大家自己购买，参考型号是HC-SR04） 用学习板和超声模块实现超声测距，并用数码管显示距离。基本要求：使用超声测距模块进行距离测试，并用数码管显示测距结果。（超声测距模块需要大家自己购买，参考型号是HC-SR04） 利用键盘和1602液晶显示器实现简易计算器基本要求：利用矩阵键盘和独立键盘实现一个计算器，计算器必须具备加减乘除功能，并利用1602液晶显示输入的数据和计算结果。计算器的其它功能根据个人能力添加。 利用键盘和数码管实现简易计算器基本要求：利用矩阵键盘和独立键盘实现一个计算器，计算器必须具备加减乘除功能，并利用数码管显示输入的数据和计算结果。计算器的其它功能根据个人能力添加。 利用键盘、发光二极管和数码管实现一个交通信号灯基本要求：指定发光二极管代表红黄绿灯，绿灯亮20s后，黄灯闪烁3s，然后红灯再亮20s，交替变化。当红灯只剩5s时长时，数码管按秒显示倒计时；当绿灯只剩5s时长时，数码管按秒显示倒计时；黄灯工作的3s期间，指定某个发光二极管以500ms为间隔闪烁。根据个人能力实现单向或十字路口交通灯。 基于课程所学内容，自己拟定实验项目和内容，完成实验，并提交报告。 注意：期末项目电子版实验报告提交给助教，报告以“学号+姓名+期末题目”形式命名，时间可以放宽到下学期开学第三周之前。是否安排现场验收，视疫情情况而定。 没有超声模块，排除1、2 选择4：数码管、键盘、计算器 1602液晶显示屏不熟悉，排除 交通灯：考虑 计算器： 计算：加减乘除 需要指定按键：keyscan()，使用所有键盘 十个数字：0~9 加减乘除，四个以上 清零 其他功能 显示屏：display()，显示加减乘除的符号、数字 应该没了？ 交通灯： 指定发光二极管代表红黄绿灯 绿灯亮20s后，黄灯闪烁3s，然后红灯再亮20s，交替变化。 当红灯只剩5s时长时，数码管按秒显示倒计时；当绿灯只剩5s时长时，数码管按秒显示倒计时；黄灯工作的3s期间，指定某个发光二极管以500ms为间隔闪烁。根据个人能力实现单向或十字路口交通灯。 单向： 四个灯，绿灯红灯黄灯和500ms闪烁灯 计时： 绿灯20s，黄灯3s和闪烁灯500ms爆闪，红灯20s 数码管5s倒计时：红灯、绿灯；3s倒计时：黄灯 没了？ 十字路口： 两个单向？ 计算器： 数字表 有小数点 无小数点 运算 display() 实时显示数字，不显示符号 keyscan() 计算器 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149#include &lt;reg52.h&gt;//定义行引脚sbit hang[]=&#123;P3^7,P3^6,P3^5,P3^4&#125;; //定义列引脚sbit lie[]=&#123;P3^3,P3^2,P3^1,P3^0&#125;;char key[4][4]=&#123; &#123;&#x27;7&#x27;,&#x27;8&#x27;,&#x27;9&#x27;,&#x27;0&#x27;&#125;, &#123;&#x27;4&#x27;,&#x27;5&#x27;,&#x27;6&#x27;,&#x27;k&#x27;&#125;, &#123;&#x27;1&#x27;,&#x27;2&#x27;,&#x27;3&#x27;,&#x27;=&#x27;&#125;, &#123;&#x27;a&#x27;, &#x27;m&#x27;, &#x27;x&#x27;, &#x27;p&#x27;&#125;&#125;;// 加减乘除int num[7]=&#123;0&#125;;int cal_num[2]=&#123;0&#125;;char fuhao=0;unsigned char code num1[]= //没有小数点的0-9对应编码&#123;0x3f,0x06,0x5b,0x4f,0x66,0x6d,0x7d,0x07,0x7f,0x6f&#125;;unsigned char code num2[]= &#123;0xbf,0x86,0xdb,0xcf,0xe6,0xed,0xfd,0x87,0xff,0xef&#125;;unsigned char code place[]=&#123;0xfe,0xfd,0xfb,0xf7,0xf5,0xf3,0xf1&#125;;void delay(int z)&#123; int i,j; for(i=z;i&gt;0;i--); for(j=110;j&gt;0;j--);&#125;void display()&#123; int i=0; int temp = cal_num[0]; for(i=0;i&lt;7&amp;&amp;temp&gt;0;i++)&#123; num[i]=temp%10; temp/=10; &#125; for(i=0;i&lt;7;i++)&#123; wela=1; P0=place[i]; wela=0; P0=0x00; dula=1; //P0=(i==1?num2[num[i]]:num1[num[i]]); P0 = cal_num[1]; delay(10); dula=0; P0=0xff; &#125; return;&#125;char keyscan()&#123; char input; int i=0,j=0; for(j=0;j&lt;4;j++)&#123; P3=0xff; hang[j]=0; for(i=0;i&lt;4;i++)&#123; if(lie[i]==0) &#123; delay(10); if(lie[i]==0) &#123; while(lie[i]==0); input=key[i][j]; &#125; &#125; &#125; &#125; return input;&#125;int calculate(char input)&#123; int temp=0; switch(input)&#123; case &#x27;1&#x27;: case &#x27;2&#x27;: case &#x27;3&#x27;: case &#x27;4&#x27;: case &#x27;5&#x27;: case &#x27;6&#x27;: case &#x27;7&#x27;: case &#x27;8&#x27;: case &#x27;9&#x27;: case &#x27;0&#x27;: cal_num[1] = cal_num[1]*10 + ((int)input - &#x27;0&#x27;) break; case &#x27;a&#x27;: case &#x27;m&#x27;: case &#x27;x&#x27;: case &#x27;p&#x27;: case &#x27;=&#x27;: switch(fuhao)&#123; case &#x27;a&#x27;: cal_num[0]+=cal_num[1]; break; case &#x27;m&#x27;: cal_num[0]-=cal_num[1]; break; case &#x27;x&#x27;: cal_num[0]*=cal_num[1]; break; case &#x27;p&#x27;: cal_num[0]/=cal_num[1]; break; case &#x27;=&#x27;: case default: break; &#125; cal_num[1]=0; fuhao = input; break; case default: break; &#125;&#125;void main()&#123; //init char input=0; //begin while(1)&#123; display(); input = keyscan(); calculate(input); &#125; return;&#125; 修改后123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569#include &lt;reg52.h&gt;sbit dula=P2^6; //dula与wela为两个使能端sbit wela=P2^7;////定义行引脚sbit lie1=P3^7;sbit lie2=P3^6;sbit lie3=P3^5;sbit lie4=P3^4;// ////定义列引脚sbit hang1=P3^3;sbit hang2=P3^2;sbit hang3=P3^1;sbit hang4=P3^0;char key[4][4]=&#123; &#123;&#x27;7&#x27;,&#x27;8&#x27;,&#x27;9&#x27;,&#x27;0&#x27;&#125;, &#123;&#x27;4&#x27;,&#x27;5&#x27;,&#x27;6&#x27;,&#x27;k&#x27;&#125;, &#123;&#x27;1&#x27;,&#x27;2&#x27;,&#x27;3&#x27;,&#x27;=&#x27;&#125;, &#123;&#x27;a&#x27;, &#x27;m&#x27;, &#x27;x&#x27;, &#x27;p&#x27;&#125;&#125;;// 加减乘除long int cal_num[3]=&#123;0,0,0&#125;;char fuhao=0;char input=0;unsigned char code num1[]= //没有小数点的0-9对应编码&#123;0x3f,0x06,0x5b,0x4f,0x66,0x6d,0x7d,0x07,0x7f,0x6f&#125;;unsigned char code num2[]= &#123;0xbf,0x86,0xdb,0xcf,0xe6,0xed,0xfd,0x87,0xff,0xef&#125;;unsigned char code place[]=&#123; //0111_1111 7f //1011_1111 bf //1101_1111 df //1110_1111 ef //1111_0111 f7 //1111_1011 fb //1111_1101 fd //1111_1110 fe0xfe,0xfd,0xfb,0xf7,0xef,0xdf,0xbf,0x7f&#125;;void delay(int z)&#123; int i,j; for(i=z;i&gt;0;i--); for(j=110;j&gt;0;j--);&#125;void display()&#123; int i=0; int temp = cal_num[2];// for(i=0;i&lt;7&amp;&amp;temp&gt;0;i++)&#123;// num[i]=temp%10;// temp/=10;// &#125; for(i=5;i&gt;0/*&amp;&amp;temp&gt;0*/;i--)&#123; wela=1; P0=place[i]; wela=0; P0=0x00; dula=1; P0 = num1[temp%10]; temp/=10; delay(10); dula=0; P0=0xff; &#125; delay(100); return;&#125;//char keyscan()//&#123;// char input;// int i=0,j=0;// for(j=0;j&lt;4;j++)&#123;// P3=0xff;// hang[j]=0;// for(i=0;i&lt;4;i++)&#123;// if(lie[i]==0)// &#123;// delay(10);// if(lie[i]==0)// &#123;// while(lie[i]==0);// input=key[i][j];// &#125;// &#125;// &#125;// &#125;// return input;//&#125;//char keyscan()&#123;//&#123;// char input=0;// P3|=0xff;// hang1=0;// if(lie1==0)// &#123;// delay(10);// if(lie1==0)// &#123;// while(lie1==0);// input=key[0][0];// cal_num[1] = cal_num[1]*10 + ((int)input - &#x27;0&#x27;);// &#125;// &#125;// // if(lie2==0)// &#123;// delay(10);// if(lie2==0)// &#123;// while(lie2==0);// input=key[0][1];// cal_num[1] = cal_num[1]*10 + ((int)input - &#x27;0&#x27;);// &#125;// &#125;// // // if(lie3==0)// &#123;// delay(10);// if(lie3==0)// &#123;// while(lie3==0);// input=key[0][2];// cal_num[1] = cal_num[1]*10 + ((int)input - &#x27;0&#x27;);// &#125;// &#125;// // if(lie4==0)// &#123;// delay(10);// if(lie4==0)// &#123;// while(lie4==0);// input=key[0][3];// cal_num[1] = cal_num[1]*10 + ((int)input - &#x27;0&#x27;);// &#125;// &#125;// // // P3|=0xff;// hang2=0;// if(lie1==0)// &#123;// delay(10);// if(lie1==0)// &#123;// while(lie1==0);// input=key[1][0];// cal_num[1] = cal_num[1]*10 + ((int)input - &#x27;0&#x27;);// &#125;// &#125;// // if(lie2==0)// &#123;// delay(10);// if(lie2==0)// &#123;// while(lie2==0);// input=key[1][1];// cal_num[1] = cal_num[1]*10 + ((int)input - &#x27;0&#x27;);// &#125;// &#125;// // // if(lie3==0)// &#123;// delay(10);// if(lie3==0)// &#123;// while(lie3==0);// input=key[1][2];// cal_num[1] = cal_num[1]*10 + ((int)input - &#x27;0&#x27;);// &#125;// &#125;// // if(lie4==0)// &#123;// delay(10);// if(lie4==0)// &#123;// while(lie4==0);// input=key[1][3];// &#125;// &#125;// // P3|=0xff;// hang3=0;// // if(lie1==0)// &#123;// delay(10);// if(lie1==0)// &#123;// while(lie1==0);// input=key[2][0];// cal_num[1] = cal_num[1]*10 + ((int)input - &#x27;0&#x27;);// &#125;// &#125;// // if(lie2==0)// &#123;// delay(10);// if(lie2==0)// &#123;// while(lie2==0);// input=key[2][1];// cal_num[1] = cal_num[1]*10 + ((int)input - &#x27;0&#x27;);// &#125;// &#125;// // // if(lie3==0)// &#123;// delay(10);// if(lie3==0)// &#123;// while(lie3==0);// input=key[2][2];// cal_num[1] = cal_num[1]*10 + ((int)input - &#x27;0&#x27;);// &#125;// &#125;// // if(lie4==0)// &#123;// delay(10);// if(lie4==0)// &#123;// while(lie4==0);// input=key[2][3];// cal_num[1]=0;// fuhao = input;// &#125;// &#125;// // // P3|=0xff;// hang4=0;// // if(lie1==0)// &#123;// delay(10);// if(lie1==0)// &#123;// while(lie1==0);// input=key[3][0];// cal_num[0]+=cal_num[1];// cal_num[1]=0;// fuhao = input;// &#125;// &#125;// // if(lie2==0)// &#123;// delay(10);// if(lie2==0)// &#123;// while(lie2==0);// input=key[3][1];// cal_num[0]-=cal_num[1];// cal_num[1]=0;// fuhao = input;// &#125;// &#125;// // // if(lie3==0)// &#123;// delay(10);// if(lie3==0)// &#123;// while(lie3==0);// input=key[3][2];// cal_num[0]*=cal_num[1];// cal_num[1]=0;// fuhao = input;// &#125;// &#125;// // if(lie4==0)// &#123;// delay(10);// if(lie4==0)// &#123;// while(lie4==0);// input=key[3][3];// cal_num[0]/=cal_num[1];// cal_num[1]=0;// fuhao = input;// &#125;// &#125;// return input;//&#125;//&#125;char keyscan()&#123;&#123; char input=0; P3|=0xff; hang1=0; if(lie1==0) &#123; delay(10); if(lie1==0) &#123; while(lie1==0); input=key[0][0]; &#125; &#125; if(lie2==0) &#123; delay(10); if(lie2==0) &#123; while(lie2==0); input=key[0][1]; &#125; &#125; if(lie3==0) &#123; delay(10); if(lie3==0) &#123; while(lie3==0); input=key[0][2]; &#125; &#125; if(lie4==0) &#123; delay(10); if(lie4==0) &#123; while(lie4==0); input=key[0][3]; &#125; &#125; P3|=0xff; hang2=0; if(lie1==0) &#123; delay(10); if(lie1==0) &#123; while(lie1==0); input=key[1][0]; &#125; &#125; if(lie2==0) &#123; delay(10); if(lie2==0) &#123; while(lie2==0); input=key[1][1]; &#125; &#125; if(lie3==0) &#123; delay(10); if(lie3==0) &#123; while(lie3==0); input=key[1][2]; &#125; &#125; if(lie4==0) &#123; delay(10); if(lie4==0) &#123; while(lie4==0); input=key[1][3]; &#125; &#125; P3|=0xff; hang3=0; if(lie1==0) &#123; delay(10); if(lie1==0) &#123; while(lie1==0); input=key[2][0]; &#125; &#125; if(lie2==0) &#123; delay(10); if(lie2==0) &#123; while(lie2==0); input=key[2][1]; &#125; &#125; if(lie3==0) &#123; delay(10); if(lie3==0) &#123; while(lie3==0); input=key[2][2]; &#125; &#125; if(lie4==0) &#123; delay(10); if(lie4==0) &#123; while(lie4==0); input=key[2][3]; &#125; &#125; P3|=0xff; hang4=0; if(lie1==0) &#123; delay(10); if(lie1==0) &#123; while(lie1==0); input=key[3][0]; &#125; &#125; if(lie2==0) &#123; delay(10); if(lie2==0) &#123; while(lie2==0); input=key[3][1]; &#125; &#125; if(lie3==0) &#123; delay(10); if(lie3==0) &#123; while(lie3==0); input=key[3][2]; &#125; &#125; if(lie4==0) &#123; delay(10); if(lie4==0) &#123; while(lie4==0); input=key[3][3]; &#125; &#125; return input;&#125;&#125;void calculate(char input)&#123; switch(input)&#123; case &#x27;1&#x27;: case &#x27;2&#x27;: case &#x27;3&#x27;: case &#x27;4&#x27;: case &#x27;5&#x27;: case &#x27;6&#x27;: case &#x27;7&#x27;: case &#x27;8&#x27;: case &#x27;9&#x27;: case &#x27;0&#x27;: cal_num[1] = cal_num[1]*10 + ((int)input - &#x27;0&#x27;); cal_num[2] = cal_num[1]; break; case &#x27;a&#x27;: case &#x27;m&#x27;: case &#x27;x&#x27;: case &#x27;p&#x27;: case &#x27;=&#x27;: switch(fuhao)&#123; case &#x27;a&#x27;: cal_num[1]+=cal_num[0]; break; case &#x27;m&#x27;: cal_num[1]=cal_num[0]-cal_num[1]; break; case &#x27;x&#x27;: cal_num[1]*=cal_num[0]; break; case &#x27;p&#x27;: cal_num[1]=cal_num[0]/cal_num[1]; break; case &#x27;=&#x27;: default: break; &#125; cal_num[2]=cal_num[1]; cal_num[0]=cal_num[1]; cal_num[1]=0; fuhao = input; break; case &#x27;k&#x27;: cal_num[0]=cal_num[1]=cal_num[2]=cal_num[3]=0; delay(10); break; default: break; &#125; input = 0; return;&#125;void main()&#123; //init input = 0; //cal_num[1]=123456; //display(); //begin while(1)&#123;// cal_num[1]=12345; display(); delay(10); input = keyscan(); if(input!=0) calculate(input); &#125; return;&#125;","categories":[],"tags":[]},{"title":"2023年3月6日","slug":"2023年3月6日","date":"2023-03-06T04:43:05.000Z","updated":"2024-03-09T08:03:29.977Z","comments":true,"path":"2023/03/06/2023年3月6日/","link":"","permalink":"http://blog.wspdwzh.space/2023/03/06/2023%E5%B9%B43%E6%9C%886%E6%97%A5/","excerpt":"","text":"环境变量可以通过alias设置别名，但不能永久保存，下一次启动shell时会重置。 PATH即是一个环境变量。Ubuntu中，有系统环境变量和用户环境变量，区别在于对所有用户生效还是仅对当前用户生效。 环境变量的储存文件：12345~/.profile# 无论是通过控制台还是图形界面启动程序时，都会自动执行该文件。~/.bashrc, ~/.bash_profile, ~/.bash_login# 当通过shell启动程序时，它们也会被加载；但当通过图形界面环境启动程序时，这些文件中的环境变量设置便不可用了。环境变量的储存文件夹：12345/etc/profile/etc/profile.d/etc/bash.bashrc/etc/profile.d文件夹来源于/etc/profile，目录下的*.sh，即以sh为后缀的文件都会被加载。 在图形界面环境下启动程序时，不会加载/ect/bash.bashrc里边的环境变量设置。 设置永久环境变量实例 编辑/etc/profile export 别名=&#39;指令&#39; 加载环境变量：1source /etc/profile cat 命令cat（英文全拼：concatenate）命令用于连接文件并打印到标准输出设备上。 1cat [-AbeEnstTuv] [--help] [--version] fileName -n 或 —number：由 1 开始对所有输出的行数编号。 -b 或 —number-nonblank：和 -n 相似，只不过对于空白行不编号。 -s 或 —squeeze-blank：当遇到有连续两行以上的空白行，就代换为一行的空白行。 -v 或 —show-nonprinting：使用 ^ 和 M- 符号，除了 LFD 和 TAB 之外。 -E 或 —show-ends : 在每行结束处显示 $。 -T 或 —show-tabs: 将 TAB 字符显示为 ^I。 -A, —show-all：等价于 -vET。 -e：等价于”-vE”选项； -t：等价于”-vT”选项； 用法：123456789cat A B &gt; C# 将文件B中的内容加上A，写入C中cat A B C &gt;&gt; D# 将B与C之间加上A，写入D中cat /dev/null &gt;&gt; A# 清空A将语句写入环境变量： echo &#39;PATH=&quot;$PATH:./node_modules/.bin&quot;&#39; &gt;&gt; ~/.profile 如何将文件夹变为 git 版本库 进入文件夹 git init 将文件添加到本地仓库：git add 可以同时添加多个文件，用空格隔开 提交：git commit -m &quot;对于本次提交的说明&quot;","categories":[],"tags":[{"name":"日志","slug":"日志","permalink":"http://blog.wspdwzh.space/tags/%E6%97%A5%E5%BF%97/"}]},{"title":"2023年3月5日","slug":"2023年3月5日","date":"2023-03-05T05:27:13.000Z","updated":"2024-04-19T05:29:29.361Z","comments":true,"path":"2023/03/05/2023年3月5日/","link":"","permalink":"http://blog.wspdwzh.space/2023/03/05/2023%E5%B9%B43%E6%9C%885%E6%97%A5/","excerpt":"","text":"买的小音箱给送到其他地方去了，憨憨本色。 然后，列一下截至目前已经买的东西： 物件 价格 购买平台 备注 orange pi zero 2 本体 + 扩展板 158.90 淘宝 12元运费，总计170.90 闪迪64G内存卡 套餐 41.90 淘宝 - 0.5m hdmi线|0.99|淘宝|特惠买的，没啥用usb 转 ttl 刷机板|4.00|淘宝|-5v xh2.54 风扇|2.00|淘宝|-5v3a 电源|7.00|淘宝|卖家未发货，退款蓝牙音箱|11.9|拼多多|送到南京去了总计|238.69|-|- orange pi zero 2 进展我的香橙派连接的是寝室网络，一直在纠结要如何在寝室外使用。 刚刚意识到可以直接通过 ttl 串口登录香橙派，不一定需要 ssh 或远程桌面或显示屏。这样只需要带上电脑和 ttl 转接头和杜邦线就行了。 下一步计划是 GUI 制作。 Microwindows MiniGui QT Gtk+ OpenGUI FLTK LingLongGUI LearningGUI 今天做了什么买了大物实验II的实验书、买了数字系统实验II的书和报告册。 然后上午摸鱼摸了一上午。 作业 周一 电磁场与波 信号与系统 需要作业本 IT英语 暂时没有作业，潜在项目 神经网络导论 周二 美术鉴赏 微处理器与嵌入式系统 可能有 人工智能基础 大物实验II 预习实验？ 周三 python语言程序设计及其应用 似乎有作业 周四 数字系统实验 asd 学术规范与论文写作 周五 唐球","categories":[],"tags":[{"name":"日志","slug":"日志","permalink":"http://blog.wspdwzh.space/tags/%E6%97%A5%E5%BF%97/"}]},{"title":"2023年3月4日","slug":"2023年3月4日","date":"2023-03-04T15:32:31.000Z","updated":"2023-03-05T05:26:10.822Z","comments":true,"path":"2023/03/04/2023年3月4日/","link":"","permalink":"http://blog.wspdwzh.space/2023/03/04/2023%E5%B9%B43%E6%9C%884%E6%97%A5/","excerpt":"","text":"买了香橙派 zero 2，租了阿里云服务器。 阿里云服务器已经实现的： ftp 服务器安装 wordpress 服务器安装 远程桌面 vnc 安装 MySql 数据库 香橙派 zero 2最近一直在摆弄。安装过程中，碰上的问题： 烧录错误镜像 Paragon ExtFS for Windows无法读取 sd 卡内容 成功配置了 wi-fi，ssh，音乐播放，安装桌面 烧录镜像完成后，遇到的问题有： 端口设置开放： 先用iptables -I INPUT -p tcp --dport 端口号 -j ACCEPT 设置需要开放端口号、权限、协议 iptables-save保存 sudo netfilter-persistent save永久保存 下一次使用需要sudo netfilter-persistent reload ftp 搭建失败 未解决 aplay 调节音量：差点把自己弄聋（开玩笑） man aplay查看帮助 aplay -D plughw:0,0 xxx.wav指定播放设备 alsamixer设置音量 broot 安装失败 直接下载安装包，未解决 git 无法提交 重新设置 putty push 的时候卡在最后：添加参数sendpack.sideband git config --global sendpack.sideband false git config --local sendpack.sideband false 网络更换手机热点 conda 很慢很卡 安装mamba 安装 vnc 失败 未解决 解压 rar 需要 unrar e 包名（直接解压）或 unrar x 包名（创建新目录） 买了风扇、蓝牙音箱等等配件。 清单：|物件|价格|购买平台|备注||—-|—-|—-|—-||orange pi zero 2 本体 + 扩展板|158.90|淘宝|12元运费||闪迪64G内存卡 套餐|41.90|淘宝||0.5m hdmi线|0.99|淘宝|特惠买的，没啥用usb 转 ttl 刷机板|4.00|淘宝|5v xh2.54 风扇|2.00|淘宝|5v3a 电源|7.00|淘宝|卖家未发货，退款蓝牙音箱|11.9|拼多多|本来打算买有线喇叭，脑子一热就买了 vist借龚的电脑跑出了模型。遇到的问题有： 安装包需要 anaconda pip 换源 临时：pip install -i https://pypi.tuna.tsinghua.edu.cn/simple some-package 永久：pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple numpy 和 python 版本不匹配 卸载重装 安装 cuda 官网下载安装 占用储存巨大 requirements.txt 依赖没写完整 手动安装依赖 pip、conda 无法卸载 python 用 conda 直接安装 另一个版本的 python 或者用 anaconda 创建一个全新环境，创建时配置默认 python 但是储存占用……好吧、必要的牺牲 我自己电脑配置环境，遇到的问题： 最大问题：显存过小，至少需要 4.3G 而我只有 4G conda 无法更换 python 版本 同龚 但是龚的电脑可以随便折腾，不用担心储存不够。真的爽！ stable-diffusion 绘图时间太久了，想不起来，下次再写","categories":[],"tags":[{"name":"日志","slug":"日志","permalink":"http://blog.wspdwzh.space/tags/%E6%97%A5%E5%BF%97/"}]},{"title":"2023年2月5日","slug":"2023年2月5日","date":"2023-02-05T11:17:48.000Z","updated":"2023-02-05T11:26:19.500Z","comments":true,"path":"2023/02/05/2023年2月5日/","link":"","permalink":"http://blog.wspdwzh.space/2023/02/05/2023%E5%B9%B42%E6%9C%885%E6%97%A5/","excerpt":"","text":"测试网易云音乐的插件 原版 测试增大高度 测试自动播放 测试边框","categories":[],"tags":[{"name":"Test","slug":"Test","permalink":"http://blog.wspdwzh.space/tags/Test/"}]},{"title":"2023年1月21日","slug":"2023年1月21日","date":"2023-01-21T11:43:16.000Z","updated":"2023-01-21T12:32:29.799Z","comments":true,"path":"2023/01/21/2023年1月21日/","link":"","permalink":"http://blog.wspdwzh.space/2023/01/21/2023%E5%B9%B41%E6%9C%8821%E6%97%A5/","excerpt":"","text":"http-serverhttp-server可以通过在本地文件夹内运行来实现预览网站的功能。或者说，让任意一个目录成为服务器的目录。默认打开index.html，如果没有，会生成一个默认网页，里面有文件夹内所有内容。 一般默认的网址为192.168.1.2:8081和127.0.0.1:8081，前者可以通过在同一路由下的其他设备访问，后者只能在本设备内查看。 “程序员游戏” 网页游戏： https://screeps.com/ https://codecombat.cn/play https://www.codingame.com/start https://www.binancemag.com/?id=23707 steam 游戏： SHENZHEN I/O SpaceChem TIS - 100 Human Source Machine A = B","categories":[],"tags":[{"name":"日志","slug":"日志","permalink":"http://blog.wspdwzh.space/tags/%E6%97%A5%E5%BF%97/"}]},{"title":"CSS 入门","slug":"试图学习CSS","date":"2023-01-20T03:54:55.000Z","updated":"2025-10-15T13:26:33.045Z","comments":true,"path":"2023/01/20/试图学习CSS/","permalink":"http://blog.wspdwzh.space/2023/01/20/%E8%AF%95%E5%9B%BE%E5%AD%A6%E4%B9%A0CSS/","excerpt":"","text":"基本语法格式CSS = 选择器 + 声明块 例：1234p &#123; color: red; text-align: center;&#125;p 为选择器，指向&lt;p&gt;标签。属性 - 冒号 - 属性值 - 分号。 注释同 C ，/*注释*/。 CSS的使用 外部CSS 例如，html内的一句&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;mystyle.css&quot;&gt;，指向mystyle.css：12345678body &#123; background-color: lightblue;&#125;h1 &#123; color: navy; margin-left: 20px;&#125; 内部css html文件中，head部分的&lt;style&gt;元素中进行定义。123456789101112131415161718192021&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;style&gt;body &#123; background-color: linen;&#125;h1 &#123; color: maroon; margin-left: 40px;&#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;This is a heading&lt;/h1&gt;&lt;p&gt;This is a paragraph.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 行内css（内联样式） 将style属性赋予某个元素。123456789&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;body&gt;&lt;h1 style=&quot;color:blue;text-align:center;&quot;&gt;This is a heading&lt;/h1&gt;&lt;p style=&quot;color:red;&quot;&gt;This is a paragraph.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 层叠顺序当为某个 HTML 元素指定了多个样式时，会使用哪种样式呢？ 页面中的所有样式将按照以下规则“层叠”为新的“虚拟”样式表，其中第一优先级最高： 1.行内样式（在 HTML 元素中） 2.外部和内部样式表（在 head 部分） 3.浏览器默认样式 因此，行内样式具有最高优先级，并且将覆盖外部和内部样式以及浏览器默认样式。 css内容颜色 颜色名 赋颜色的一种方式 背景色 12&lt;h1 style=&quot;background-color:DodgerBlue;&quot;&gt;China&lt;/h1&gt;&lt;p style=&quot;background-color:Tomato;&quot;&gt;China is a great country!&lt;/p&gt; 文本颜色 123&lt;h1 style=&quot;color:Tomato;&quot;&gt;China&lt;/h1&gt;&lt;p style=&quot;color:DodgerBlue;&quot;&gt;China is a great country!&lt;/p&gt;&lt;p style=&quot;color:MediumSeaGreen;&quot;&gt;China, officially the People&#x27;s Republic of China...&lt;/p&gt; 边框颜色 123&lt;h1 style=&quot;border:2px solid Tomato;&quot;&gt;Hello World&lt;/h1&gt;&lt;h1 style=&quot;border:2px solid DodgerBlue;&quot;&gt;Hello World&lt;/h1&gt;&lt;h1 style=&quot;border:2px solid Violet;&quot;&gt;Hello World&lt;/h1&gt; 颜色值 使用RGB值、HEX值、HSL值、RGBA值或者HSLA值来指定颜色。123456&lt;h1 style=&quot;background-color:rgb(255, 99, 71);&quot;&gt;...&lt;/h1&gt;&lt;h1 style=&quot;background-color:#ff6347;&quot;&gt;...&lt;/h1&gt;&lt;h1 style=&quot;background-color:hsl(9, 100%, 64%);&quot;&gt;...&lt;/h1&gt;&lt;h1 style=&quot;background-color:rgba(255, 99, 71, 0.5);&quot;&gt;...&lt;/h1&gt;&lt;h1 style=&quot;background-color:hsla(9, 100%, 64%, 0.5);&quot;&gt;...&lt;/h1&gt;直接使用RGB：rgb(red, green, blue) 使用RGBA：有不透明度的RGB 背景12345678910111213body &#123; background-color: lightblue;/* 背景色 */ opacity: 0.3;/* 不透明度 */ background-image: url(&quot;paper.gif&quot;);/* 背景图像 */&#125;/* 以及 */body &#123; background-image: url(&quot;tree.png&quot;); background-repeat: no-repeat; background-position: right top; background-attachment: fixed;&#125; 简写：123body &#123; background: #ffffff url(&quot;tree.png&quot;) no-repeat right top;&#125;在使用简写属性时，属性值的顺序为： background-color background-image background-repeat background-attachment background-position 轮廓（不同于边框）CSS 拥有如下轮廓属性： outline-style outline-color outline-width outline-offset outline 文本 文本对齐 文本方向 垂直对齐 文字装饰 大小写自动转换 缩进 字符间距 行高 字间距 文字阴影 斜体 粗细 大小 CSS 盒子模型CSS 选择器布局方式CSS3","categories":[],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://blog.wspdwzh.space/tags/%E7%AC%94%E8%AE%B0/"},{"name":"未完待续","slug":"未完待续","permalink":"http://blog.wspdwzh.space/tags/%E6%9C%AA%E5%AE%8C%E5%BE%85%E7%BB%AD/"}]},{"title":"2023年1月20日","slug":"2023年1月20日","date":"2023-01-20T03:42:26.000Z","updated":"2023-01-20T11:36:58.811Z","comments":true,"path":"2023/01/20/2023年1月20日/","link":"","permalink":"http://blog.wspdwzh.space/2023/01/20/2023%E5%B9%B41%E6%9C%8820%E6%97%A5/","excerpt":"","text":"关于阿里云ESC的应用本质是一个可租赁服务器。要用于搭建博客，需要安装Apache（服务器软件）、MariaDB数据库（或者MySql）、PHP，然后通过WordPress完成博客的搭建。 CSS的学习笔记 测试html元素的插入hhhhh 12&lt;p&gt;&lt;b&gt;hhhhh&lt;/b&gt;&lt;/p&gt;","categories":[],"tags":[{"name":"日志","slug":"日志","permalink":"http://blog.wspdwzh.space/tags/%E6%97%A5%E5%BF%97/"}]},{"title":"总结一下hexo-theme-fluid的使用方法","slug":"总结一下hexo-theme-fluid的使用方法","date":"2023-01-17T02:16:35.000Z","updated":"2023-01-17T03:32:21.729Z","comments":true,"path":"2023/01/17/总结一下hexo-theme-fluid的使用方法/","link":"","permalink":"http://blog.wspdwzh.space/2023/01/17/%E6%80%BB%E7%BB%93%E4%B8%80%E4%B8%8Bhexo-theme-fluid%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/","excerpt":"来看看罢？","text":"全局 设置文章默认封面：12post: default_index_img: /img/example.jpg 代码块设置：123456789101112code: copy_btn: true highlight: enable: true line_number: true lib: &quot;highlightjs&quot; highlightjs: style: &#x27;Github Gist&#x27; bg_color: false prismjs: style: &quot;default&quot; preprocess: true copy_btn: 是否开启复制代码的按钮 line_number: 是否开启行号 highlight: 是否开启代码高亮 lib: 选择生成高亮的库，可选项: highlightjs、prismjs，对应下面两组配置，高亮的配置说明具体见主题配置中的注释 首页 大标题：Slogan(打字机)，配置方法是1234index: slogan: enable: true text: 这是一条 Slogan 每篇文章 指定摘要：12# 在文章开头加上：excerpt: 这是摘要 隐藏文章：12# 在文章开头加上：hide: true 手动置顶：12# 在文章开头加上：sticky: 100 在首页的封面：12# 在文章开头加上：index_img: /img/example.jpg 文章头图：12# 在文章开头加上：banner_img: /img/post_banner.jpg 手动置顶：12# 在文章开头加上：sticky: 100 勾选框：1&#123;% cb 文字, 是否已勾选, 是否内联 %&#125; 这是一个勾选框 按钮：1&#123;% btn 链接, text, title %&#125; text 组图：1234567&#123;% gi total n1-n2-... %&#125; ![](url) ![](url) ![](url) ![](url) ![](url)&#123;% endgi %&#125; 特殊页面 About 页","categories":[],"tags":[{"name":"日志","slug":"日志","permalink":"http://blog.wspdwzh.space/tags/%E6%97%A5%E5%BF%97/"}]},{"title":"2023年1月16日","slug":"2023年1月16日","date":"2023-01-16T09:28:49.000Z","updated":"2023-04-23T15:21:12.637Z","comments":true,"path":"2023/01/16/2023年1月16日/","link":"","permalink":"http://blog.wspdwzh.space/2023/01/16/2023%E5%B9%B41%E6%9C%8816%E6%97%A5/","excerpt":"","text":"hexo 使用： 12345678$ cd myblog//首先进入myblog文件夹$ hexo clear//然后清理之前残留的网页$ hexo g//然后生成网页$ hexo d //然后推送到GitHub上 markdown 本身使用 标题：井号，或 “ === ” ， 或 “ —- ” 段落：一行空白行，不应使用 tab 或者空格。 换行：段尾加两个空格，并换行。或者使用 标签。 粗体：两个星号或者两个下划线。 斜体：一个星号或一个下划线。 引用：在段落前添加 &gt; 符号。要引用多个段落，应给空白行也添加 &gt; 符号。 嵌套引用：额外加一个 &gt; 符号。 列表：数字和英文句号。 例如： 阿三大苏打 阿三大苏打 阿三大苏打 无序列表：段前加 - 或 * 或 + 。要保持缩进，需要添加四个空格，或一个 tab 。 代码块：四个空格或一个 tab 。 短单词表示为代码：用 ‘ 包裹。一段代码包含单引号：这段代码应用 `` 包裹。围栏代码块：加入 ``` 包裹。 分割线： 三个星号、三个 - 、三个下划线，并在此之后添加空白行。 链接：中括号包含文本，小括号包含链接。所谓 title ， 即是鼠标悬浮在链接上的时候显示的东西，可以用双引号写在小括号结尾。hhh对于一般的链接，用尖括号框起来即可。https://nga.178.com 图片：![这是图片](/assets/img/philly-magic-garden.jpg &quot;Magic Gardens&quot;) 或者有链接的图片：[![沙漠中的岩石图片](/assets/img/shiprock.jpg &quot;Shi prock&quot;)](https://markdown.com.cn) 如何将 Windows 下文件导入 wsl wsl 中的 /mnt 文件夹，对应 Windows 的计算机。例如，想要引用 D:\\桌面\\临时 里面的 103041518_p0.jpg，对应过来就是 /mnt/d/桌面/临时/103041518_p0.jpg然后复制到 wsl：cp /mnt/d/桌面/临时/103041518_p0.jpg ~/myblog/source/_posts/图片测试 看看效果？ 2023年4月23日更新： 其实可以直接通过Windows资源管理器访问linux文件夹。 Git 的使用 git commit &lt;文件&gt; （然后需要写提交日志） git pull git push","categories":[],"tags":[]}],"categories":[],"tags":[{"name":"日志","slug":"日志","permalink":"http://blog.wspdwzh.space/tags/%E6%97%A5%E5%BF%97/"},{"name":"Test","slug":"Test","permalink":"http://blog.wspdwzh.space/tags/Test/"},{"name":"笔记","slug":"笔记","permalink":"http://blog.wspdwzh.space/tags/%E7%AC%94%E8%AE%B0/"},{"name":"未完待续","slug":"未完待续","permalink":"http://blog.wspdwzh.space/tags/%E6%9C%AA%E5%AE%8C%E5%BE%85%E7%BB%AD/"}]}