{"meta":{"title":"petertan303","subtitle":"welcome？","description":"","author":"peter？","url":"http://Petertan303.github.io","root":"/"},"pages":[{"title":"about","date":"2023-01-16T14:00:14.000Z","updated":"2023-07-01T04:45:36.299Z","comments":false,"path":"about/index.html","permalink":"http://petertan303.github.io/about/index.html","excerpt":"","text":"你好，世界。 你好，陌生人。 我是一名大三电子信息工程在读大学生，对软件硬件都略有涉猎，正在摸索未来的方向。你可以称我为 petertan303 ，也可以称呼我为皮蛋。欢迎通过 peter_tan_303@foxmail.com 联系我。"}],"posts":[{"title":"2023年8月16日","slug":"2023年8月16日","date":"2023-08-16T07:37:59.000Z","updated":"2023-08-16T07:38:10.653Z","comments":true,"path":"2023/08/16/2023年8月16日/","link":"","permalink":"http://petertan303.github.io/2023/08/16/2023%E5%B9%B48%E6%9C%8816%E6%97%A5/","excerpt":"","text":"hello","categories":[],"tags":[]},{"title":"Django 学习","slug":"2023年8月10日","date":"2023-08-10T14:45:07.000Z","updated":"2023-08-16T07:40:39.864Z","comments":true,"path":"2023/08/10/2023年8月10日/","link":"","permalink":"http://petertan303.github.io/2023/08/10/2023%E5%B9%B48%E6%9C%8810%E6%97%A5/","excerpt":"","text":"正在学习 Django，和半吊子 mysql。 顺便练习键盘盲打……之前一直是一指禅野路子，现在眼睛也离不开键盘。 命令行里面使用就是 django-admin，注意不是django。python包是django （正在看网课 前端+MySQL+Django） 顺带一提，Windows快速切换桌面是 win+ctrl+方向 各个文件分工asgi 和 wsgi涉及请求，一个同步一个异步，一般来说不需要更改。 urls对应python函数和网站的url，使用比较频繁。 settings配置文件，需要连接数据库，注册app，等等操作。 initmanage和其他的不在一起，在外面。 最常用的文件。 APP的概念大型项目中的某些功能。不同app可以拥有独立的表结构，html模板，css，不会相互影响。 但是一般来说多app的项目就是比较复杂的了。 可以通过 python manage.py startapp app01 这种形式来创建应用。新应用回合项目本体一样有自己的文件夹。 apps不需要更改 tests单元测试用的 views用于和 urls.py 里面的函数对应，所谓视图函数。 models专门操作数据库，使用orm，可以取代pymysql。 admin默认提供后台管理功能，一般不使用。 主要就是 views 和 models 这两个基本使用步骤 首先需要创建并注册 app：在setting的installed_apps这个列表里面注册，具体来说就是添加字符串，内容为形如 app01.apps.app01config 之类的类，这个类里面应该包含 app01 所需要的注册信息。 然后编写一个 urls 和 apps 的对应关系：编写 urls 文件。 然后编写一个视图函数 views，需要有一个函数 （例如index），这个函数 index 必须有一个参数 request 。这个函数中，可以使用httpresponse()之类的方法返回文字信息，也可以通过更加复杂的方法返回其他信息。 启动 django 程序：使用 python manage.py runserver 总结一下就是一般网站配置 urls 和 views 即可，如果需要访问数据库则需要 models。每一个 url 可以对应一个函数。 模板，和静态文件templates 模板的使用： views文件的函数返回render()，参数为request和html模板文件名，例如return render(request,”asd.html”) 其中，默认情况下，程序会在app的templates目录下寻找html模板文件。如果setting里面配置了TEMPLATES里面的DIRS，则会改变。 静态文件：例如CSS，图片，js静态文件放在app 目录底下的 static 文件夹底下 一般来说， static 文件夹底下还会有css，img，plungins，js等等细分文件，方便管理 注意少使用绝对路径，可以使用 { % load static % } 之类的 #","categories":[],"tags":[]},{"title":"VITS 论文阅读-3","slug":"VITS-论文阅读-3","date":"2023-06-14T15:49:51.000Z","updated":"2023-06-14T16:58:42.498Z","comments":true,"path":"2023/06/14/VITS-论文阅读-3/","link":"","permalink":"http://petertan303.github.io/2023/06/14/VITS-%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-3/","excerpt":"","text":"VITS 本质是一个以最大化变分下界为目标的条件VAE. 这个变分下界表达式为 \\log p_{\\theta}(x \\mid c) \\geq \\mathbb{E}_{q_{\\phi}(z \\mid x)}\\left[\\log p_{\\theta}(x \\mid z)-\\log \\frac{q_{\\phi}(z \\mid x)}{p_{\\theta}(z \\mid c)}\\right]={似然函数}[log{数据点 x 的似然函数} - log({近似后验分布} / {条件c下潜变量z的先验分布})] 条件VAE公式（a conditional VAE formulation） 目标:”变分下界”，证据下界（ELBO） 重建损失 KL收敛 基于变分推理的对准估计（alignment estimation derived from variational inference）- 提高合成质量的对抗性训练（adversarial training for improving synthesis quality） 总损失函数是各个损失函数相加. 条件VAE公式输入语料 $x_{mel}$ ，提取 x 的 mel 频谱(梅尔语谱图, 用于音频处理). (人耳对频率的感受是对数的(logarithmic), 因此不能线性处理, 需要梅尔语谱图) 通过解码器将潜在变量 z 上采样, 转到波形域 $\\hat{y}$.将 $\\hat{y}$ 变换到 mel 频谱 $\\hat{x}_{mel}$ . 对比 $x{mel}$ 和 $\\hat{x}{mel}$ ,差值就是重建损失. 这个重建损失可以看作一个拉普拉斯分布, 但这个估计不需要可训练的参数，因为它只使用 STFT(短时傅立叶变换) 和线性投影到 mel 标度上; 估计仅在训练期间使用，推理不需要. 重建损失需要求一个变分下界, \\mathbb{E}_{q_{\\phi}(z \\mid x)}\\left[\\log p_{\\theta}(x \\mid z)-\\log \\frac{q_{\\phi}(z \\mid x)}{p_{\\theta}(z \\mid c)}\\right]训练需要保证这个下界最大. 先验编码器 c 的输入条件, 由 从文本中提取的音素$c_{text}$, 和 音素与潜在变量之间的对齐 A 组成。 变分推理的对准估计对抗性训练训练过程有 $x_{mel}$ , 有潜变量 z, 可以得到重建损失.","categories":[],"tags":[]},{"title":"VITS 论文阅读-2","slug":"VITS-论文阅读-2","date":"2023-06-14T07:53:57.000Z","updated":"2023-06-25T14:56:53.744Z","comments":true,"path":"2023/06/14/VITS-论文阅读-2/","link":"","permalink":"http://petertan303.github.io/2023/06/14/VITS-%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-2/","excerpt":"","text":"方法所提出的方法主要在前三小节中描述： 条件VAE公式（a conditional VAE formulation） 基于变分推理的对准估计（alignment estimation derived from variational inference） 提高合成质量的对抗性训练（adversarial training for improving synthesis quality） 图1a和1b分别显示了我们方法的训练和推理过程。从现在起，我们将把我们的方法称为端到端文本到语音（VITS），具有对抗性学习的变分推理。 训练和推理流程如下： 条件推理（conditional inference）条件VAE公式（a conditional VAE formulation）。 目标为一个”变分下界”，也叫证据下界（ELBO）。详细说就是“intractable marginal log-likelihood ”棘手边缘拟合对数似然的变分下界。 如图，$\\log p{\\theta}(x \\mid c)$的变分下界为$\\mathbb{E}{q{\\phi}(z \\mid x)}\\left[\\log p{\\theta}(x \\mid z)-\\log \\frac{q{\\phi}(z \\mid x)}{p{\\theta}(z \\mid c)}\\right]$。 L_{\\text {recon }}=\\left\\|x_{mel}-\\hat{x}_{mel}\\right\\|_{1}下界：似然【数据点x的似然函数 - （近似后验分布 / 条件c下潜变量z的先验分布）的对数】 训练损失即负的ELBO。 也可以看作为重建损失 + KL散度，这在潜变量z服从近似后验分布时成立。 重建损失作为重建损失中的目标数据点，我们使用mel频谱图而不是原始波形，由 $x{mel}$ 表示。我们通过解码器将潜在变量z上采样到波形域 $\\hat{y}$ ，并将 $\\hat{y}$ 变换到融合谱图域 $\\hat{x}{mel}$ 。然后，预测的和目标mel谱图之间的L1损失被用作重建损失： L_{\\text {recon }}=\\left\\|x_{mel}-\\hat{x}_{mel}\\right\\|_{1}这可以被视为假设数据分布的拉普拉斯分布并忽略常数项的最大似然估计。我们定义了mel声谱图域中的重建损失，以通过使用近似人类听觉系统响应的mel标度来提高感知质量。注意，根据原始波形的mel谱图估计不需要可训练的参数，因为它只使用STFT和线性投影到mel标度上。此外，估计仅在训练期间使用，而不是推理。 在实践中，我们不对整个潜在变量z进行上采样，而是使用部分序列作为解码器的输入，这是用于高效端到端训练的窗口生成器训练。 KL收敛先验编码器c的输入条件由从文本中提取的音素$c_{text}$和音素与潜在变量之间的对齐 A 组成。 对齐是一个硬单调注意力矩阵，其$\\mid c_{text}\\mid \\times \\mid z\\mid$维度表示每个输入音素扩展到与目标语音时间对齐的长度。由于对齐没有基本事实标签，我们必须在每次训练迭代时估计对齐。 在我们的问题设置中，我们的目标是为后验编码器提供更多的高分辨率信息。因此，我们使用目标语音$x_{lin}$的线性尺度频谱图作为输入，而不是mel频谱图。注意，修改后的输入并不违反变分推理的性质。那么KL分歧是： “因子分解正态分布”用于参数化我们的先验和后验编码器。 我们发现，增加先验分布的表现力对于生成真实样本很重要。因此，我们应用归一化流 f ，该流允许在因子分解的正态先验分布之上，根据变量变化规则，将简单分布可逆变换为更复杂的分布。 路线估计（Alignment Estimation）基于变分推理的对准估计（alignment estimation derived from variational inference）。 单调对齐搜索（MONOTONIC ALIGNMENT SEARCH）为了估计输入文本和目标语音之间的对齐A，我们采用单调对齐搜索（MAS）。 这是一种搜索对齐的方法，其最大化了由归一化流 f 参数化的数据的可能性。 因为人类按顺序阅读文本，不跳过任何单词，候选比对（ candidate alignments）被限制为单调且不跳过。 为了找到最佳对准，Kim等人（2020）使用动态规划。在我们的这个情况下直接应用MAS是困难的，因为我们的目标是ELBO，而不是确切的对数似然。因此，我们重新定义MAS，以找到最大化ELBO的对齐。 这个过程简化为找到最大化潜在变量z的对数似然的对齐。 但事实上，无论修不修改，都可以工作。因此我们使用的是原始MAS。 文本时长预测器（DURATION PREDICTION FROM TEXT）我们可以通过对估计的对齐$\\sum{j}^{} A{i,j}$的每行中的所有列求和来计算每个输入token$d_i$的持续时间。但持续时间可以用来训练确定性的持续时间预测器，但它不能表达一个人每次以不同的语速说话的方式。 为了生成类似人类的语音节奏，我们设计了一个随机持续时间预测器，使其样本遵循给定音素的持续时间分布。 随机持续时间预测器是一种基于流的生成模型，通常通过最大似然估计进行训练。然而，最大似然估计的直接应用是困难的，因为每个输入音素的持续时间是 1）离散整数，其需要被去量化（dequantized）以使用连续归一化流。 2）标量，其由于可逆性而无法进行高维变换。 我们应用变分去量化和变分数据扩充来解决这些问题。 具体地说，我们引入了两个随机变量 u 和 v ，它们具有与持续时间序列 d 相同的时间分辨率和维度，分别用于变分去方程化和变分数据扩充。 我们将u的支持度限制为[0, 1），使得差$d-v$变成了一个正实数序列。 我们按通道连接 v 和 d ，以生成更高维的潜在表示。、 我们通过近似后验分布$q(u,v|d,c{text})$对这两个变量进行采样。由此产生的目标是音素持续时间的对数似然的变分下界。训练损失$L{dur}$是负变分下界。 我们将阻止输入梯度反向传播的”停止梯度算子”应用于输入s，保证持续时间预测器的训练不会影响其他模块的训练。 而取样程序相对简单：通过随机持续时间预测器的逆变换，从随机噪声中采样音素持续时间，然后将其转换为整数。 对抗训练提高合成质量的对抗性训练（ adversarial training for improving synthesis quality）。 为了在我们的学习系统中采用对抗性训练，我们添加了一个鉴别器D，用于区分解码器G生成的输出和实际的波形y。 在这项工作中，我们使用了两种成功应用于语音合成的损失类型：一种是对抗性训练的最小二乘损失函数，另一种是训练生成器的附加特征匹配损失。 T表示鉴别器中的层的总数，并且$D^{l}$输出具有$N_{l}$个特征的鉴别器的第l层的特征图。 值得注意的是，特征匹配损失可以被视为在鉴别器的隐藏层中测量的重建损失，该重建损失被建议作为VAE的逐元素重建损失的替代方案。 最终的损失函数所有损失函数直接相加。 模型架构总体架构由后验编码器、先验编码器、解码器、鉴别器和随机持续时间预测器组成。后验编码器和鉴别器仅用于训练，而不用于推理。 后验编码器对于后验编码器，我们使用WaveGlow和Glow-TTS中使用的非因果WaveNet残差块, “the non-causal WaveNet residual blocks”。 WaveNet残差块由具有多个扩张卷积层（ dilated convolutions ），每层含有门控激活单元（gated activation unit）和跳跃连接（ skip connection）。块上方的线性投影层产生正态后验分布的均值和方差。 对于多个说话人的情况，我们在残差块中使用全局条件反射（global conditioning）来添加说话人embedding。 先验编码器先验编码器包括处理输入音素$c_{text}$的文本编码器、改进先验分布的灵活性的归一化流 f 。 文本编码器是一种transformer编码器（transformer encoder），它使用相对位置表示（relative positional representation）而不是绝对位置编码（absolute positional encoding）。 我们可以通过文本编码器和文本编码器上方的线性投影层，从 $c{text}$ 中获得 hidden representation $h{text}$ ，该线性投影层产生用于构建先验分布的均值和方差。 归一化流(normalizing flow)是仿射耦合层（affine coupling layers）堆积而成，包含 WaveNet 残差块的堆栈。为了简单起见，我们将归一化流设计为雅可比行列式为1的保体积变换（a volume-preserving transformation with the Jacobian determinant of one）。 这个变换来自于 GLOW. https://arxiv.org/abs/1807.03039 对于多说话人设置，我们通过全局条件，将说话人embedding加入到归一化流中的残差块中。 解码器解码器本质上是HiFi GAN V1生成器。它由”反条件姿态卷积”堆积组成，每个卷积后面，都有一个多接收场融合模块（MRF）。 MRF的输出是具有不同感受野大小的残差块的输出之和。 对于多说话人设置，我们添加一个转换说话人embedding的线性层，并将其添加到输入潜在变量z中。 判别器我们遵循HiFi GAN中提出的多周期鉴别器的鉴别器架构。 多周期判别器是基于马尔可夫窗的子鉴别器的混合，每个子判别器对输入波形的不同周期模式进行操作。 随机持续时间预测器随机持续时间预测器根据条件输入的 $h_{text}$ 估计音素持续时间的分布。 为了有效地参数化随机持续时间预测器，我们将残差块，与扩张和深度可分离的卷积层叠加。我们还将神经样条流（neural spline flows）应用于耦合层，其通过使用单调有理二次样条（monotonic rational-quadratic splines）采用可逆非线性变换的形式。 与常用的仿射耦合层相比，神经样条流的参数相似数量，但提高了变换的表现力。 对于多说话人设置，我们添加了一个线性层来转换说话人embedding，并将其添加到输入 $h_{text}$ 中。 个人理解训练过程使用了： 后验编码器 先验编码器 解码器 鉴别器 随机持续时间预测器 也就是所有部件。 $x_{lin}$ 为线性频谱, 通过后验编码器, flow, 解码器, 输出预测的原始波形 $\\hat{y}$ . $c{text}$ 为从文本中提取的音素, 通过文本编码器得到 $h{text}$ , 投影到 z 所服从的正态分布, 正态分布的两个参数是 $\\mu{\\theta}$ 和 $\\sigma{\\theta}$ . 然后使用单调对齐搜索( MAS )估计潜在变量之间的对齐 A ,最大化由归一化流 f 参数化的数据的可能性. 对齐 A 是一个硬单调注意力矩阵，其$\\mid c{text}\\mid \\times \\mid z\\mid$维度, 表示每个输入音素$c{text}$扩展到与目标语音时间对齐的长度。 核心的 flow 是一堆 z 和一堆对应的 $fz(z)$ .对于 $\\theta$ 层的 $z$, 服从的正态分布系数是 $\\mu{\\theta}$ 和 $\\sigma_{\\theta}$ , $f_{\\theta}(z)$ , 推理过程使用了： 先验编码器 解码器 随机持续时间预测器 也就是不使用后验编码器和判别器。 $c_{text}$ ，phoneme（音素），作为输入。 经过text encoder，文本编码器，和线性投影层，得到 $h_{text}$ ，hidden representation，和投影。 $h_{text}$ 使用随机时间预测器，逆变换，从随机噪声中提取持续时间。 取样程序：通过随机持续时间预测器的逆变换，从随机噪声中采样音素持续时间，然后将其转换为整数，得到向量 $d$ 。 然后投入先验编码器，先验编码器包括文本编码器和归一化流，文本编码器是一个transformer，归一化流进行估计，参数化对先验概率q的逼近。 涉及的论文与概念归一化流本质是一个生成模型。一个基于可能性的生成模型。 （自回归模型, 生成对抗网络(GAN)的一部分, 变分自动编码器（VAE）也是自回归模型。） Flow 将简单分布（易于采样和评估密度）映射到复杂分布（通过数据学习）。但是方便起见，实际使用时就是想办法得到一个encoder将输入x编码为隐变量z，并且使得z服从标准正态分布。 得益于flow模型的精巧设计，这个encoder是可逆的，从而我们可以立马从encoder写出相应的decoder（生成器）出来，因此，只要encoder训练完成，我们就能同时得到decoder，完成生成模型的构建。 x 和 z 应该有以下关系： 首先， $X=f(Z)$ ， $Z=f^{-1}(X)$ 。也就是说从 Z 映射到 X ，这个映射确定而可逆。 然后有： 变量变换定理(change of variable theorem): 有 $p_z(z)$ 和 $p_x(x)$ ,有 $f(z)=x$ ,如果要通过 $f$ 建立 $p_z(z)$ 和 $p_x(x)$ 之间的关系，可以将 $p_z(z)$ 和 $p_x(x)$ 使用微分方法借取一小段，直接计算一小段的体积，并对比，并按照体积的比例进行缩放，缩放函数在每个点上组合起来就是 $f(z)=x$ 。 p_x(x)=p_z(z) ( f^{-1}(x)) \\mid {det}( \\frac{\\partial f^{-1}(x)}{\\partial x} =p_z(z) ( f^{-1}(x)) \\mid {det}( \\frac{\\partial f(x)}{\\partial x}^{-1} ) \\mid其中，由于可逆矩阵 $det(A^{-1})=det(A)^{-1}$ 。因此对于 $z=f^{-1}(x)$ ，有： p_x(x)=p_z(z) \\mid {det}( \\frac{\\partial f(z)}{\\partial z} ) \\mid对于 $\\frac{\\partial f^{-1}(x)}{\\partial x}$ ，这是一个 n 维矩阵。这个矩阵记做雅可比矩阵。 保体积： $\\mid {det}( \\frac{\\partial f(z)}{\\partial z} ) \\mid =1$ ，则从 z 到 x 的映射是保体积的。换言之，变换后的 $p_x$ 和 原始的 $p_z$ 有同样的体积，或者说volume。 (体积指的就是行列式.) 流模型核心条件： 模型可逆 对应的雅可比行列式容易计算 因此本文将其设计为雅可比行列式为1的保体积变换（a volume-preserving transformation with the Jacobian determinant of one） 有“边界可能性” $p_x(x)$ ，满足 p_x(x;\\theta )=p_z(f_{\\theta }^{-1}(x)) \\mid {det}( \\frac{\\partial f_{\\theta }^{-1}(x)}{\\partial x} ) \\mid名称“归一化流”可以解释如下： “归一化”意味着变量的变化在应用可逆变换后给出归一化密度（normalized density）。 “流”意味着可逆变换可以相互组合，以创建更复杂的可逆变换。 存在多个隐变量 z, 存在对应数量的变换函数 f(z), 而最后一个 z 对应出来就是 x. 优化函数: logp_k(x^i)=logp_z(z^i)+\\sum_{h=1}^{K}log\\mid det(J_{G^{-1}})\\mid =logp_z(G^{-1}(x^i))+\\sum_{h=1}^{K}log\\mid det(J_{G^{-1}})\\mid这是 $G^{-1}$ 训练的目标: 最大化这个式子的值即可. 实际使用 G, 将其逆转即可. 平面流vits使用的流模型the non-causal WaveNet residual blocks used in WaveGlow (Prenger et al., 2019) and Glow-TTS (Kim et al., 2020).","categories":[],"tags":[]},{"title":"fpga 电梯项目","slug":"fpga-电梯项目","date":"2023-06-13T05:17:56.000Z","updated":"2023-06-13T07:20:34.254Z","comments":true,"path":"2023/06/13/fpga-电梯项目/","link":"","permalink":"http://petertan303.github.io/2023/06/13/fpga-%E7%94%B5%E6%A2%AF%E9%A1%B9%E7%9B%AE/","excerpt":"","text":"累死我了。昨天下午到今天中午。 累不累不要紧，主要是这是期末复习周。分秒寸金的复习周。 吐槽两句调试：vivado，verilog的开发方式和其他语言不太一样。调试的话，要么仿真，要么建立一个debug core调试核，要么下板。一开始，觉得很快就能做完；觉得编写仿真文件，或者现学调试不合算，我选择直接下板。然后被这个反复下板浪费的时间折磨到了。 而且三阶段，一个是分析，一个是硬件，一个是比特流，每一项都花时间，每一项都走不开，不能像是“让程序慢慢跑，吃个饭先”之类的。 下次一定仿真。 暂时不要相信gpt的复杂代码水平基于python或c或go之类的几十行一两百行还好，这种复杂的程序真的是难为gpt这种泛用模型了。尤其是verilog还是个非主流语言。 而且，我这个项目，是网络上已经有不少现成的，gpt是将它们按照我的要求缝在了一起。有的地方缝错位了，有的地方不该缝的缝上了。还有有的地方我以为缝错了其实缝对了。导致修改花了绝大多数时间。 不过，要我自己从零写，不知道要花多少时间。我没这个时间也没这个精力再写一次。 遗憾：fpga开发板贵的一批。学校给了我使用的机会，但我没有珍惜。 下次一定。 基本架构有以下几个部分： top：顶层文件 key_debounce：按键消抖 matrix_key：矩阵键盘。实际使用四个键，属于是卵用没有，只能添乱。 switch_control：拨码开关控制（并输出floor查看运行状态） clk_div：理论有用但实际没用，全他妈用的是自己分频…………这个模块对我的唯一贡献，是给led_control模块塞了一个花了我好长时间的bug…… seg_control：控制数码管显示。大改过。 led_control：控制led和电梯上下楼，名副其实的灵魂模块。 beep_control：一个意义不明的模块，我不知道gpt本来是想做什么，反正它在我这里就是一个运行指示器。 top里面重要的reg： row行信号，设置为1110 一开始设的是0001，纳闷了好久。 几个led灯 key_in和key_out floor和floor_out floor是寄存器，作为模块输入，不能作为输出。 要改变floor的值，需要通过一个wire，floor_out来转接。 我在top里面加了一句always @(posedge clk) floor&lt;=floor_out; endmodule，用来将这两个直接相连。 模块介绍top：顶层文件模块例化，将floor_out和floor链接。 `timescale 1ns / 1ps不知道有没有用，总之加上就是了。之前因为这一句翻过车。 总之就是要把各个变量对应好，不要出现什么时钟频率错误，in和out变量错误什么的。 key_debounce：按键消抖基本原理是检测到按键按下，然后等20个时钟周期再看看，如果还是按下，那就真的按下了，输出按键信息。 switch_control：拨码开关控制（并输出floor查看运行状态）其实也是个没卵用的模块，把二位的led_status分割成一个rst一个start。我是不知道为什么我不在xdc里面直接定义rst和start……可能是闲得蛋疼。 但是我还是保留了，毕竟能正常工作，还能加点其他功能，不在其他模块碍眼。例如打印floor状态。 clk_div：理论有用但实际没用，全他妈用的是自己分频…………这个模块对我的唯一贡献，是给led_control模块塞了一个花了我好长时间的bug……字面意思，理论上应该用这个控制所有时钟分频，但是我的模块用分频的少，所以都自己分了。 seg_control：控制数码管显示。大改过。大改指的是把本来的全部注释掉然后重写。 主要是因为我改了matrix_key，没用，导致编码从8421变成了独热码。而且我的floor只有两位，按键四个，不需要那么复杂的东西。 两个数码管，交替选择，选择时显示内容。 如果不使用分频，会导致残影。理论上需要专门的方法去除，但是我懒狗，我是把频率降一下就当没看到残影。我是用的是1000hz。 led_control：控制led和电梯上下楼，名副其实的灵魂模块。首先是判断key_in，如果非零，那就说明按键按下。在这个情况下，需要根据floor和key的内容选择新的floor。 松开按键，则key就会归零，于是针对key我使用了一个key_reg保存上一次的输入。所有判断都是在计时器计满之后执行的；都是基于上一次key的输入来选择判断。 好吧，实际用到key_reg的只有一处，控制led灯那里。要求是： 1234567891011121314151617181920led_out0：按下KEY0键，若电梯不在1楼，则LED0亮；电梯到达1楼后，LED0指示灯灭掉由于按下key0，电平会从高变低，因此是：若为一楼停靠：00：led0灭，为0若为二楼停靠，或者其他状态：key0取反led_out1：按下KEY1键, 若电梯不在2楼，则LED1亮,电梯到达2楼后，LED1指示灯灭掉.由于按下key1，电平会从高变低，因此是：若为一楼停靠，或其他状态：key1取反，若key1按下，则为1，若未按下，则为0若为二楼停靠：01：led1灭，为0led_out2：电梯在2楼，按KEY2键, 则LED2亮，电梯到1楼后LED2灭01、11：key2取反00、10：设0led_out3：电梯在1楼，按KEY3键, 则LED3亮，电梯到2楼后LED3灭。00、10：key3取反（一楼、一楼到二楼）01、11：设0 本来有很多用了key_reg的，砍掉了。 还有就是运行时灯的流动，12led_reg，五个灯，0.1秒移动一次，在电梯运行时移动。led_reg则是对应G5～T4，从左到右分别01234代码:122&#x27;b10: led_reg &lt;= &#123;led_reg[3:0],led_reg[4]&lt;=1&#125;; //如果电梯上行，LED11至LED7从左到右轮流点亮2&#x27;b11: led_reg &lt;= &#123;led_reg[0]&lt;=1,led_reg[4:1]&#125;; //如果电梯下行，LED11至LED7从右到左轮流点亮注意不是流水灯，但大差不差。 beep_control：一个意义不明的模块，我不知道gpt本来是想做什么，反正它在我这里就是一个运行指示器。改了，改成了到站叫一声。 使用了一个timer_start一个beep_enable来分别控制counter和timer，timer控制时长，counter控制频率。","categories":[],"tags":[]},{"title":"Transformer(Attention机制)论文阅读-2","slug":"Transformer-Attention机制-论文阅读-2","date":"2023-06-13T05:16:37.000Z","updated":"2023-06-14T11:21:49.785Z","comments":true,"path":"2023/06/13/Transformer-Attention机制-论文阅读-2/","link":"","permalink":"http://petertan303.github.io/2023/06/13/Transformer-Attention%E6%9C%BA%E5%88%B6-%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-2/","excerpt":"","text":"结构编码器encoder包含了6个相同的层组成的“stack”，每层两个子层，一个是多头自注意力机制，一个是“simple, positionwise fully connected feed-forward network”简单的、互联的前馈网络。 在每子层的周围使用残差连接、层归一化。“We employ a residual connection around each of the two sub-layers, followed by layer normalization.”，也就是每层的输出为 LayerNorm(x + Sublayer(x))。 所有层被标准化为512维的输出。 解码器decoder同样包含了6个相同的层组成的“stack”，但每层三个子层，一个是多头自注意力机制，一个是多头编码器-解码器注意力机制，“performs multi-head attention over the output of the encoder stack”，一个是简单的、互联的前馈网络。 其中的自注意力层和编码器有所不同，不会关注当前位置后面的位置。 和编码器相同，在每子层的周围使用残差连接、层归一化。“We employ a residual connection around each of the two sub-layers, followed by layer normalization.”，也就是每层的输出为 LayerNorm(x + Sublayer(x))。所有层被标准化为512维的输出。 注意力机制本质是将查询（query）和一组键值对（a set of key-value pairs，是键和值）映射到输出。 换言之，这个键和这个值是配对的，查询是额外的。 输出是值的加权和，权重由查询和对应关键字兼容性函数确定。（weight assigned to each value is computed by a compatibility function of the query with the corresponding key.） 将三种向量各自组成查询（Q），键（K），值（V），然后三个矩阵变一个Output。 其中，求权重的“Scaled Dot-Product Attention”的公式为： 即计算QKV三者输出。假设Q和K等长，长度dk，V长度dv，计算过程： 求QK余弦相似度：求夹角余弦值，相当于判断向量夹角，角度越小越相似。 余弦相似度除(dk)^(1/2)（长度） softmax得到权重，即是attention。 attention权重和V相乘，每一行就是需要的输出。 Scaled Dot-Product Attention属于点乘注意力机制，并在一般点乘注意力机制的基础上，加上了scaled。scaled是指对注意力权重进行缩放，以确保数值的稳定性。 常用注意力机制有additive attention、dot-product (multiplicative) attention，加性注意力和点积注意力。Scaled Dot-Product Attention属于点积注意力，但Scaled Dot-Product Attention 比传统的点积注意力多了一个根号dk的部分。 加性注意力使用具有单个隐藏层的前馈网络来计算兼容性函数。 虽然加与乘注意力两者在理论复杂性上相似，但点积注意力在实践中要快得多，而且更节省空间，因为它可以使用高度优化的矩阵乘法代码来实现。 引入根号dk的原因：弥补点积注意力相对于加法注意力的缺陷：对于较大的dk值，点积的大小会变大，从而将softmax函数推向具有极小梯度的区域。根号dk可以抵消这个影响。 多头注意力从“performing a single attention function with dmodel-dimensional keys, values and queries” 到“linearly project the queries, keys and values h times with different, learned linear projections to dk, dk and dv dimensions, respectively，On each of these projected versions of queries, keys and values we then perform the attention function in parallel, yielding dv-dimensional output values. These are concatenated and once again projected, resulting in the final values.” （projected，含预计和投影的意思。） 翻译一下就是，本来是单头注意力，只有一个注意力函数。 而多头注意力是用不同的、通过机器学习学到的线性投影，将查询、键和值（三个向量）分别线性投影到dk、dk和dv维度h次，也就是h个注意力头。然后在查询、键和值的每个投影版本上，我们并行执行注意力函数，生成dv维输出值。这些被连接起来，组成多头，并再次投影，得到最终值。 多头注意力允许模型联合关注来自不同位置的不同表示子空间的信息。对于一个单一的注意力头而言，做不到，因为单头注意力使用的平均会抑制这种情况。 “头”指的是某次线性投影得到的注意力。 团队在测试的时候使用了八个头，h=8，QK长度均为64，d(model)则是h与64相乘。 总计算成本比较低，因为每个头的维数并不高，而且还可以并行计算。 Transformer中注意力机制的使用编码器-解码器注意力在解码器中使用。 查询来自上一个解码器层，键和值来自编码器的输出。 这种机制模仿了序列到序列模型中的典型编码器-解码器注意力机制，允许解码器中的每一个位置关注输入序列中的所有位置。 编码器自注意力所有的键、值和查询都来自同一个地方，也就是是编码器中前一层的输出。 这种机制允许编码器中的每个位置关注编码器的前一层中的所有位置。 解码器自注意力基本同编码器，但是解码器只能关注半边的信息，“prevent leftward information flow in the decoder to preserve the auto-regressive property” 位置前馈网络Position-wise Feed-Forward Networks每层都包含一个全连接神经网络。“applied to each position separately and identically”，分别且相同地应用于每个位置。 这个网络包含了两个线性变换，一个是relu激活。 不同层网络结构相同但参数不同。 这个网络也可以看作是一个卷积核大小为1的两个卷积。实验者设置的输入和输出的维度为dmodel=512，内层的维度为dff=2048。 Embeddings and Softmaxembedding含义为嵌入层，可以把信息选择性保留，缩小矩阵大小（稀疏矩阵）抽象但更容易处理，即降维；也可以升维。 transformer中的embedding是输入token和输出token转换为维度为dmodel的向量，还使用普通线性变换和softmax函数，将解码器的输出转换为预测的下一个token概率。 transformer中两个嵌入层和预softmax线性变换之间共享相同的权重矩阵。在embedding层中，将这些权重和根号dmodel相乘。 位置编码positional encodings只用注意力机制，不使用卷积和递归，因此需要引入相关位置信息，计算序列中的token。 每层的复杂度、顺序操作、最大路径长度 n是序列长度，d是表示维度，k是卷积的核大小，r是限制自注意中邻域的大小。 transformer将位置编码和“编码器和解码器堆栈底部的‘输入embedding’”结合。（指编码器解码器都有多层，这里是加到最底下一层的embedding子层） 位置编码与embedding具有相同的维度dmodel，因此可以将两者进行直接处理。有多种位置编码可以选择，可以选择让机器学习编码，也可以直接使用固定方式。而本文使用的是不同频率正余弦函数。 输入参数中，pos是位置，i是尺寸。 可以理解为将每个位置和频域上的冲激相对应起来。之所以选择正余弦函数，是对pos的任何偏移，都可以将函数转化为没有偏移的正余弦函数。 自注意力机制和递归、卷积对比三个方面： 每层的总计算复杂度可以并行化的计算量网络中长程依赖项之间的路径长度（path length between long-range dependencies in the network）网络需要学习长程依赖关系，而影响学习这种依赖性的能力的一个关键因素是前向和后向信号在网络中必须经过的路径的长度，越短就越容易学习。 研究时统计了由不同层类型组成的网络中任意两个输入和输出位置之间的最大路径长度： 每层的复杂度、顺序操作、最大路径长度 n是序列长度，d是表示维度，k是卷积的核大小，r是限制自注意中邻域的大小。12345自关注层通过恒定数量的顺序执行操作连接所有位置，而递归层需要O（n）个顺序操作。就计算复杂性而言，当序列长度n小于表示维度d时，自注意层比递归层更快，这在机器翻译中最先进的模型使用的句子表示中最为常见，例如分词[38]和字节对[31]表示。为了提高涉及非常长序列的任务的计算性能，可以将自注意限制为仅考虑输入序列中以相应输出位置为中心的大小为r的邻域。这将使最大路径长度增加到O（n＝r）。我们计划在未来的工作中进一步研究这种方法。核宽度k＜n的单个卷积层并不连接所有输入和输出位置对。在连续核的情况下，这样做需要O（n=k）个卷积层的堆栈，或者在扩张卷积的情况下需要O（logk（n））[18]，从而增加网络中任意两个位置之间最长路径的长度。卷积层通常比递归层贵k倍。然而，可分离卷积[6]将复杂性显著降低到O（k n d+n d2）。然而，即使k=n，可分离卷积的复杂性也等于自注意层和逐点前馈层的组合，这是我们在模型中采用的方法。作为副作用，自我关注可以产生更多可解释的模型。我们从我们的模型中检查注意力分布，并在附录中给出和讨论示例。个体注意力负责人不仅清楚地学会了执行不同的任务，而且许多人似乎表现出与句子的句法和语义结构有关的行为。 自注意力层：通过恒定数量的顺序执行操作连接所有位置 递归层：需要O（n）个顺序操作 当序列长度n小于表示维度d时，自注意层比递归层更快 为了提高涉及非常长序列的任务的计算性能，可以将自注意限制为仅考虑输入序列中以相应输出位置为中心的大小为r的邻域。这将使最大路径长度增加到O（n＝r）。我们计划在未来的工作中进一步研究这种方法。 核宽度k＜n的单个卷积层并不连接所有输入和输出位置对。在连续核的情况下，这样做需要O（n=k）个卷积层的堆栈，或者在扩张卷积的情况下需要O（logk（n））[18]，从而增加网络中任意两个位置之间最长路径的长度。卷积层通常比递归层贵k倍。然而，可分离卷积[6]将复杂性显著降低到O（k n d+n d2）。然而，即使k=n，可分离卷积的复杂性也等于自注意层和逐点前馈层的组合，这是我们在模型中采用的方法。 另外，自注意力可以产生更多可解释的模型。 我们从我们的模型中检查注意力分布，并在附录中给出和讨论示例。单个的注意力头不仅清楚地学会了执行不同的任务，而且许多注意力头似乎表现出与句子的句法和语义结构有关的行为。 训练使用BLEU评价效果。","categories":[],"tags":[]},{"title":"VITS论文阅读","slug":"VITS论文阅读","date":"2023-06-12T06:53:17.000Z","updated":"2023-06-12T08:25:00.512Z","comments":true,"path":"2023/06/12/VITS论文阅读/","link":"","permalink":"http://petertan303.github.io/2023/06/12/VITS%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","excerpt":"","text":"概览VITS，Variational Inference with adversarial learning for end-to-end Text-to-Speech，一个很牛逼的变分推理 + 对抗学习的端到端 TTS 网络。 基于《Attention is all you need》中的Transformer结构，额外添加了一个持续时长预测器。 基本结构基于 transformer，也有编码器，解码器。但是编码器做了文本编码器、先验编码器、后验编码器的区分。 基本组成部分： • 文本编码器（Text Encoder）：将输入的文本序列转换为文本特征序列，使用transformer的编码器结构。 • 后验编码器（Posterior Encoder）：将文本特征序列和真实的语音特征序列（如梅尔频谱）作为输入，使用transformer的编码器结构，输出一个后验潜变量分布。 • 先验编码器（Prior Encoder）：将文本特征序列作为输入，使用transformer的编码器结构，并在每个层后面加入一个标准化流层（Normalizing Flow Layer），输出一个先验潜变量分布。 • 语音解码器（Speech Decoder）：将文本特征序列和从先验或后验分布中采样得到的潜变量作为输入，使用transformer的解码器结构，并在最后一层后面加入一个对抗损失层（Adversarial Loss Layer），输出一个语音特征序列。 • 持续时间预测器（Duration Predictor）：将文本特征序列作为输入，使用一个全连接层和一个softmax层，输出一个持续时间序列，表示每个文本单元对应的语音帧数。 VITS的模型训练过程包含以下几个损失函数： • 重建损失（Reconstruction Loss）：衡量语音解码器输出的语音特征序列和真实的语音特征序列之间的差异，使用L1损失或MSE损失。 • 对抗损失（Adversarial Loss）：衡量语音解码器输出的语音特征序列是否能够被一个判别器（Discriminator）区分出真假，使用Wasserstein距离或GAN损失。 • KL散度损失（KL Divergence Loss）：衡量后验潜变量分布和先验潜变量分布之间的差异，使用KL散度公式。 • 持续时间损失（Duration Loss）：衡量持续时间预测器输出的持续时间序列和真实的持续时间序列之间的差异，使用MSE损失或二值交叉熵损失。 训练过程的网络12345671.将输入的文本序列和真实的语音特征序列（如梅尔频谱）通过文本编码器和后验编码器得到后验潜变量分布，并从中采样得到后验潜变量。2.将输入的文本序列通过先验编码器得到先验潜变量分布，并从中采样得到先验潜变量。3.将文本特征序列和后验潜变量或先验潜变量通过语音解码器得到重建的语音特征序列，并通过判别器判断其真假。4.根据重建损失、对抗损失、KL散度损失和持续时间损失对模型参数进行更新。 总结一下，即 文本序列，真实语音序列作为输入，通过文本编码器、后验编码器，输出后验潜变量分布，采样得后验潜变量。 文本序列作为输入，通过先验编码器，得到先验潜变量分布，采样得到先验潜变量。 “文本特征序列”+后验潜变量通过语音解码器，得到重建语音特征序列。 “文本特征序列”+先验潜变量通过语音解码器，得到重建语音特征序列。 重建语音特征序列输入判别器，判断真假。 计算所有损失，求和，并进行模型参数更新。 但是VITS将本来的编码器换成了VAE，又加了个标准化流，变成了Glow模型。 推理过程的网络VITS的模型推理过程如下： • 将输入的文本序列通过文本编码器得到文本特征序列。 • 将文本特征序列通过先验编码器得到先验潜变量分布，并从中采样得到潜变量。 • 将文本特征序列和潜变量通过语音解码器得到语音特征序列。 • 将语音特征序列通过一个声码器（Vocoder）得到最终的语音波形。","categories":[],"tags":[]},{"title":"Transformer 在 VITS 中的应用","slug":"Transformer-在-VITS-中的应用","date":"2023-06-12T06:29:03.000Z","updated":"2023-06-12T06:46:23.218Z","comments":true,"path":"2023/06/12/Transformer-在-VITS-中的应用/","link":"","permalink":"http://petertan303.github.io/2023/06/12/Transformer-%E5%9C%A8-VITS-%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/","excerpt":"","text":"VITS，Variational Inference with adversarial learning for end-to-end Text-to-Speech，使用了 transformer 作为基本的架构，但是在后验编码器和先验编码器之间额外添加了变分推理和标准化流。 Transformer的结构一个编码器，一个解码器。 编码器解码器各自是一个相对完整的神经网络，每层含子层，子层分别为注意力和前馈神经网络。处理查询（query）、 键（key）或值（value）（都是向量）。 VITS的结构和原版Transformer的对应文本编码器（Text Encoder）：transformer的编码器结构，将输入的文本序列转换为文本特征序列。 后验编码器（Posterior Encoder）：transformer的编码器结构，将文本特征序列和真实的语音特征序列（如梅尔频谱）作为输入，输出一个后验潜变量分布。 先验编码器（Prior Encoder）：transformer的编码器结构，将文本特征序列作为输入，并在每个层后面加入一个标准化流层（Normalizing Flow Layer），输出一个先验潜变量分布。 语音解码器（Speech Decoder）：transformer的解码器结构，将文本特征序列和从先验或后验分布中采样得到的潜变量作为输入，并在最后一层后面加入一个对抗损失层（Adversarial Loss Layer），输出一个语音特征序列。 以及额外添加的： 持续时间预测器（Duration Predictor）：将文本特征序列作为输入，使用一个全连接层和一个softmax层，输出一个持续时间序列，表示每个文本单元对应的语音帧数。","categories":[],"tags":[]},{"title":"信号与系统复习","slug":"信号与系统复习","date":"2023-06-10T12:16:46.000Z","updated":"2023-06-13T05:17:20.238Z","comments":true,"path":"2023/06/10/信号与系统复习/","link":"","permalink":"http://petertan303.github.io/2023/06/10/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F%E5%A4%8D%E4%B9%A0/","excerpt":"","text":"傅立叶变换、拉普拉斯变换和z变换都是积分变换。傅立叶变换是拉普拉斯变换的特殊形式，而z变换是拉普拉斯变换的离散形式。 变换 公式 傅立叶变换 F(\\omega)=\\int_{-\\infty}^{\\infty}f(t)e^{-j\\omega t}dt 拉普拉斯变换 F(s)=\\int_{0}^{\\infty}f(t)e^{-st}dt z变换 F(z)=\\sum_{n=-\\infty}^{\\infty}f[n]z^{-n} 傅立叶变换将函数的时域与频域相关联。频谱中的不同成分频率在频域中以峰值形式表示。傅立叶变换在物理学和工程学中有许多应用。傅立叶变换的作用是将函数分解为不同特征的正弦函数的和，如同化学分析来分析一个化合物的元素成分。对于一个函数，也可对其进行分析，来确定组成它的基本（正弦函数）成分¹。 拉普拉斯变换是傅立叶变换的推广，傅立叶变换不适用于指数级增长的函数，而拉氏变换相当于是带有一个指数收敛因子的傅立叶变换，把频域推广到复频域，能分析的信号更广。然而缺点是从拉普拉斯变换的式子中，只能看到变量s，没有频率f的概念，要看幅频响应和相频响应，还得令s=j2πf²。 Z变换可将时域信号（即：离散时间序列）变换为在复频域的表达式。它在离散时间信号处理中的地位，如同拉普拉斯变换在连续时间信号处理中的地位。离散时间信号的Z变换是分析线性时不变离散时间系统问题的重要工具，在数字信号处理、计算机控制系统等领域有着广泛的应用³。","categories":[],"tags":[]},{"title":"Transformer(Attention机制)论文阅读-1","slug":"Transformer-Attention机制-论文阅读","date":"2023-06-09T13:06:38.000Z","updated":"2023-06-13T05:16:54.986Z","comments":true,"path":"2023/06/09/Transformer-Attention机制-论文阅读/","link":"","permalink":"http://petertan303.github.io/2023/06/09/Transformer-Attention%E6%9C%BA%E5%88%B6-%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","excerpt":"","text":"业界典中典之《Attention Is All You Need》，影响世界格局的注意力机制，和“Transformer”。你甚至可以在 维基百科的transformer 页面看到它的大名。 论文原链接为https://arxiv.org/abs/1706.03762 和 https://arxiv.org/pdf/1706.03762.pdf。方便起见，我在文末会嵌入论文pdf页面。 首先问问new bing怎么说：1234567891011121314151617《Attention Is All You Need》是一篇于2017年发表在NIPS会议上的论文，由Google Brain和Google Research的8位作者共同撰写 。这篇论文提出了一种新的基于注意力机制的网络架构，叫做Transformer，它完全摒弃了循环神经网络和卷积神经网络，只使用注意力机制来编码和解码序列。这篇论文的主要贡献有以下几点：• 提出了一种新的注意力函数，叫做缩放点积注意力（Scaled Dot-Product Attention），它可以计算一个查询向量和一组键值对之间的相关性，并输出相应的值向量的加权和。• 提出了一种新的注意力模块，叫做多头注意力（Multi-Head Attention），它可以将输入向量分成多个子空间，并在每个子空间上分别进行缩放点积注意力，然后将结果拼接起来。• 提出了一种新的位置编码方式，叫做正弦余弦位置编码（Sinusoidal Positional Encoding），它可以给输入序列中的每个位置添加一个固定的向量，用来表示位置信息。• 提出了一种新的网络结构，叫做Transformer，它由一个编码器和一个解码器组成，每个编码器和解码器都包含若干层，每层都由多头注意力、前馈神经网络、残差连接和层归一化组成。• 在两个机器翻译任务上，分别是WMT 2014英德翻译和WMT 2014英法翻译，展示了Transformer的优越性能，分别达到了28.4 BLEU和41.8 BLEU的单模型最佳结果。• 在一个英语成分句法分析任务上，展示了Transformer的泛化能力，无论是在大规模还是小规模的训练数据上，都能取得不错的效果。这篇论文对于自然语言处理领域有着深远的影响，它开创了基于自注意力机制的序列建模和转换的范式，并为后续的许多工作提供了灵感和基础。例如BERT、GPT、XLNet等预训练语言模型都是基于Transformer或其变体构建的。 总结一下，新提出的有以下： 神经网络架构 Transformer，核心是注意力机制 由一个编码器和一个解码器组成 每个编码器和解码器都包含若干层，每层都由多头注意力、前馈神经网络、残差连接和层归一化组成 注意力函数 名为缩放点积注意力（Scaled Dot-Product Attention） 计算一个查询向量和一组键值对之间的相关性，并输出相应的值向量的加权和 注意力模块 多头注意力（Multi-Head Attention） 将输入向量分成多个子空间，并在每个子空间上分别进行缩放点积注意力，然后将结果拼接起来 位置编码方式 正弦余弦位置编码（Sinusoidal Positional Encoding） 给输入序列中的每个位置添加一个固定的向量，用来表示位置信息 总之就是注意力，围绕注意力机制展开的一系列工作。 论文摘要为：1234567891011基于复杂的循环或卷积神经网络的编码器-解码器配置的主导序列转换模型。最佳性能的模型还通过注意力机制连接编码器和解码器。我们提出了一种新的简单网络架构，Transformer，它完全基于注意力机制，完全摒弃了循环和卷积。两个机器翻译任务上的实验表明，这些模型在质量上优于其他模型，同时更易于并行化，并且需要显著更少的时间来训练。我们的模型在WMT 2014英德翻译任务上实现了28.4 BLEU的单一模型最佳结果，在现有最佳结果（包括集成）上提高了2 BLEU以上。在WMT 2014英法翻译任务上，我们的模型在8个GPU上训练3.5天后建立了41.8 BLEU的单一模型最新水平BLEU分数，这是文献中最佳模型训练成本的一小部分。我们展示了Transformer对其他任务具有很好的泛化能力，通过将其成功应用于英语成分句法分析，在大规模和有限训练数据上都取得了不错的效果。（其实什么都没说，就是效果好，好的离谱。） 根据搜索结果，本文Transformer中的各个组成模块分别是： • 缩放点积注意力（Scaled Dot-Product Attention）：这是一种注意力函数，它计算一个查询向量和一组键值对之间的相关性，并输出相应的值向量的加权和。它的公式是： \\text{Attention}(Q,K,V)=\\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V其中，$Q$是查询矩阵，$K$是键矩阵，$V$是值矩阵，$d_k$是键向量的维度。分母上的$\\sqrt{d_k}$是为了缩放点积的结果，避免过大或过小的数值影响梯度传播。 • 多头注意力（Multi-Head Attention）：这是一种注意力模块，它将输入向量分成多个子空间，并在每个子空间上分别进行缩放点积注意力，然后将结果拼接起来。它的公式是： \\text{MultiHead}(Q,K,V)=\\text{Concat}(\\text{head}_1,\\dots,\\text{head}_h)W^O其中，$\\text{head}_i=\\text{Attention}(QW_i^Q,KW_i^K,VW_i^V)$，$W_i^Q,W_i^K,W_i^V,W^O$都是可学习的参数矩阵。多头注意力可以让模型同时关注不同的表示子空间和不同的位置信息。 • 正弦余弦位置编码（Sinusoidal Positional Encoding）：这是一种位置编码方式，它给输入序列中的每个位置添加一个固定的向量，用来表示位置信息。它的公式是： \\text{PE}{(pos,2i)}=\\sin(pos/10000^{2i/d{\\text{model}}})\\text{PE}{(pos,2i+1)}=\\cos(pos/10000^{2i/d{\\text{model}}})其中，$pos$是位置索引，$i$是维度索引，$d_{\\text{model}}$是模型维度。正弦余弦位置编码可以让模型捕捉到相对位置和绝对位置的信息，并且具有平移不变性。 • Transformer：这是一种网络结构，它由一个编码器和一个解码器组成，每个编码器和解码器都包含若干层，每层都由多头注意力、前馈神经网络、残差连接和层归一化组成。编码器用来将输入序列编码成一个高维向量表示，解码器用来根据编码器的输出和自身的输入生成目标序列。 以上就是本文Transformer中各个组成模块的简要解释。如果你想了解更多细节，请参考原文 https://www.electricalclassroom.com/parts-of-a-transformer/ 或其他相关资料。 也就是 • 缩放点积注意力（Scaled Dot-Product Attention）：注意力函数 计算一个查询向量和一组键值对之间的相关性，并输出相应的值向量的加权和 • 多头注意力（Multi-Head Attention）：注意力模块 将输入向量分成多个子空间，并在每个子空间上分别进行缩放点积注意力，然后将结果拼接起来 • 正弦余弦位置编码（Sinusoidal Positional Encoding）：位置编码方式 给输入序列中的每个位置添加一个固定的向量，用来表示位置信息 • Transformer：网络结构 由一个编码器和一个解码器组成，每个编码器和解码器都包含若干层，每层都由多头注意力、前馈神经网络、残差连接和层归一化组成。编码器用来将输入序列编码成一个高维向量表示，解码器用来根据编码器的输出和自身的输入生成目标序列。 神经网络架构 Transformer 编码器 将输入序列编码成一个高维向量表示 若干层 多头注意力 前馈神经网络 残差连接 层归一化 解码器 根据编码器的输出和自身的输入生成目标序列 若干层 多头注意力 前馈神经网络 残差连接 层归一化 注意力函数 缩放点积注意力（Scaled Dot-Product Attention） 计算一个查询向量和一组键值对之间的相关性 输出相应的值向量的加权和 注意力模块 多头注意力（Multi-Head Attention） 将输入向量分成多个子空间 在每个子空间上分别进行缩放点积注意力 然后将结果拼接起来 位置编码方式 正弦余弦位置编码（Sinusoidal Positional Encoding） 给输入序列中的每个位置添加一个固定的向量，用来表示位置信息 transformer 是一个网络结构，它包含了缩放点积注意力、多头注意力和正弦余弦位置编码等部分。 自注意力机制（Self-Attention Mechanism）是一种注意力机制，它计算一个序列中不同位置的元素之间的相关性，并输出相应的元素的加权和。它的公式是： \\text{Attention}(Q,K,V)=\\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V其中，$Q$是查询矩阵，$K$是键矩阵，$V$是值矩阵，$d_k$是键向量的维度。分母上的$\\sqrt{d_k}$是为了缩放点积的结果，避免过大或过小的数值影响梯度传播。 自注意力机制的本质可以被描述为一个查询（query）到一系列（键key-值value）对的映射，其中查询和键值对都来自于同一个序列。 自注意力机制可以让序列中的每个元素都与其他元素进行交互，从而捕捉序列内部的结构和依赖关系。 自注意力机制有多种变体，例如多头注意力（Multi-Head Attention），它将输入向量分成多个子空间，并在每个子空间上分别进行自注意力，然后将结果拼接起来。 自注意力机制被广泛应用于基于深度学习的自然语言处理任务中，例如机器翻译、文本摘要、语义分析等。 如果你想了解更多关于自注意力机制的原理和应用，请参考以下资源： • 《Attention Is All You Need》 ：这是一篇经典的论文，提出了基于自注意力机制的Transformer网络结构，在机器翻译任务上取得了显著的效果。 • 《Illustrated: Self-Attention》 ：这是一篇通俗易懂的博客文章，用图解的方式介绍了自注意力机制的计算过程和意义。 • 《The Transformer Attention Mechanism》 ：这是一篇详细的教程文章，介绍了Transformer中使用的不同类型的自注意力机制，以及如何用Python实现它们。 《Attention Is All You Need》是一篇于2017年发表在NIPS会议上的论文，由Google Brain和Google Research的研究人员合作撰写。 该论文提出了一种新的神经网络架构，称为Transformer，它完全基于注意力机制（attention mechanism），摒弃了循环（recurrence）和卷积（convolution）。 注意力机制是一种将一个查询（query）和一组键值对（key-value pairs）映射到一个输出（output）的函数，其中查询、键、值和输出都是向量。 Transformer利用了两种注意力机制：自注意力（self-attention）和编码器-解码器注意力（encoder-decoder attention）。 自注意力允许模型在同一个序列中的不同位置之间建立联系，编码器-解码器注意力允许模型在不同序列之间建立联系。 Transformer由一个编码器（encoder）和一个解码器（decoder）组成，每个部分都包含多个相同的层（layer）。 每个层都有两个子层（sub-layer），一个是多头注意力（multi-head attention），另一个是前馈神经网络（feed-forward neural network）。 此外，每个子层都有残差连接（residual connection）和层归一化（layer normalization）。 Transformer在机器翻译任务上取得了优异的性能，超过了当时的最佳模型，包括集成模型。它在WMT 2014英德翻译任务上达到了28.4 BLEU，比最佳结果提高了2 BLEU以上。它在WMT 2014英法翻译任务上达到了41.8 BLEU，创造了新的单模型最高纪录。Transformer还能很好地泛化到其他任务，例如英语成分句法分析（English constituency parsing）。 捋清思路注意力的本质是处理“查询”和“键值对”并输出的函数。操作对象都是向量。 多头注意力，包含两种注意力机制，一种是自注意力，另一种是编码器-解码器注意力。 自注意力用于在同一序列、不同位置之间建立联系。可以让模型学习到序列内部的依赖关系，无论他们相隔多远。 编码器-解码器注意力用于在不同序列之间建立联系。可以让模型关注到编码器输出中和当前解码器输入相关的部分。 Transformer架构如下： transformer 编码器：包含多个相同的层，每层包含两个子层。 层：包含两个子层 多头注意力 残差连接 层归一化 前馈神经网络 残差连接 层归一化 解码器：包含多个相同的层，每层包含两个子层。 层：包含两个子层 多头注意力 残差连接 层归一化 前馈神经网络 残差连接 层归一化 自然语言处理中： 序列（sequence）：句子 序列中的不同位置（position）：单词，或者子词。 Transformer网络的目标是解决序列到序列（sequence-to-sequence）的任务，例如机器翻译（machine translation），即将一个源语言序列转换为一个目标语言序列。 Transformer网络的工作过程可以分为以下几个步骤： 首先，将源语言序列和目标语言序列都进行编码（encoding），即将每个单词或子词转换为一个固定长度的向量（vector），通常使用词嵌入（word embedding）或者位置编码（position encoding）来实现。 然后，将源语言序列的向量输入到编码器（encoder）中，编码器由多个层（layer）组成，每个层都包含一个多头自注意力（multi-head self-attention）子层和一个前馈神经网络（feed-forward neural network）子层。多头自注意力子层可以让每个位置的输出都包含了输入序列中所有位置的信息，从而捕捉到序列中的依赖关系。前馈神经网络子层可以对每个位置的输出进行非线性变换，从而增加模型的表达能力。 接着，将目标语言序列的向量输入到解码器（decoder）中，解码器也由多个层组成，每个层都包含一个多头自注意力子层、一个多头编码器-解码器注意力（multi-head encoder-decoder attention）子层和一个前馈神经网络子层。多头自注意力子层可以让每个位置的输出都包含了目标语言序列中所有位置的信息，从而捕捉到序列中的依赖关系。多头编码器-解码器注意力子层可以让每个位置的输出都包含了编码器输出序列中所有位置的信息，从而实现了源语言序列和目标语言序列之间的对齐。前馈神经网络子层可以对每个位置的输出进行非线性变换，从而增加模型的表达能力。 最后，将解码器输出的向量进行解码（decoding），即将每个向量转换为一个单词或子词，通常使用线性变换（linear transformation）和softmax函数来实现。这样就得到了最终的目标语言序列。 多头注意力层： 可以将输入序列分成多个子序列，然后对每个子序列应用不同的注意力函数，最后将各个子序列的输出拼接起来。这样可以让模型同时关注到不同的特征和信息。自注意力和编码器-解码器注意力都是一种注意力函数，只是应用的对象不同。自注意力是在同一个序列中的不同位置之间进行计算，编码器-解码器注意力是在不同序列之间进行计算。 在编码器自注意力中，查询（query）和键（key）、值（value）都来自于输入序列； 在编码器-解码器注意力中，查询（query）来自于解码器的输出序列，而键（key）和值（value）来自于编码器的输出序列。 编码器自注意力和编码器-解码器注意力的主要区别在于它们的查询（query）来源。 编码器-解码器注意力是一种注意力机制，它用于编码器-解码器模型中。 在这种模型中，编码器将输入序列编码为一个固定长度的向量，然后解码器使用这个向量来生成输出序列。编码器-解码器注意力允许解码器在生成输出序列时直接访问编码器的输出。 在编码器-解码器注意力中，查询（query）来自于解码器的输出序列，而键（key）和值（value）来自于编码器的输出序列。这种机制允许解码器根据输入序列中不同位置的相关性来分配不同的权重，从而更好地捕捉序列中不同位置之间的关系。 自注意力（Self-Attention）是一种注意力机制，它用于捕捉序列中不同位置之间的关系。 与传统的注意力机制不同，自注意力减少了对外部信息的依赖，更擅长捕捉数据或特征的内部相关性。 在自注意力中，查询（query）、键（key）和值（value）都来自于输入序列。这种机制允许模型根据输入序列中不同位置的相关性来分配不同的权重，从而更好地捕捉序列中不同位置之间的关系。 在自注意力机制中，查询（query）、键（key）和值（value）都来自于输入序列。查询（query）表示请求的内容，键（key）表示被请求的内容，值（value）表示被请求内容的实际值。通过计算查询（query）和键（key）之间的点积来确定每个值（value）的权重，然后对所有值（value）进行加权求和来得到输出。 在编码器-解码器注意力机制中，查询（query）来自于解码器的输出序列，而键（key）和值（value）来自于编码器的输出序列。查询（query）表示请求的内容，键（key）表示被请求的内容，值（value）表示被请求内容的实际值。 与自注意力机制类似，编码器-解码器注意力机制通过计算查询（query）和键（key）之间的点积来确定每个值（value）的权重，然后对所有值（value）进行加权求和来得到输出。不同之处在于，查询（query）来自于解码器的输出序列，而键（key）和值（value）来自于编码器的输出序列。 自注意力机制中，Transformer首先将输入序列转化为查询（query）、键（key）和值（value），然后通过自注意力机制进行处理并输出。 编码器-解码器注意力机制中，编码器首先将输入序列编码为一个固定长度的向量，然后解码器使用这个向量来生成输出序列。在生成输出序列时，解码器会根据输入序列中不同位置的相关性来分配不同的权重，从而更好地捕捉序列中不同位置之间的关系。 在Transformer网络中，编码器和解码器是两个分开的部分，它们之间通过编码器-解码器注意力机制进行交互。 编码器将输入序列编码为一个固定长度的向量，然后解码器使用这个向量来生成输出序列。在生成输出序列时，解码器会使用编码器-解码器注意力机制来直接访问编码器的输出。这种机制允许解码器根据输入序列中不同位置的相关性来分配不同的权重，从而更好地捕捉序列中不同位置之间的关系。 多头注意力是Transformer网络中编码器和解码器共有的子层。它允许模型同时关注多个位置，从而更好地捕捉序列中不同位置之间的关系。在多头注意力中，查询（query）、键（key）和值（value）被分成多个头，每个头分别进行自注意力或编码器-解码器注意力计算，然后将所有头的结果拼接起来作为最终输出。 Q：在运行过程中，编码器和解码器的层是同一层吗？换句话说，能不能认为，transformer是一个大型网络，不存在编码器解码器的分别，只是transformer网络中的每一层，可以看出有两个部分，一部分负责编码一部分负责解码？ A：在Transformer网络中，编码器和解码器是两个分开的部分，它们由多个层组成。编码器和解码器的层数可以相同，也可以不同。 编码器将输入序列编码为一个固定长度的向量，然后解码器使用这个向量来生成输出序列。编码器和解码器都由多个层组成，每个层都包含多头注意力子层和前馈神经网络子层。在编码器中，多头注意力子层使用自注意力机制来捕捉输入序列中不同位置之间的关系。在解码器中，多头注意力子层既使用自注意力机制来捕捉输出序列中不同位置之间的关系，也使用编码器-解码器注意力机制来直接访问编码器的输出。 因此，Transformer网络可以看作是一个大型网络，它由编码器和解码器两个部分组成。每个部分都由多个层组成，每个层都包含多头注意力子层和前馈神经网络子层。编码器和解码器之间通过编码器-解码器注意力机制进行交互。 亦即是说解码器和编码器确实是分开的，两个网络，毕竟层数都可以不一样。 但也没有分那么开，联系相当紧密。 Q：我复述一遍，你看看对不对。序列进入transformer时，首先是进入编码器，通过所有层，而不是只通过某一层，最终生成的是编码后的向量。这个向量再被放入解码器，得到输出序列。那么，我有一个问题。编码器输出的向量，是query、key和value中的哪一个？解码器的各个层中的编码器-解码器注意力，使用的query、key和value是解码器的前一层的输出，还是编码器的输出？ A：您的理解是正确的。序列进入Transformer时，首先进入编码器，通过所有层，最终生成编码后的向量。这个向量再被放入解码器，得到输出序列。 编码器输出的向量不是查询（query）、键（key）或值（value），而是编码后的向量，它表示输入序列的固定长度表示。在解码器中，每个层的编码器-解码器注意力子层使用的查询（query）来自于解码器的前一层的输出，而键（key）和值（value）来自于编码器的输出。 Q：你说解码器的键（key）和值（value）来自于编码器的输出，又说编码器输出的向量不是查询（query）、键（key）或值（value），而是编码后的向量。编码后的向量和键（key）、值（value）有什么关系？请详细介绍。 A：编码器输出的向量是输入序列的固定长度表示，它由编码器的最后一层输出。在解码器中，每个层的编码器-解码器注意力子层使用的键（key）和值（value）来自于编码器的输出，也就是说，它们来自于编码器的最后一层输出的编码后的向量。 在编码器-解码器注意力子层中，查询（query）、键（key）和值（value）都是通过将输入序列中的每个元素与不同的权重矩阵相乘来计算得到的。查询（query）来自于解码器的前一层的输出，而键（key）和值（value）来自于编码器的最后一层输出的编码后的向量。 因此，编码后的向量和键（key）、值（value）之间的关系是：编码后的向量是输入序列的固定长度表示，它由编码器的最后一层输出；而键（key）和值（value）则是通过将编码后的向量与不同的权重矩阵相乘来计算得到的。 亦即是说，编码器确实是执行完所有层，才会输出句子对应的向量。 这个向量经过与不同的权重矩阵相乘来计算，得到键（key）和值（value）。 键（key）和值（value）会传递给解码器，解码器第一层会将目标序列转化为查询（query）向量，传递给下一层；之后的每一层会输出向量，作为下一层的查询（query）输入。 Q：解码器的输入是“目标序列”，那么，这个“目标序列”是怎么转化为查询（query）的？ A：在解码器中，每个层的编码器-解码器注意力子层使用的查询（query）来自于解码器的前一层的输出。在解码器的第一层中，查询（query）来自于目标序列。 目标序列首先被转化为嵌入表示，然后与位置编码相加来表示序列中每个元素的位置信息。这个嵌入表示就是解码器第一层的输入，也就是查询（query）。 在解码器的每个层中，查询（query）都是通过将输入序列中的每个元素与权重矩阵相乘来计算得到的。在解码器的第一层中，输入序列就是目标序列的嵌入表示。 Q：详细解释权重矩阵是哪里来的。是transformer神经网络自带的吗？键（key）和值（value）在解码器的每一层中是如何处理的？ A：权重矩阵是Transformer网络的参数之一，它们在训练过程中被学习得到。查询（query）、键（key）和值（value）都是通过将输入序列中的每个元素与不同的权重矩阵相乘来计算得到的。 在解码器的每一层中，查询（query）来自于解码器的前一层的输出，而键（key）和值（value）来自于编码器的输出。多头注意力子层将查询（query）、键（key）和值（value）分成多个头，每个头分别进行自注意力或编码器-解码器注意力计算，然后将所有头的结果拼接起来作为最终输出。 在编码器-解码器注意力计算中，首先计算查询（query）和键（key）之间的点积来确定每个值（value）的权重，然后对所有值（value）进行加权求和来得到输出。这样，解码器就可以根据输入序列中不同位置的相关性来分配不同的权重，从而更好地捕捉序列中不同位置之间的关系。 因此，在解码器的每一层中，键（key）和值（value）都是通过编码器-解码器注意力计算来处理的。它们用于确定每个值（value）的权重，并对所有值（value）进行加权求和来得到输出。 transformer的训练产物是权重矩阵。","categories":[],"tags":[]},{"title":"更加完善的爬虫 plus","slug":"更加完善的爬虫-plus","date":"2023-05-28T13:54:38.000Z","updated":"2023-05-28T15:10:45.964Z","comments":true,"path":"2023/05/28/更加完善的爬虫-plus/","link":"","permalink":"http://petertan303.github.io/2023/05/28/%E6%9B%B4%E5%8A%A0%E5%AE%8C%E5%96%84%E7%9A%84%E7%88%AC%E8%99%AB-plus/","excerpt":"","text":"算上注释，和一些意义不明的回车，大概五百行。 总之就是： 使用controller控制页面的切换，实现了return，而且不用像之前一样重复实例化多个窗口（在connect里面实时实例化）。 优化了UI的布局。 进行了exe打包 增加了功能： 使用jieba进行分词 使用word2vec进行 句子-词向量 的转化 使用pandas将测到的结果写入csv文件 Controller 控制器核心是Qt的信号量机制。1234567891011121314151617181920212223242526# 利用一个控制器来控制页面的跳转class Controller: def __init__(self): pass # 跳转到 main 窗口 def show_main(self): self.main = mainpage() self.main.switch_window1.connect(self.show_add_url) # 信号量关联 self.main.switch_window2.connect(self.show_crawler) self.main.show() # 跳转到search窗口, 注意关闭原页面 def show_add_url(self): self.add_url = addurl() self.add_url.switch_window1.connect(self.show_main) self.add_url.switch_window1.connect(self.add_url.close) self.main.close() self.add_url.show() #跳转到 DisFac 窗口, 注意关闭原页面 def show_crawler(self): self.crawler = crawler() self.crawler.switch_window1.connect(self.show_main) self.crawler.switch_window1.connect(self.crawler.close) self.main.close() self.crawler.show()可以看到，函数中调用的self.xxx.switch_window1是原类中的一个pyqtSignal()对象，本质是Qt使用的信号量。在类的开头进行实例化：1switch_window1=pyqtSignal()实例化后就可以调用其中的emit()方法，在这里，方便起见，我另外设置了一个方法来调用。 具体内容为：12def return_to_main(self): self.switch_window1.emit() 而与之对应，在主页面也有对应方法，用于和对应的跳转按钮对应起来：12345678910switch_window1=pyqtSignal()switch_window2=pyqtSignal()def jump_to_add_url(self): print(&#x27;jump to add url&#x27;) self.switch_window1.emit()def jump_to_crawler(self): print(&#x27;jump to crawler&#x27;) self.switch_window2.emit()总之就是，使用pyqtSignal()对象中的emit()方法进行跳转。在Controller内，这个pyqtSignal()对象应该和形如show_add_url的方法对应起来。 UI的优化主页： 添加url： 爬取： exe打包使用了pyinstaller，值得注意的是，当前虚拟环境（我用了anaconda）里，没有用到的包似乎也会被一并打包，导致最终的exe巨大一个。 要是需要小一点的exe，可以新建虚拟环境，并尽量少地安装包。 readline 和 rstrip(“\\n”) 和 split(‘ ‘)readline真的是只读一行，读到回车为止。 rstrip是一个字符串的方法，可以删去字符串首尾的多余字符。例如skipwords[i] = skipwords[i].rstrip(&quot;\\n&quot;) split也是一个字符串的方法，可以以参数为界，将字符串切割为列表。 forcutwordslist += [word for word in jieba.cut(word_read, cut_all=False) if word not in skipwords] C for A in B，用中括号括起来就是一个列表，甚至可以用if进行跳过。很神奇。 eval 和 dict理论上dict可以将字符串转化为字典，但是我从来没使用成功过，反倒是一直在用eval。 jieba 分词cutwordslist += [word for word in jieba.cut(word_read, cut_all=False) if word not in skipwords] jieba.cut方法，输入需要切割的字符串，指定切割模式，返回一个列表。 word2vec首先加载模型，w2v_model = Word2Vec.load(&#39;aaa.model&#39;) 然后，由于我使用的向量是一百二十八维的（主要是因为模型就是这个维数），所以需要更新大小。 vec = numpy.zeros(size).reshape((1, size)) 要想获得一句话的词向量，只需要将词汇的词向量全部相加。 vec += w2v_model.wv[word].reshape((1, size)) 获得vec之后写入即可。 pandas 写入 csvpandas使用的数据类型叫做DataFrame，初始化的时候需要提供数据和标签，data和columns。 data=pandas.DataFrame(data=[j for j in range(128)],columns=[&#39;index&#39;]) 写入新数据是data[line]=vec[0]，其中line为句子本身的字符串，作为索引，vec是一个列表套列表所以不能直接用，需要vec[0]。 如果vec维数不够128维就会出现报错，以防万一，使用if判断，然后data[line]=[0 for k in range(128)]进行补零。 最后写入：data.to_csv(&#39;data_final_&#39;+self.site+&#39;.csv&#39;)。","categories":[],"tags":[]},{"title":"有GUI的爬虫plus","slug":"有GUI的爬虫plus","date":"2023-05-22T06:27:45.000Z","updated":"2023-05-22T07:00:08.817Z","comments":true,"path":"2023/05/22/有GUI的爬虫plus/","link":"","permalink":"http://petertan303.github.io/2023/05/22/%E6%9C%89GUI%E7%9A%84%E7%88%AC%E8%99%ABplus/","excerpt":"","text":"代码比较多，优化空间也很大，就不放上来了。 聊聊写的时候碰到的问题和解决。 QT使用的基本思路首先实例化组件：1234self.label_name = QLabel(&#x27;name&#x27;)self.edit_name = QComboBox()self.label_num = QLabel(&#x27;page num&#x27;)self.edit_page_num = QComboBox()层：1self.lay_h1=QHBoxLayout()向层中添加组件：12345678910self.lay_h1.addWidget(self.label_name)self.lay_h1.addWidget(self.label_num)self.lay_h1.addWidget(self.label_url)self.lay_h2.addWidget(self.edit_name)self.lay_h2.addWidget(self.edit_page_num)self.lay_h2.addWidget(self.edit_url)self.lay_h3.addWidget(self.btn_crawl)self.lay_h3.addWidget(self.btn_update)self.lay_h3.addWidget(self.btn_exit)向窗口添加层:1234self.lay_v1=QVBoxLayout()self.lay_v1.addLayout(self.lay_h1)self.lay_v1.addLayout(self.lay_h2)self.lay_v1.addLayout(self.lay_h3)定义按钮行为:1234self.btn_crawl.clicked.connect(self.crawl)# self.btn_exit.clicked.connect(main.show)self.btn_update.clicked.connect(self.update)self.btn_exit.clicked.connect(self.close)设置下拉框等等：123# 下拉框self.edit_name.addItems(list(url_dict.keys())) # 认列表，不认字典self.edit_page_num.addItems(str(i) for i in range(1,11)) # 好事情最后完成窗口设置：1self.setLayout(self.lay_v1) 如何多py文件开发？我也不清楚这个应该怎么称呼，总之就是多个源文件，但源文件之间可以使用其他文件的代码。要称呼的话应该是“工程”。 如果需要使用其他文件里的代码，在文件开头import文件名即可，就当作库来使用。 主函数也就是if __name__ == &#39;__main__&#39;:这句话，__name__是自带变量，获取文件名。 使用pyqt窗口需要实例化，即123456app = QApplication(sys.argv)addurl_test=addurl()crawl_test=crawler()main = mainpage(addurl_test,crawl_test)main.show()sys.exit(app.exec_())实例化了几个窗口，在实例化时，会调用__init__方法，但是没有调用show方法，所以并不会显示。 关于窗口切换一开始是试着通过调用close和show实现窗口切换，但是发现类的方法之间并不能使用主函数中实例化的窗口，需要传送参数，但是connect方法传参会出现TypeError: argument 1 has unexpected type &#39;NoneType&#39;的问题，于是不了了之。 后面参考其他同学的代码，发现他们是通过在分页面的类内插入形如12switch_window1=QtCore.pyqtSignal()self.switch_window1.emit()的语段来实现。 在主界面似乎并没有这种语段。 需要更改父类的方法直接写就是覆盖，如果需要在父类方法中插入语句，可以 123def show(self): super().show() print(self.__class__.__name__) 使用super()。 QT自带计时器123timer=QTimer(self)timer.start(5000)timer.stop() 计时器也是一个对象（毕竟面向对象），是需要实例化的。 “抓取成功”提示","categories":[],"tags":[]},{"title":"爬虫 plus","slug":"Python-爬虫-plus","date":"2023-05-18T02:34:08.000Z","updated":"2023-05-18T03:14:22.592Z","comments":true,"path":"2023/05/18/Python-爬虫-plus/","link":"","permalink":"http://petertan303.github.io/2023/05/18/Python-%E7%88%AC%E8%99%AB-plus/","excerpt":"","text":"3123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869# 导入所需模块import requestsfrom bs4 import BeautifulSoupfrom os import _exit,path,remove,systemfrom time import ctime# import jsoncookie = &#x27;this is cookies&#x27; cookies = &#123;i.split(&quot;=&quot;)[0]:i.split(&quot;=&quot;)[-1] for i in cookie.split(&quot;; &quot;)&#125;headers = &#123;&#x27;User-Agent&#x27;:&#x27;this is User-Agent&#x27;&#125;site_url=open(&#x27;site.txt&#x27;,&#x27;r+&#x27;,encoding=&#x27;utf-8&#x27;) # 可读可写url_read=site_url.read()url_dict=eval(url_read) # 转化为字典# site=set(url_dict) # 这样会输出集合，不方便遍历site=list(url_dict.keys()) # 需要从dict_key强转为listdef add_site(): print(url_dict) url_dict[input(&#x27;输入站点代号：&#x27;)]=input(&#x27;请输入站点url：&#x27;) print(url_dict) site_url.seek(0) site_url.write(str(url_dict))while 1: # system(&#x27;cls&#x27;) print(&#x27;-1.add new site&#x27;) print(&#x27;0.quit&#x27;) for i in range(len(url_dict)): print(str(i+1)+&#x27;.&#x27;+site[i]) num=int(input(&#x27;请输入站点编号：&#x27;)) if num==0: site_url.close() _exit(0) if num==-1: add_site() site_url.seek(0) url_read=site_url.read() site=list(url_dict.keys()) # 需要从dict_key强转为list continue page_num=int(input(&#x27;请输入抓取页数：&#x27;)) file_path = &#x27;data&#x27;+&#x27;_&#x27;+site[num-1]+&#x27;.txt&#x27; if path.exists(file_path): remove(file_path) f=open(file_path, &#x27;a&#x27;, encoding=&#x27;utf-8&#x27;) f.write(&#x27;抓取时间：&#x27;+ctime()+&#x27;\\n&#x27;) f.close() for page in range(page_num): f=open(file_path, &#x27;a&#x27;, encoding=&#x27;utf-8&#x27;) f.write(&#x27;\\n\\n第&#x27;+str(page+1)+&#x27;页：\\n&#x27;) f.close() url = url_dict[site[num-1]]+str(page+1) print(url) response = requests.get(url, headers=headers,cookies=cookies) soup = BeautifulSoup(response.text, &#x27;lxml&#x27;) for each in soup.find_all(&#x27;tbody&#x27;): title = each.find(&#x27;a&#x27;,class_ = &#x27;topic&#x27;).get_text(strip=True) f=open(file_path, &#x27;a&#x27;, encoding=&#x27;utf-8&#x27;) f.write(&#x27;\\n&#x27;.join([title])) f.write(&#x27;\\n&#x27;) f.close() print(&#x27;response.status_code ==&#x27;,response.status_code)site_url.close() 改进增加了通过文件读写来更新site即站点列表； 增加了交互式查询的功能； 增加了抓取时间和抓取页面的页数（如果是用于数据分析，那这个属于是多余，但如果爬出来的结果是给人看的，那就显得很有必要了。） 注意点文件的打开方式只介绍我用到的两种，和试图用的一种 ‘r+’：可读可写 ‘a’：追加内容 ‘w+’：打开即清空 前两种的差别在于文件指针初始位置： ‘r+’初始在文件头，read操作将其挪到文件尾，导致第二次read就读不出东西。这种时候就可以通过seek()方法更改文件指针位置，例如seek(0)就是挪到文件开头。 ‘a’初始在文件尾，因此我们需要if path.exists(file_path): remove(file_path)来进行伪覆写。 ‘w+’不是很讲理，将打开的文件视作全新文件，即使没有任何操作也会清空文件内容。 python各种对象和字符串对象的转化其实字符串也是对象，但字符串比较偏朴素，和花里胡哨的dict、list、set什么的完全比不了。 其他对象可以使用str()转化为字符串，字符串也可以通过list()（列表）、eval（字典）等方法转化为其它类型的对象。 其他类型的强制类型转化也是类似，例如字符串可以转化为整型数，’1’可以转化为 1。 对 C 语言起手的人来说堪称魔法。 获取目前时间使用time库的ctime()方法。 连缀&#39;\\n&#39;.join([title])，意思是通过换行符号将join里字符串序列连接起来。 收回前言，python字符串也挺花里胡哨的。 python中的for看上去和 C 里的 for(i=0;i&lt;n;i++);很像，但这里的意思是选取系列中的元素，对所有元素进行以下操作。 如果把系列，也就是soup.find_all(&#39;tbody&#39;)换成range()，那就和 C 类似了。 另外，python的for是可以使用else的。312for each in soup.find_all(&#x27;tbody&#x27;): title = each.find(&#x27;a&#x27;,class_ = &#x27;topic&#x27;).get_text(strip=True)果然面向过程到面向对象的思维转化是个艰难的过程。 从右向左执行url_dict[input(&#39;输入站点代号：&#39;)]=input(&#39;请输入站点url：&#39;)，会先让你输入url，再输入站点代号。反正我觉得没差，就没动它了。","categories":[],"tags":[]},{"title":"Python爬虫构建","slug":"Python爬虫构建","date":"2023-05-17T15:47:40.000Z","updated":"2023-05-17T16:11:27.665Z","comments":true,"path":"2023/05/17/Python爬虫构建/","link":"","permalink":"http://petertan303.github.io/2023/05/17/Python%E7%88%AC%E8%99%AB%E6%9E%84%E5%BB%BA/","excerpt":"","text":"3123456789101112131415161718192021# 导入所需模块import requestsfrom bs4 import BeautifulSoupcookie = &#x27;this is cookies&#x27; cookies = &#123;i.split(&quot;=&quot;)[0]:i.split(&quot;=&quot;)[-1] for i in cookie.split(&quot;; &quot;)&#125;headers = &#123;&#x27;User-Agent&#x27;: &#x27;this is user-agent&#x27;,&#125;for page in range(10): url = &#123;&quot;ng2&quot;:&#x27;https://bbs.nga.cn/thread.php?fid=-447601&amp;page=%s&#x27; %page, &quot;ark&quot;:&#x27;https://bbs.nga.cn/thread.php?fid=-34587507&amp;page=%s&#x27; %page&#125; response = requests.get(url[&#x27;ark&#x27;], headers=headers,cookies=cookies) soup = BeautifulSoup(response.text, &#x27;lxml&#x27;) for each in soup.find_all(&#x27;tbody&#x27;): title = each.find(&#x27;a&#x27;,class_ = &#x27;topic&#x27;).get_text(strip=True) f=open(&#x27;data&#x27;+&#x27;_&#x27;+&#x27;ark&#x27;+&#x27;.txt&#x27;, &#x27;a&#x27;, encoding=&#x27;utf-8&#x27;) f.write(&#x27;\\n&#x27;.join([title])) f.write(&#x27;\\n&#x27;) f.close() print(&#x27;response.status_code ==&#x27;,response.status_code) 关于爬虫本质是一个访问网站，提取某些信息的程序。 “爬取”这个动词描述获取数据的过程。其实比起爬取，爬虫的行为更像是递交一个申请表，申请到一本html文件，然后对着这本html文件写了一篇摘要呈现给用户。 理论上说，人来通过浏览器手动记录数据本质和爬虫一样，但爬虫效率高，容易把服务器爬出问题。 关于我这个爬虫用来爬ngabbs.com的某些版面帖子标题，用于数据分析，绝对不是干什么坏事。 解读首先我是使用了beautifulsoup4和request库。不得不说python的库是真的方便。312import requestsfrom bs4 import BeautifulSoup然后我需要清理一下之前生成的残留文件，因此我需要os来获取当前路径下的文件并移除：312345import ospath = &#x27;data&#x27;+&#x27;_&#x27;+&#x27;ark&#x27;+&#x27;.txt&#x27;if os.path.exists(path): os.remove(path)然后是构建请求。 请求需要Cookies，否则会报403错误（无权限）； Cookies不能直接提交，需要转换为字典； 请求需要请求头，也就是headers，里面包含User-Agent。一开始我不知道，把Cookies也放在了里面。事实上Cookies应该单独提交； 请求需要url，因为我需要不同版面，不同页数的数据，因此构建了一个字典，使用助记词对应url。令我惊叹的、很人性化的一点是，可以使用%s和追加%page来实现变参的作用； 最后，我们调用了get方法，得到的是response。 然后使用BeautifulSoup对其进行解码，得到soup。312345678910cookie = &#x27;this is cookies&#x27; cookies = &#123;i.split(&quot;=&quot;)[0]:i.split(&quot;=&quot;)[-1] for i in cookie.split(&quot;; &quot;)&#125;headers = &#123;&#x27;User-Agent&#x27;: &#x27;this is user-agent&#x27;,&#125;for page in range(10): url = &#123;&quot;ng2&quot;:&#x27;https://bbs.nga.cn/thread.php?fid=-447601&amp;page=%s&#x27; %page, &quot;ark&quot;:&#x27;https://bbs.nga.cn/thread.php?fid=-34587507&amp;page=%s&#x27; %page&#125; response = requests.get(url[&#x27;ark&#x27;], headers=headers,cookies=cookies) soup = BeautifulSoup(response.text, &#x27;lxml&#x27;)然后是写入文件，这部分折磨了我好久。我一开始的版本是：3123456for each in soup.find_all(&#x27;tbody&#x27;): title = each.find(&#x27;a&#x27;,class_ = &#x27;topic&#x27;).get_text(strip=True) with open(&#x27;data&#x27;+&#x27;_&#x27;+&#x27;ark&#x27;+&#x27;.txt&#x27;, &#x27;w&#x27;, encoding=&#x27;utf-8&#x27;) as f: f.write(&#x27;\\n&#x27;.join([title])) f.write(&#x27;\\n&#x27;) f.close()但这样写会让文件的写入覆盖前一个，也就是说，无数轮循环结束，文件里只能保留最后一个标题。 但我不知道为什么，怀疑是with open(&#39;data&#39;+&#39;_&#39;+&#39;ark&#39;+&#39;.txt&#39;, &#39;w&#39;, encoding=&#39;utf-8&#39;) as f:的问题。我将其改成了f = open(&#39;data&#39;+&#39;_&#39;+&#39;ark&#39;+&#39;.txt&#39;, &#39;w&#39;, encoding=&#39;utf-8&#39;)，但还是同样的问题。 其实我的怀疑是对的，但没怀疑到点子上。 事实上是这个： 31with open(&#x27;data&#x27;+&#x27;_&#x27;+&#x27;ark&#x27;+&#x27;.txt&#x27;, &#x27;a&#x27;, encoding=&#x27;utf-8&#x27;) as f: 注意到区别了吗？ ‘a’ 和 ‘w’。 我应该再多读读文件操作那章的。31print(&#x27;response.status_code ==&#x27;,response.status_code)这句不用多说，是打印状态值。一开始疯狂报403、411，终于稳定报200之后，我真的是甚是欣慰。 爬取的成果如下：（碍于篇幅，只展示第一页的）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[公告] [四周年活动第一弹]分享罗德岛的年度工作报告，赢版面声望！(抽30位幸运坛友赠送周边一份！)[ROLL] 明日方舟四周年庆典签到活动 抽取iPad手办京东卡等周边大奖[剧情讨论] [闲谈交流] 关于“坠落的星星”，我发现一个华点黄铁峡谷18：“弑君者III：狼牙”+“源石环境：活性III”[可能火星]如果下个月是异格阿葬的话，他就是第77个六星[全新开业]龙门茶馆 - 一盅两盏，畅所欲言[提问]新人放入坑，有一堆疑问汐斯塔扭蛋广场[安科/安价]出场文物是各位干员的泰拉博物馆奇妙夜(博士升任司岁台头头)[失智安科]博士发现了一个奇怪的法阵[博all]随机挑选一个男干员当小妈，但是博士想追求自己的小妈[随缘安科][棘流勇境]极境是要成为魔法帝的男人！[ex8突袭]令人绝望的场景[ROLL] 来roll送一块手工小莫流麻！帮助选择困难症萌新回忆一些老cp的发展，非常主观莱塔尼亚大图书馆[同人文] 《边缘》明日方舟x死亡空间[短篇同人](阿米娅向)雷姆必拓的兔子们[渣文笔][同人文]凯尔希之家[葬博] [送葬人氵] 试图坚持三十天每日一葬[提问] 对萌新来说，这次活动商店兑换优先级是什么样的[闲谈交流] 保全派驻的一点正体验(仅限模拟器)[保全氵]太恶心了[破事氵]虽然不是什么特别的数字，但怎么总觉得这龙门币在骂我自己[氵]突然在想，为什么谢拉格二期的中心不能是崖心呢？为啥突袭0—1这么难啊，把我关了陈陈陈陈陈陈是否还有第二异格形态的可能？保全任务是不是有bug和海愿绝配[闲谈交流]各圈各平台最火CP一览，方舟上榜[剧情讨论] 所以老干猫到底有没有自我意识越来越喜欢叔叔了 因为我加班一个月了才发现明日方舟干员列表的背景不是白色而是透明的保全派驻是明日方舟最弱智最失败的模式，没有之一。有没有基建大佬展示一下顶配基建收益3月后入坑的人，没有夜刀玩肉鸽是不是很难受？黄票不足 要换小火龙吗卡西米尔竞技场[突袭cws4](已过审)无限定，6人带阿消，操作简单，大部分时间在挂机[泰拉记事社] #吉姆波顿 # 特里蒙晚间电波秀[孤星]CW-S-1-AB到CW-S-4突袭摆完挂机，不过是小猪！[中坚寻访]中坚甄选：05月18日 04:00 - 06月01日 03:59[剧情氵]霍尔海雅与缪尔赛思人物对比分析[攒抽氵]小刻也能看懂的零氪攒抽记录--《从大哥到缪缪》[微考据][小车氵]Friston？神经科学？是你！——Friston 在现实世界的致敬/原型[考据氵][抛砖引玉氵]谈“孤星”剧情中的科幻Neta(已更新DLC)[活动奖励干员]重装-铁卫 Friston-3[活动奖励服饰] //竞技之梦改装 - 正义骑士号","categories":[],"tags":[]},{"title":"评论再测试","slug":"评论再测试","date":"2023-05-05T10:14:16.000Z","updated":"2023-05-05T12:37:22.143Z","comments":true,"path":"2023/05/05/评论再测试/","link":"","permalink":"http://petertan303.github.io/2023/05/05/%E8%AF%84%E8%AE%BA%E5%86%8D%E6%B5%8B%E8%AF%95/","excerpt":"","text":"测试 18点36分 测试 18点40分 测试 18点55分 测试 18点59分 测试 19点01分 测试 19点13分 测试 20点37分","categories":[],"tags":[]},{"title":"评论测试","slug":"评论测试","date":"2023-05-05T05:55:29.000Z","updated":"2023-05-05T07:43:12.750Z","comments":true,"path":"2023/05/05/评论测试/","link":"","permalink":"http://petertan303.github.io/2023/05/05/%E8%AF%84%E8%AE%BA%E6%B5%8B%E8%AF%95/","excerpt":"","text":"12345678910111213&lt;head&gt; &lt;script src=&#x27;//unpkg.com/valine/dist/Valine.min.js&#x27;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=&quot;vcomments&quot;&gt;&lt;/div&gt; &lt;script&gt; new Valine(&#123; el: &#x27;#vcomments&#x27;, appId: &#x27;xxx&#x27;, appKey: &#x27;xxx&#x27; &#125;) &lt;/script&gt;&lt;/body&gt; 以上的html代码放在全文结尾。 还没搞明白 hexo 自带的是怎么搞…… config 配置如下123456789101112valine: enable: true # 设置为true，默认为false appid: # 将应用key的App ID设置在这里 appkey: # 将应用key的App Key设置在这里 notify: false# 邮箱通知 , https://github.com/xCss/Valine/wiki，默认为false verify: false# 验证码 默认为false placeholder: Just go go ^_^ # 初始化评论显示，根据自己修改，这里默认， avatar: monsterid # 头像风格，默认为mm，可进入网址：https://valine.js.org/visitor.html查看头像设置，这里有许多头像风格，进行设置 guest_info: nick,mail,link # 自定义评论标题 pageSize: 10 # 分页大小，10页就自动分页 visitor: true # 是否允许游客评论 ，进入官网查看设置：https://valine.js.org/visitor.html值得注意的是，yml文件的冒号后需要空格。 有一说一，leancloud的速度似乎会拖慢页面加载的速度…… new Valine({ el: '#vcomments', appId: 'mV6pM4FkddUR4CfQioaXxMrp-9Nh9j0Va', appKey: 'YvR7UmmLPsWePIigEYzEjLuy' })","categories":[],"tags":[]},{"title":"2023年5月5日","slug":"2023年5月5日","date":"2023-05-04T15:54:15.000Z","updated":"2023-05-05T08:07:44.559Z","comments":true,"path":"2023/05/04/2023年5月5日/","link":"","permalink":"http://petertan303.github.io/2023/05/04/2023%E5%B9%B45%E6%9C%885%E6%97%A5/","excerpt":"","text":"关于阿里云服务器让一个七个月的云服务器烂在手里还是太可惜了。 github上看到一个很有意思的项目，https://github.com/jaywcjlove/reference，似乎非常非常适合镜像到自己的服务器上，作为时时刻刻、随时随地的便利参考。 好奇还有什么类似的项目。 关于云服务器直接部署页面……部署了wordpress博客，搭建了数据库，但是不会使用，不会操作，所以这么长时间就放任它烂在了手里。感觉对不起这个云服务器……属于是倒了大霉碰上了我。 另外，我的服务器是2G+2G配置，据同学说，这个配置跑 MC 似乎还是比较吃力的。 关于VITS论文还在读，笔记做的是纸质的。学习完成之后，打算一股脑传上来。 关于课业 1、信号与系统作业 2、电磁场与波作业 3、美术鉴赏ppt 4、神经网络导论期末大作业 5、信号与系统课程设计 6、python语言课程作业 关于勾选框的使用方法：使用 hexo 的勾选框 6、python语言课程作业 12345678&#123;% cb 6、python语言课程作业,false %&#125;&#123;% cb text, checked?, incline? %&#125;text：显示的文字checked：默认是否已勾选，默认 falseincline: 是否内联（可以理解为后面的文字是否换行），默认 false&#123;% cb false %&#125; 也可以只传入一个参数，文字写在后边（这样不支持外联）内联就是不换行，外联就是换行。 使用 md 自带的勾选框 [ ] 这是未选择 [x] 这是选择 123- [ ] 这是未选择- [x] 这是选择注意空格和 “ - ” 关于 hexo 博客的评论功能开启评论需要在主题配置中开启并指定评论模块： post: comments: enable: true type: disqus 然后在下方还要设置对应评论模块的参数，比如 disqus 对应设置： disqus: shortname: fluid 当前支持的评论插件如下： Valine (opens new window):基于 LeanCloud Waline (opens new window): 从 Valine 衍生而来，额外增加了服务端和多种功能 Gitalk (opens new window): 基于 GitHub Issues Utterances (opens new window): 基于 GitHub Issues Disqus (opens new window): 基于第三方的服务 畅言 (opens new window): 基于第三方的服务 来必力(Livere) (opens new window): 基于第三方的服务 Remark42 (opens new window): 需要自托管服务端 Twikoo (opens new window): 基于腾讯云开发 Cusdis (opens new window): 基于第三方服务或自托管服务 Giscus (opens new window): 基于 GitHub Discussion 使用方式和参数设置请点击上面链接查看各自的文档。 若想自己添加新的评论插件，可通过自定义功能加入 &lt;script&gt;，并判断是否存在 #comments 元素进行挂载。 TIP 国内用户推荐使用 Valine、Waline 或者 twikoo 如果设置后评论模块没有显示，说明配置没有完成，或者配置有误出现报错（请在浏览器控制台查看具体报错） 如果想在某个文章页关闭评论，或者想在某个自定义页面开启评论，可以通过在 Front-matter (opens new window)设置 comment: bool 来控制评论开关，或者通过 comment: &#39;type&#39; 来开启指定的评论插件。 例如在关于页开启并指定评论插件： 12345678---title: 关于页layout: aboutindex_img: /img/example.jpgdate: 2019-10-10 10:00:00comment: &#x27;valine&#x27;---以下是正文内容 总结一下就是 主题内配置开启与参数。 高级用户可以通过自己的script客制化。 可以在页面的开头设置本页面是否开启评论、开启哪种方式的评论。 使用 gittalk 评论12345678910111213gitalk: enable: true #启用gitalk github_id: #github帐号 例：CodeHaotian id: location.pathname #此设置参照下文常见问题说明 repo: #存放评论的仓库名称 client_id: #application的id，即上文Client ID client_secret: #application的密码，即上文Client Secret admin_user: #页面显示联系**初始化评论 例：CodeHaotian distraction_free_mode: true # Facebook-like distraction free mode # Gitalk&#x27;s display language depends on user&#x27;s browser or system environment # If you want everyone visiting your site to see a uniform language, you can set a force language value # Available values: en | es-ES | fr | ru | zh-CN | zh-TW language: zh-CN 这种方法需要一个github application，一个github repo，一个github账号。","categories":[],"tags":[]},{"title":"Numpy 和 Matplotlib 的使用","slug":"Numpy-和-Matplotlib-的使用","date":"2023-04-26T10:41:49.000Z","updated":"2023-05-04T15:51:45.561Z","comments":true,"path":"2023/04/26/Numpy-和-Matplotlib-的使用/","link":"","permalink":"http://petertan303.github.io/2023/04/26/Numpy-%E5%92%8C-Matplotlib-%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"","text":"首先，import一下：123import numpy as npimport matplotlibimport matplotlib.pyplot as plt NumpyNumpy是Python的一个科学计算的库，提供了矩阵运算的功能，其一般与Scipy、matplotlib一起使用。其实，list已经提供了类似于矩阵的表示形式，不过numpy为我们提供了更多的函数。 操作的对象有两种，一种是 N 维数组对象 ndarray，另一种是矩阵 matrix。 数据类型也很多，虽然不需要像C一样指定，但数据确实是有数据类型的。 创建一个 ndarry 对象123456789101112131415161718numpy.array(object, dtype = None, copy = True, order = None, subok = False, ndmin = 0)# 必须的只有object，也就是数组对象，新建的 ndarry 内容和 object 完全一致。# 可以输入多个 object，这样会被视为多维度 ndarry。# numpy.empty(shape, dtype = float, order = &#x27;C&#x27;)numpy.asarray(a, dtype = None, order = None)numpy.frombuffer(buffer, dtype = float, count = -1, offset = 0)numpy.fromiter(iterable, dtype, count=-1)numpy.arange(start, stop, step, dtype)np.linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None)np.logspace(start, stop, num=50, endpoint=True, base=10.0, dtype=None)","categories":[],"tags":[]},{"title":"2023年4月23日","slug":"2023年4月23日","date":"2023-04-23T15:14:53.000Z","updated":"2023-04-23T15:52:00.664Z","comments":true,"path":"2023/04/23/2023年4月23日/","link":"","permalink":"http://petertan303.github.io/2023/04/23/2023%E5%B9%B44%E6%9C%8823%E6%97%A5/","excerpt":"","text":"关于so-vits-svc首先，这是一个很牛逼的项目，极大简化了训练和音色迁移的过程，随着团队的接手，他们甚至加上了webUI。 但是。 他们把项目存了档，我不知道是什么让他们这么做的，但他们就是这么干了。我的评价是这是一个极其弱智且不负责任的行为，因为随着项目的存档，关于该项目的所有issue全部丢失。issue堪称这个项目的贡献者与使用者浓度最高的聚居地，绝大多数讨论都是在issue内进行，只有极少部分有典型性的问题会被搬运到其他平台。 关了之后，当人们碰到问题，或试图参与开发时，想上网寻找相关资料，在搜索引擎里敲入相关字眼，引入眼帘的永远是已经关闭了的issue。 无论如何，项目是他们的，我没有参与贡献，我只是一个学习者，他们确确实实有权决定这个项目的一切。 不过我也确确实实的很不爽。 然后，黑泥结束，让我来夸夸这个项目。 VITS是一个文字转语音的网络，最大的特征是对抗学习和时长预测。论文涉及到不少我本人知识范围以外的东西，在在试着读透。 我在AutoDL上租了一块GPU进行训练。 开始的时候，我以为本地并不足以支持音色迁移的工作完成，所以音色迁移都是交给云端来完成的，现在想想浪费了不少资源。 后来，我开始训练翎羽的语音资料。 解释一下，翎羽是游戏明日方舟的一个角色，有中、日、韩、英四国语音，各有33条。一开始，我是使用日文语音进行训练的，日文语音总时长在三分钟左右。总共运行了63500步，然后我认为，仅仅三分钟的语音不足以构建出色的模型，于是停止了训练，导入了新的语音。 但是事实上，在这个项目中，模型和训练数据集语音直接挂钩，甚至可以说是一一对应，连顺序都不能替换。但我并没有意识到这一点，也没有人和我说，于是，我放弃了现有的训练数据集，后面的事情可想而知。 我跑了六万步的模型尚未完成，卡在不能训练和不能用之间，或者说，在我随机排列32条语音找到正确顺序之前，我无法对其进行进一步训练；同时由于训练步数原因，产生的音频电流声巨大，完全不能使用。 更糟糕的是，我使用的新训练集是四国语音复合的，也就是说实际上是四个人的语音素材。新训练集跑了三万多步，实际效果可谓是一团浆糊。 而我花了很久才意识到这一点。 关于VITS论文于三年前发表，属于是经典之一。正在读论文。 关于其他类似项目DDSP-SVC。 按照介绍，这是一个针对低显存设备进行特别优化的项目。我本人的笔记本电脑是惠普的战99，使用的是nvidia t600入门级专业卡，内存只有可怜的4G。 要不然我为什么要租显卡…… 还没用，但很期待。","categories":[],"tags":[]},{"title":"2023年4月19日","slug":"2023年4月19日","date":"2023-04-19T11:07:00.000Z","updated":"2023-04-19T14:19:56.152Z","comments":true,"path":"2023/04/19/2023年4月19日/","link":"","permalink":"http://petertan303.github.io/2023/04/19/2023%E5%B9%B44%E6%9C%8819%E6%97%A5/","excerpt":"","text":"亲爱的日记：关于vits前几天发现了autodl这个GPU租用平台，于是充了15块钱，拿来跑vits。 至于原因，我之前一直觉得，自家电脑环境有问题、显存也不够，不足以支撑运算。于是租了三块，每块用多少扣多少钱，一个小时0.78元，可以说是相当便宜。 刚刚回忆了一下，之前监控的内存占用，是不是只有2G多，还有快到离谱（训练一分钟歌曲只需要零点几秒）的速度，又想起还有conda这个环境管理器，于是在自己电脑上试了试。 事实证明，能跑，而且，对显存要求很低。大概只占用了1G多。虽然确实慢了不少，78秒的音频文件，使用了61秒跑完。尽管确实很慢，但比我想象中还是快太多了。 这下不需要忧心忡忡等GPu空闲了。也不需要开着filezilla等着文件传输的完成。更不需要熄灯后用手机热点慢慢传数据了。 但是训练模型，应该还是需要更牛逼的GPU来干。 关于spleeter这是一个分割音频中人声、伴奏的开源工程，只有11M左右。GUI版本甚至更小，只有10M。 我正在试图解读。 还是关于vitsvits和so-vits-svc有本质区别，虽然我把这俩混为一谈。vits，很小，只有14m；so-vits-svc，更小，小的超乎想象，只有9m。 但是事实上这俩确实是两码事。vits比较大可能是因为自带了测试样品。 so-vits-svc，SoftVC VITS Singing Voice Conversion。 vits，VITS，Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech。 这是VITS的论文。 https://arxiv.org/abs/2106.06103 https://petertan303.github.io/img/2106.06103.pdf 关于hexo博客插入pdf在线预览https://lizhening.github.io/posts/7d20ce7f/ 简单概括就是： hexo-pdf插件。通过npm安装，注意是在hexo根目录下执行该语句。npm install --save hexo-pdf &#123;% pdf 链接 %&#125;的形式插入即可，例如&#123;% pdf http://7xov2f.com1.z0.glb.clouddn.com/bash_freshman.pdf %&#125; 那么，我这个就是: 另外注意pdf可以直接放在source文件夹里面。似乎并不可以……还是放在img文件夹里得了。 好吧，还是有点问题。现在好了。真不错。 正事 [x] py作业 [ ] it英语作业 [ ] 体测：周四 [ ] 数字系统实验报告（纸质） [ ] 实际实验 [ ] 仿真实验：延时灯 [ ] 交通灯 [x] 美术鉴赏作业 [ ] 复习 [ ] 人工智能基础 [ ] 电磁场与波 不是正事希望可以找时间解决了…… [ ] VITS论文阅读 [ ] VITS代码阅读 [ ] so-vits-svc代码阅读","categories":[],"tags":[]},{"title":"关于香橙派显示屏","slug":"关于香橙派显示屏","date":"2023-04-11T10:33:01.000Z","updated":"2023-04-12T05:56:51.963Z","comments":true,"path":"2023/04/11/关于香橙派显示屏/","link":"","permalink":"http://petertan303.github.io/2023/04/11/%E5%85%B3%E4%BA%8E%E9%A6%99%E6%A9%99%E6%B4%BE%E6%98%BE%E7%A4%BA%E5%B1%8F/","excerpt":"","text":"香橙派店家资料LCD 显示屏和开发板的接线方式如下所示对应到手头的显示屏|TFT SPI 模块引脚|开发板26pin 对应的引脚|GPIO — GPIO num—-|—-|—-|—-|3.3v|VCC | 1 号引脚GND|GND |6 号引脚T_CS|CS |24 号引脚RST|RESET |7 号引脚|PC9 — 73AO(LCD_RS)|D/C |11 号引脚|PC6 — 70MOSI/SDI|SDI(MOSI) |19 号引脚SDK|SCK |23 号引脚?|LED |13 号引脚|PC5 — 69MISO|SDO(MISO) |21 引脚 显示屏店家资料解释|16|14|12|10|8|6|4|2||—-|—-|—-|—-|—-|—-|—-|—-|—-|电路板|T_CLK|NC|MOSI|NC|CS|SCK|NC|GND原理图|T_CLK|-|T_MOSI|-|LCD_CS|LCD_SCL|-|GND||解释|时钟？|-|输入|-|片选信号|时钟信号|-|地-|17|15|13|11|9|7|5|3|1电路板|T_CS|PEN|MISO|SDI|AO|RST|BL|3.3V原理图|T_CS|T_PEN|T_MISO|LCD_SDI|LCD_RS|LCD_RST|IO_BK|3.3v解释|片选信号|？|输出|传递数据|命令/数据|重置|？|电源 一般来说是标准七脚，分别是GND，VCC，D0，D1，RES，DC，CS GND：接地 VCC：供电 DO：Master input slave output，MISO， DI：Master output slave input，MOSI， RES：RST，复位 DC：RS，在只有MOSI的情况下控制写入数据还是命令，这个时候没有MISO CS：CE，SSEL，SS，片选信号 SCLK：时钟信号 放在这块显示屏上，则是 GND：接地 VCC：供电 DO：T_MISO DI：T_MOSI，LCD_SDI RES：LCD_RST DC：LCD_RS CS：T_CS SCLK：T_CLK，LCD_SCL 公用的有 GND 3.3v IO_BK LCD开头的有 LCD_CS LCD_SCL（CLK） LCD_SDI（MOSI） LCD_RS LCD_RST T开头的有 T_CLK T_MOSI T_MISO T_CS T_PEN 公用三个，T开头LCD开头各五个，共计16个，三个NC 基本参数： 240 X RGB X 320 驱动：fb_ili9341 使用ssh传输文件：123scp root@192.168.3.29:/boot/boot.bmp .scp &quot;burythelight2 (online-audio-converter.com).rar&quot; root@192.168.3.29:/.","categories":[],"tags":[]},{"title":"嵌入式操作系统","slug":"嵌入式操作系统","date":"2023-04-11T09:13:57.000Z","updated":"2023-04-11T23:58:20.592Z","comments":true,"path":"2023/04/11/嵌入式操作系统/","link":"","permalink":"http://petertan303.github.io/2023/04/11/%E5%B5%8C%E5%85%A5%E5%BC%8F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/","excerpt":"","text":"现有嵌入式操作系统Mobile operating systems DIP DOS on Atari Portfolio Embedded Linux (see also Linux for mobile devices) Android CalyxOS DivestOS EMUI Flyme OS GrapheneOS LineageOS MIUI Replicant See also List of custom Android distributions Firefox OS KaiOS Ångström distribution Familiar Linux Mæmo based on Debian deployed on Nokia’s Nokia 770, N800 and N810 Internet Tablets. OpenZaurus webOS from Palm, Inc., later Hewlett-Packard via acquisition, and most recently at LG Electronics through acquisition from Hewlett-Packard[39] Access Linux Platform bada Openmoko Linux OPhone MeeGo (from merger of Maemo &amp; Moblin) Mobilinux MotoMagx Qt Extended Sailfish OS Tizen (earlier called LiMo Platform) Ubuntu Touch PostmarketOS Inferno (distributed OS originally from Bell Labs) Magic Cap MS-DOS on Poqet PC, HP 95LX, HP 100LX, HP 200LX, HP 1000CX, HP OmniGo 700LX NetBSD Newton OS on Apple MessagePad Palm OS from Palm, Inc; now spun off as PalmSource PEN/GEOS on HP OmniGo 100 and 120 PenPoint OS Plan 9 from Bell Labs PVOS Symbian OS EPOC Windows CE, from Microsoft Pocket PC from Microsoft, a variant of Windows CE Windows Mobile from Microsoft, a variant of Windows CE Windows Phone from Microsoft DSPnano RTOS iOS watchOS tvOS iPod software iPodLinux iriver clix OS RockBox BlackBerry OS PEN/GEOS, GEOS-SC, GEOS-SE Palm OS Symbian platform (successor to Symbian OS) BlackBerry 10 HarmonyOS - Routers CatOS – by Cisco Systems Cisco IOS – originally Internetwork Operating System by Cisco Systems DNOS – by DriveNets Inferno – distributed OS originally from Bell Labs IOS-XR – by Cisco Systems JunOS – by Juniper Networks LCOS – by LANCOM Systems[40] Linux OpenWrt DD-WRT LEDE Gargoyle LibreCMC Zeroshell FTOS – by Force10 Networks FreeBSD m0n0wall OPNsense pfsense List of wireless router firmware projects - Other embedded Apache Mynewt ChibiOS/RT Contiki ERIKA Enterprise eCos NetBSD Nucleus RTOS[41] NuttX Minix NCOS freeRTOS, openRTOS, safeRTOS Fuchsia OpenEmbedded (or Yocto Project) OpenHarmony pSOS (Portable Software On Silicon) QNX – Unix-like real-time operating system, aimed primarily at the embedded systems market.[42] REX OS – microkernel; usually an embedded cell phone OS RIOT ROM-DOS TinyOS ThreadX RT-Thread DSPnano RTOS Windows IoT – formerly Windows Embedded Windows CE Windows IoT Core Windows IoT Enterprise Wind River VxWorks RTOS.[17] Wombat – microkernel; usually real-time embedded Zephyr LEGO Mindstorms brickOS leJOS 介绍1234567An embedded operating system is an operating system for embedded computer systems. Embedded operating systems are computer systems designed to increase functionality and reliability for achieving a specific task.[1] Resource efficiency comes at the cost of losing some functionality or granularity that larger computer operating systems provide, including functions that may not be used by the specialized applications run. Depending on the method used for multitasking, this type of OS is frequently considered a real-time operating system or RTOS. Embedded systems are mostly used as Real-time operating systems.All embedded systems contain a processor and software. There must be a place for embedded software to store the executable code and temporary storage for run-time data manipulations. These take the form of ROM and RAM, respectively. All embedded systems must also contain some form of inputs and outputs to function. Within the exception of these few common features, the rest of the embedded hardware is usually unique and varies from application to application.[2] The hardware running an embedded operating system can be very limited in resources; therefore the embedded design of these operating systems may have a narrow scope tailored to a specific application to achieve the desired operation under these constraints. The embedded operating system that organizes and controls the hardware usually determines the rest of the embedded hardware needed.To take better advantage of the processing power of the CPU, software developers may write critical code directly in assembly. This machine efficient language can potentially result in gains in speed and determinism at the cost of portability and maintainability. Often, embedded operating systems are written entirely in more portable languages, like C, however.An important difference between most embedded operating systems and desktop operating systems is that the application, including the operating system, is usually statically linked into a single executable image. Unlike a desktop operating system, the embedded operating system does not load and execute many applications.[3] This means that the system is only able to run a few application(s). 种类，构成，应用","categories":[],"tags":[]},{"title":"2023年4月8日","slug":"2023年4月8日","date":"2023-04-08T09:32:42.000Z","updated":"2023-04-08T10:36:20.294Z","comments":true,"path":"2023/04/08/2023年4月8日/","link":"","permalink":"http://petertan303.github.io/2023/04/08/2023%E5%B9%B44%E6%9C%888%E6%97%A5/","excerpt":"","text":"用 Python 读取&amp;解析 jsonjson 范例：123456789&#123; &quot;name&quot;: &quot;United States&quot;, &quot;population&quot;: 331002651, &quot;capital&quot;: &quot;Washington D.C.&quot;, &quot;languages&quot;: [ &quot;English&quot;, &quot;Spanish&quot; ]&#125;JSON以键值对的形式传递数据，类似XML，XML示例：12345678910&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;country&gt; &lt;name&gt;United States&lt;/name&gt; &lt;population&gt;331002651&lt;/population&gt; &lt;capital&gt;Washington D.C.&lt;/capital&gt; &lt;languages&gt; &lt;language&gt;English&lt;/language&gt; &lt;language&gt;Spanish&lt;/language&gt; &lt;/languages&gt;&lt;/country&gt;众所周知，Python原生支持JSON数据，json模块是标准库的一部分，无序手动解析。 可以将JSON数据从JSON格式转换到等效的Python对象，例如dictionary和list。JSON模块还可以将Python对象转换为JSON格式。 具体使用：将json字符串转化为字典传入：字符串格式的 json 数据。 123456import json# 导入json包country = &#x27;&#123;&quot;name&quot;: &quot;United States&quot;, &quot;population&quot;: 331002651&#125;&#x27;# 定义字符串，json，countrycountry_dict = json.loads(country)# 使用json.loads()方法处理country 结果country_dict是字典。 注意，json内数据类型和Python内有一一对应的关系。 JSON Python object dict array list string str number (integer) int number (real) float true True false False null None 将json文件转化为字典使用open()方法导入文件，然后使用json.loads()处理读入的字符串。123456import jsonwith open(&#x27;united_states.json&#x27;) as f: data = json.load(f)print(type(data))测试结果： python 字典单向读取，打印时呈现json格式。 用 Python 调用 api12345import requestsdef request_data(url): req = requests.get(url, timeout=30) # 请求连接 req_jason = req.json() # 获取数据 return req_jason 也就是通过requests包里的requests.get(url,timeout)进行获取内容，这个方法会返回一个字符串。 Python 正则模块 reQ：如何将非标准json数据（例如nga的api）掐头去尾？ A：使用re的findall()模块 12345678# 处理形如ashdasbdh(# 中间是json# );import redt = re.findall(r&#x27;[(](.*?)[)]&#x27;, text)data_json = json.loads(dt[0])print(dt)print(data_json) vscode json 自动排版使用json tools工具内的 ctrl+alt+M快捷键","categories":[],"tags":[]},{"title":"专业认知与探索期末作业","slug":"专业认知与探索期末作业","date":"2023-03-16T02:58:26.000Z","updated":"2023-04-23T15:21:49.342Z","comments":true,"path":"2023/03/16/专业认知与探索期末作业/","link":"","permalink":"http://petertan303.github.io/2023/03/16/%E4%B8%93%E4%B8%9A%E8%AE%A4%E7%9F%A5%E4%B8%8E%E6%8E%A2%E7%B4%A2%E6%9C%9F%E6%9C%AB%E4%BD%9C%E4%B8%9A/","excerpt":"","text":"截止时间：周五，也就是明天晚上 要求： 期末题目：用TX-1C学习板实现下列题目中的一个，每人独立完成。 必须完成基本要求，其它功能可以自行添加。 用学习板和超声模块实现超声测距，并用点阵或液晶显示。基本要求：使用超声测距模块进行距离测试，用点阵显示超声波测试的距离，距离越近，点阵中亮的点越少；距离越远，点阵中亮的点越多。（超声测距模块需要大家自己购买，参考型号是HC-SR04） 用学习板和超声模块实现超声测距，并用数码管显示距离。基本要求：使用超声测距模块进行距离测试，并用数码管显示测距结果。（超声测距模块需要大家自己购买，参考型号是HC-SR04） 利用键盘和1602液晶显示器实现简易计算器基本要求：利用矩阵键盘和独立键盘实现一个计算器，计算器必须具备加减乘除功能，并利用1602液晶显示输入的数据和计算结果。计算器的其它功能根据个人能力添加。 利用键盘和数码管实现简易计算器基本要求：利用矩阵键盘和独立键盘实现一个计算器，计算器必须具备加减乘除功能，并利用数码管显示输入的数据和计算结果。计算器的其它功能根据个人能力添加。 利用键盘、发光二极管和数码管实现一个交通信号灯基本要求：指定发光二极管代表红黄绿灯，绿灯亮20s后，黄灯闪烁3s，然后红灯再亮20s，交替变化。当红灯只剩5s时长时，数码管按秒显示倒计时；当绿灯只剩5s时长时，数码管按秒显示倒计时；黄灯工作的3s期间，指定某个发光二极管以500ms为间隔闪烁。根据个人能力实现单向或十字路口交通灯。 基于课程所学内容，自己拟定实验项目和内容，完成实验，并提交报告。 注意：期末项目电子版实验报告提交给助教，报告以“学号+姓名+期末题目”形式命名，时间可以放宽到下学期开学第三周之前。是否安排现场验收，视疫情情况而定。 没有超声模块，排除1、2 选择4：数码管、键盘、计算器 1602液晶显示屏不熟悉，排除 交通灯：考虑 计算器： 计算：加减乘除 需要指定按键：keyscan()，使用所有键盘 十个数字：0~9 加减乘除，四个以上 清零 其他功能 显示屏：display()，显示加减乘除的符号、数字 应该没了？ 交通灯： 指定发光二极管代表红黄绿灯 绿灯亮20s后，黄灯闪烁3s，然后红灯再亮20s，交替变化。 当红灯只剩5s时长时，数码管按秒显示倒计时；当绿灯只剩5s时长时，数码管按秒显示倒计时；黄灯工作的3s期间，指定某个发光二极管以500ms为间隔闪烁。根据个人能力实现单向或十字路口交通灯。 单向： 四个灯，绿灯红灯黄灯和500ms闪烁灯 计时： 绿灯20s，黄灯3s和闪烁灯500ms爆闪，红灯20s 数码管5s倒计时：红灯、绿灯；3s倒计时：黄灯 没了？ 十字路口： 两个单向？ 计算器： 数字表 有小数点 无小数点 运算 display() 实时显示数字，不显示符号 keyscan() 计算器 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149#include &lt;reg52.h&gt;//定义行引脚sbit hang[]=&#123;P3^7,P3^6,P3^5,P3^4&#125;; //定义列引脚sbit lie[]=&#123;P3^3,P3^2,P3^1,P3^0&#125;;char key[4][4]=&#123; &#123;&#x27;7&#x27;,&#x27;8&#x27;,&#x27;9&#x27;,&#x27;0&#x27;&#125;, &#123;&#x27;4&#x27;,&#x27;5&#x27;,&#x27;6&#x27;,&#x27;k&#x27;&#125;, &#123;&#x27;1&#x27;,&#x27;2&#x27;,&#x27;3&#x27;,&#x27;=&#x27;&#125;, &#123;&#x27;a&#x27;, &#x27;m&#x27;, &#x27;x&#x27;, &#x27;p&#x27;&#125;&#125;;// 加减乘除int num[7]=&#123;0&#125;;int cal_num[2]=&#123;0&#125;;char fuhao=0;unsigned char code num1[]= //没有小数点的0-9对应编码&#123;0x3f,0x06,0x5b,0x4f,0x66,0x6d,0x7d,0x07,0x7f,0x6f&#125;;unsigned char code num2[]= &#123;0xbf,0x86,0xdb,0xcf,0xe6,0xed,0xfd,0x87,0xff,0xef&#125;;unsigned char code place[]=&#123;0xfe,0xfd,0xfb,0xf7,0xf5,0xf3,0xf1&#125;;void delay(int z)&#123; int i,j; for(i=z;i&gt;0;i--); for(j=110;j&gt;0;j--);&#125;void display()&#123; int i=0; int temp = cal_num[0]; for(i=0;i&lt;7&amp;&amp;temp&gt;0;i++)&#123; num[i]=temp%10; temp/=10; &#125; for(i=0;i&lt;7;i++)&#123; wela=1; P0=place[i]; wela=0; P0=0x00; dula=1; //P0=(i==1?num2[num[i]]:num1[num[i]]); P0 = cal_num[1]; delay(10); dula=0; P0=0xff; &#125; return;&#125;char keyscan()&#123; char input; int i=0,j=0; for(j=0;j&lt;4;j++)&#123; P3=0xff; hang[j]=0; for(i=0;i&lt;4;i++)&#123; if(lie[i]==0) &#123; delay(10); if(lie[i]==0) &#123; while(lie[i]==0); input=key[i][j]; &#125; &#125; &#125; &#125; return input;&#125;int calculate(char input)&#123; int temp=0; switch(input)&#123; case &#x27;1&#x27;: case &#x27;2&#x27;: case &#x27;3&#x27;: case &#x27;4&#x27;: case &#x27;5&#x27;: case &#x27;6&#x27;: case &#x27;7&#x27;: case &#x27;8&#x27;: case &#x27;9&#x27;: case &#x27;0&#x27;: cal_num[1] = cal_num[1]*10 + ((int)input - &#x27;0&#x27;) break; case &#x27;a&#x27;: case &#x27;m&#x27;: case &#x27;x&#x27;: case &#x27;p&#x27;: case &#x27;=&#x27;: switch(fuhao)&#123; case &#x27;a&#x27;: cal_num[0]+=cal_num[1]; break; case &#x27;m&#x27;: cal_num[0]-=cal_num[1]; break; case &#x27;x&#x27;: cal_num[0]*=cal_num[1]; break; case &#x27;p&#x27;: cal_num[0]/=cal_num[1]; break; case &#x27;=&#x27;: case default: break; &#125; cal_num[1]=0; fuhao = input; break; case default: break; &#125;&#125;void main()&#123; //init char input=0; //begin while(1)&#123; display(); input = keyscan(); calculate(input); &#125; return;&#125; 修改后123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569#include &lt;reg52.h&gt;sbit dula=P2^6; //dula与wela为两个使能端sbit wela=P2^7;////定义行引脚sbit lie1=P3^7;sbit lie2=P3^6;sbit lie3=P3^5;sbit lie4=P3^4;// ////定义列引脚sbit hang1=P3^3;sbit hang2=P3^2;sbit hang3=P3^1;sbit hang4=P3^0;char key[4][4]=&#123; &#123;&#x27;7&#x27;,&#x27;8&#x27;,&#x27;9&#x27;,&#x27;0&#x27;&#125;, &#123;&#x27;4&#x27;,&#x27;5&#x27;,&#x27;6&#x27;,&#x27;k&#x27;&#125;, &#123;&#x27;1&#x27;,&#x27;2&#x27;,&#x27;3&#x27;,&#x27;=&#x27;&#125;, &#123;&#x27;a&#x27;, &#x27;m&#x27;, &#x27;x&#x27;, &#x27;p&#x27;&#125;&#125;;// 加减乘除long int cal_num[3]=&#123;0,0,0&#125;;char fuhao=0;char input=0;unsigned char code num1[]= //没有小数点的0-9对应编码&#123;0x3f,0x06,0x5b,0x4f,0x66,0x6d,0x7d,0x07,0x7f,0x6f&#125;;unsigned char code num2[]= &#123;0xbf,0x86,0xdb,0xcf,0xe6,0xed,0xfd,0x87,0xff,0xef&#125;;unsigned char code place[]=&#123; //0111_1111 7f //1011_1111 bf //1101_1111 df //1110_1111 ef //1111_0111 f7 //1111_1011 fb //1111_1101 fd //1111_1110 fe0xfe,0xfd,0xfb,0xf7,0xef,0xdf,0xbf,0x7f&#125;;void delay(int z)&#123; int i,j; for(i=z;i&gt;0;i--); for(j=110;j&gt;0;j--);&#125;void display()&#123; int i=0; int temp = cal_num[2];// for(i=0;i&lt;7&amp;&amp;temp&gt;0;i++)&#123;// num[i]=temp%10;// temp/=10;// &#125; for(i=5;i&gt;0/*&amp;&amp;temp&gt;0*/;i--)&#123; wela=1; P0=place[i]; wela=0; P0=0x00; dula=1; P0 = num1[temp%10]; temp/=10; delay(10); dula=0; P0=0xff; &#125; delay(100); return;&#125;//char keyscan()//&#123;// char input;// int i=0,j=0;// for(j=0;j&lt;4;j++)&#123;// P3=0xff;// hang[j]=0;// for(i=0;i&lt;4;i++)&#123;// if(lie[i]==0)// &#123;// delay(10);// if(lie[i]==0)// &#123;// while(lie[i]==0);// input=key[i][j];// &#125;// &#125;// &#125;// &#125;// return input;//&#125;//char keyscan()&#123;//&#123;// char input=0;// P3|=0xff;// hang1=0;// if(lie1==0)// &#123;// delay(10);// if(lie1==0)// &#123;// while(lie1==0);// input=key[0][0];// cal_num[1] = cal_num[1]*10 + ((int)input - &#x27;0&#x27;);// &#125;// &#125;// // if(lie2==0)// &#123;// delay(10);// if(lie2==0)// &#123;// while(lie2==0);// input=key[0][1];// cal_num[1] = cal_num[1]*10 + ((int)input - &#x27;0&#x27;);// &#125;// &#125;// // // if(lie3==0)// &#123;// delay(10);// if(lie3==0)// &#123;// while(lie3==0);// input=key[0][2];// cal_num[1] = cal_num[1]*10 + ((int)input - &#x27;0&#x27;);// &#125;// &#125;// // if(lie4==0)// &#123;// delay(10);// if(lie4==0)// &#123;// while(lie4==0);// input=key[0][3];// cal_num[1] = cal_num[1]*10 + ((int)input - &#x27;0&#x27;);// &#125;// &#125;// // // P3|=0xff;// hang2=0;// if(lie1==0)// &#123;// delay(10);// if(lie1==0)// &#123;// while(lie1==0);// input=key[1][0];// cal_num[1] = cal_num[1]*10 + ((int)input - &#x27;0&#x27;);// &#125;// &#125;// // if(lie2==0)// &#123;// delay(10);// if(lie2==0)// &#123;// while(lie2==0);// input=key[1][1];// cal_num[1] = cal_num[1]*10 + ((int)input - &#x27;0&#x27;);// &#125;// &#125;// // // if(lie3==0)// &#123;// delay(10);// if(lie3==0)// &#123;// while(lie3==0);// input=key[1][2];// cal_num[1] = cal_num[1]*10 + ((int)input - &#x27;0&#x27;);// &#125;// &#125;// // if(lie4==0)// &#123;// delay(10);// if(lie4==0)// &#123;// while(lie4==0);// input=key[1][3];// &#125;// &#125;// // P3|=0xff;// hang3=0;// // if(lie1==0)// &#123;// delay(10);// if(lie1==0)// &#123;// while(lie1==0);// input=key[2][0];// cal_num[1] = cal_num[1]*10 + ((int)input - &#x27;0&#x27;);// &#125;// &#125;// // if(lie2==0)// &#123;// delay(10);// if(lie2==0)// &#123;// while(lie2==0);// input=key[2][1];// cal_num[1] = cal_num[1]*10 + ((int)input - &#x27;0&#x27;);// &#125;// &#125;// // // if(lie3==0)// &#123;// delay(10);// if(lie3==0)// &#123;// while(lie3==0);// input=key[2][2];// cal_num[1] = cal_num[1]*10 + ((int)input - &#x27;0&#x27;);// &#125;// &#125;// // if(lie4==0)// &#123;// delay(10);// if(lie4==0)// &#123;// while(lie4==0);// input=key[2][3];// cal_num[1]=0;// fuhao = input;// &#125;// &#125;// // // P3|=0xff;// hang4=0;// // if(lie1==0)// &#123;// delay(10);// if(lie1==0)// &#123;// while(lie1==0);// input=key[3][0];// cal_num[0]+=cal_num[1];// cal_num[1]=0;// fuhao = input;// &#125;// &#125;// // if(lie2==0)// &#123;// delay(10);// if(lie2==0)// &#123;// while(lie2==0);// input=key[3][1];// cal_num[0]-=cal_num[1];// cal_num[1]=0;// fuhao = input;// &#125;// &#125;// // // if(lie3==0)// &#123;// delay(10);// if(lie3==0)// &#123;// while(lie3==0);// input=key[3][2];// cal_num[0]*=cal_num[1];// cal_num[1]=0;// fuhao = input;// &#125;// &#125;// // if(lie4==0)// &#123;// delay(10);// if(lie4==0)// &#123;// while(lie4==0);// input=key[3][3];// cal_num[0]/=cal_num[1];// cal_num[1]=0;// fuhao = input;// &#125;// &#125;// return input;//&#125;//&#125;char keyscan()&#123;&#123; char input=0; P3|=0xff; hang1=0; if(lie1==0) &#123; delay(10); if(lie1==0) &#123; while(lie1==0); input=key[0][0]; &#125; &#125; if(lie2==0) &#123; delay(10); if(lie2==0) &#123; while(lie2==0); input=key[0][1]; &#125; &#125; if(lie3==0) &#123; delay(10); if(lie3==0) &#123; while(lie3==0); input=key[0][2]; &#125; &#125; if(lie4==0) &#123; delay(10); if(lie4==0) &#123; while(lie4==0); input=key[0][3]; &#125; &#125; P3|=0xff; hang2=0; if(lie1==0) &#123; delay(10); if(lie1==0) &#123; while(lie1==0); input=key[1][0]; &#125; &#125; if(lie2==0) &#123; delay(10); if(lie2==0) &#123; while(lie2==0); input=key[1][1]; &#125; &#125; if(lie3==0) &#123; delay(10); if(lie3==0) &#123; while(lie3==0); input=key[1][2]; &#125; &#125; if(lie4==0) &#123; delay(10); if(lie4==0) &#123; while(lie4==0); input=key[1][3]; &#125; &#125; P3|=0xff; hang3=0; if(lie1==0) &#123; delay(10); if(lie1==0) &#123; while(lie1==0); input=key[2][0]; &#125; &#125; if(lie2==0) &#123; delay(10); if(lie2==0) &#123; while(lie2==0); input=key[2][1]; &#125; &#125; if(lie3==0) &#123; delay(10); if(lie3==0) &#123; while(lie3==0); input=key[2][2]; &#125; &#125; if(lie4==0) &#123; delay(10); if(lie4==0) &#123; while(lie4==0); input=key[2][3]; &#125; &#125; P3|=0xff; hang4=0; if(lie1==0) &#123; delay(10); if(lie1==0) &#123; while(lie1==0); input=key[3][0]; &#125; &#125; if(lie2==0) &#123; delay(10); if(lie2==0) &#123; while(lie2==0); input=key[3][1]; &#125; &#125; if(lie3==0) &#123; delay(10); if(lie3==0) &#123; while(lie3==0); input=key[3][2]; &#125; &#125; if(lie4==0) &#123; delay(10); if(lie4==0) &#123; while(lie4==0); input=key[3][3]; &#125; &#125; return input;&#125;&#125;void calculate(char input)&#123; switch(input)&#123; case &#x27;1&#x27;: case &#x27;2&#x27;: case &#x27;3&#x27;: case &#x27;4&#x27;: case &#x27;5&#x27;: case &#x27;6&#x27;: case &#x27;7&#x27;: case &#x27;8&#x27;: case &#x27;9&#x27;: case &#x27;0&#x27;: cal_num[1] = cal_num[1]*10 + ((int)input - &#x27;0&#x27;); cal_num[2] = cal_num[1]; break; case &#x27;a&#x27;: case &#x27;m&#x27;: case &#x27;x&#x27;: case &#x27;p&#x27;: case &#x27;=&#x27;: switch(fuhao)&#123; case &#x27;a&#x27;: cal_num[1]+=cal_num[0]; break; case &#x27;m&#x27;: cal_num[1]=cal_num[0]-cal_num[1]; break; case &#x27;x&#x27;: cal_num[1]*=cal_num[0]; break; case &#x27;p&#x27;: cal_num[1]=cal_num[0]/cal_num[1]; break; case &#x27;=&#x27;: default: break; &#125; cal_num[2]=cal_num[1]; cal_num[0]=cal_num[1]; cal_num[1]=0; fuhao = input; break; case &#x27;k&#x27;: cal_num[0]=cal_num[1]=cal_num[2]=cal_num[3]=0; delay(10); break; default: break; &#125; input = 0; return;&#125;void main()&#123; //init input = 0; //cal_num[1]=123456; //display(); //begin while(1)&#123;// cal_num[1]=12345; display(); delay(10); input = keyscan(); if(input!=0) calculate(input); &#125; return;&#125;","categories":[],"tags":[]},{"title":"2023年3月6日","slug":"2023年3月6日","date":"2023-03-06T04:43:05.000Z","updated":"2023-04-23T15:17:20.886Z","comments":true,"path":"2023/03/06/2023年3月6日/","link":"","permalink":"http://petertan303.github.io/2023/03/06/2023%E5%B9%B43%E6%9C%886%E6%97%A5/","excerpt":"","text":"1昨天的 “ jj ” 是龚写的。 环境变量可以通过alias设置别名，但不能永久保存，下一次启动shell时会重置。 PATH即是一个环境变量。Ubuntu中，有系统环境变量和用户环境变量，区别在于对所有用户生效还是仅对当前用户生效。 环境变量的储存文件：12345~/.profile# 无论是通过控制台还是图形界面启动程序时，都会自动执行该文件。~/.bashrc, ~/.bash_profile, ~/.bash_login# 当通过shell启动程序时，它们也会被加载；但当通过图形界面环境启动程序时，这些文件中的环境变量设置便不可用了。环境变量的储存文件夹：12345/etc/profile/etc/profile.d/etc/bash.bashrc/etc/profile.d文件夹来源于/etc/profile，目录下的*.sh，即以sh为后缀的文件都会被加载。 在图形界面环境下启动程序时，不会加载/ect/bash.bashrc里边的环境变量设置。 设置永久环境变量实例 编辑/etc/profile export 别名=&#39;指令&#39; 加载环境变量：1source /etc/profile cat 命令cat（英文全拼：concatenate）命令用于连接文件并打印到标准输出设备上。 1cat [-AbeEnstTuv] [--help] [--version] fileName -n 或 —number：由 1 开始对所有输出的行数编号。 -b 或 —number-nonblank：和 -n 相似，只不过对于空白行不编号。 -s 或 —squeeze-blank：当遇到有连续两行以上的空白行，就代换为一行的空白行。 -v 或 —show-nonprinting：使用 ^ 和 M- 符号，除了 LFD 和 TAB 之外。 -E 或 —show-ends : 在每行结束处显示 $。 -T 或 —show-tabs: 将 TAB 字符显示为 ^I。 -A, —show-all：等价于 -vET。 -e：等价于”-vE”选项； -t：等价于”-vT”选项； 用法：123456789cat A B &gt; C# 将文件B中的内容加上A，写入C中cat A B C &gt;&gt; D# 将B与C之间加上A，写入D中cat /dev/null &gt;&gt; A# 清空A将语句写入环境变量： echo &#39;PATH=&quot;$PATH:./node_modules/.bin&quot;&#39; &gt;&gt; ~/.profile 如何将文件夹变为 git 版本库 进入文件夹 git init 将文件添加到本地仓库：git add 可以同时添加多个文件，用空格隔开 提交：git commit -m &quot;对于本次提交的说明&quot;","categories":[],"tags":[{"name":"日志","slug":"日志","permalink":"http://petertan303.github.io/tags/%E6%97%A5%E5%BF%97/"}]},{"title":"jj","slug":"jj","date":"2023-03-05T10:52:07.000Z","updated":"2023-03-05T10:58:11.928Z","comments":true,"path":"2023/03/05/jj/","link":"","permalink":"http://petertan303.github.io/2023/03/05/jj/","excerpt":"","text":"AI绘画基于本地的python,python具体是啥还需自学。linux指令略知一二，ls ls-，rm，cd，ssh，hexo。。。 非常多，还需自学。 香橙派类似于一微型电脑，有一具体应用程序，可以进行相应指令输入， 阿里云盘。。 从头开始学习python以及linux，学习到何种程度具体情况具体分析。","categories":[],"tags":[]},{"title":"2023年3月5日","slug":"2023年3月5日","date":"2023-03-05T05:27:13.000Z","updated":"2023-04-23T15:19:33.239Z","comments":true,"path":"2023/03/05/2023年3月5日/","link":"","permalink":"http://petertan303.github.io/2023/03/05/2023%E5%B9%B43%E6%9C%885%E6%97%A5/","excerpt":"","text":"买的小音箱给送到其他地方去了，憨憨本色。 然后，列一下截至目前已经买的东西：|物件|价格|购买平台|备注||—-|—-|—-|—-||orange pi zero 2 本体 + 扩展板|158.90|淘宝|12元运费，总计170.90||闪迪64G内存卡 套餐|41.90|淘宝|-|0.5m hdmi线|0.99|淘宝|特惠买的，没啥用usb 转 ttl 刷机板|4.00|淘宝|-5v xh2.54 风扇|2.00|淘宝|-5v3a 电源|7.00|淘宝|卖家未发货，退款蓝牙音箱|11.9|拼多多|送到南京去了总计|238.69|-|- orange pi zero 2 进展我的香橙派连接的是寝室网络，一直在纠结要如何在寝室外使用。 刚刚意识到可以直接通过 ttl 串口登录香橙派，不一定需要 ssh 或远程桌面或显示屏。这样只需要带上电脑和 ttl 转接头和杜邦线就行了。 下一步计划是 GUI 制作。 Microwindows MiniGui QT Gtk+ OpenGUI FLTK LingLongGUI LearningGUI 今天做了什么买了大物实验II的实验书、买了数字系统实验II的书和报告册。 然后上午摸鱼摸了一上午。 作业 周一 电磁场与波 信号与系统 需要作业本 IT英语 暂时没有作业，潜在项目 神经网络导论 周二 美术鉴赏 微处理器与嵌入式系统 可能有 人工智能基础 大物实验II 预习实验？ 周三 python语言程序设计及其应用 似乎有作业 周四 数字系统实验 asd 学术规范与论文写作 周五 唐球","categories":[],"tags":[{"name":"日志","slug":"日志","permalink":"http://petertan303.github.io/tags/%E6%97%A5%E5%BF%97/"}]},{"title":"2023年3月4日","slug":"2023年3月4日","date":"2023-03-04T15:32:31.000Z","updated":"2023-03-05T05:26:10.822Z","comments":true,"path":"2023/03/04/2023年3月4日/","link":"","permalink":"http://petertan303.github.io/2023/03/04/2023%E5%B9%B43%E6%9C%884%E6%97%A5/","excerpt":"","text":"买了香橙派 zero 2，租了阿里云服务器。 阿里云服务器已经实现的： ftp 服务器安装 wordpress 服务器安装 远程桌面 vnc 安装 MySql 数据库 香橙派 zero 2最近一直在摆弄。安装过程中，碰上的问题： 烧录错误镜像 Paragon ExtFS for Windows无法读取 sd 卡内容 成功配置了 wi-fi，ssh，音乐播放，安装桌面 烧录镜像完成后，遇到的问题有： 端口设置开放： 先用iptables -I INPUT -p tcp --dport 端口号 -j ACCEPT 设置需要开放端口号、权限、协议 iptables-save保存 sudo netfilter-persistent save永久保存 下一次使用需要sudo netfilter-persistent reload ftp 搭建失败 未解决 aplay 调节音量：差点把自己弄聋（开玩笑） man aplay查看帮助 aplay -D plughw:0,0 xxx.wav指定播放设备 alsamixer设置音量 broot 安装失败 直接下载安装包，未解决 git 无法提交 重新设置 putty push 的时候卡在最后：添加参数sendpack.sideband git config --global sendpack.sideband false git config --local sendpack.sideband false 网络更换手机热点 conda 很慢很卡 安装mamba 安装 vnc 失败 未解决 解压 rar 需要 unrar e 包名（直接解压）或 unrar x 包名（创建新目录） 买了风扇、蓝牙音箱等等配件。 清单：|物件|价格|购买平台|备注||—-|—-|—-|—-||orange pi zero 2 本体 + 扩展板|158.90|淘宝|12元运费||闪迪64G内存卡 套餐|41.90|淘宝||0.5m hdmi线|0.99|淘宝|特惠买的，没啥用usb 转 ttl 刷机板|4.00|淘宝|5v xh2.54 风扇|2.00|淘宝|5v3a 电源|7.00|淘宝|卖家未发货，退款蓝牙音箱|11.9|拼多多|本来打算买有线喇叭，脑子一热就买了 vist借龚的电脑跑出了模型。遇到的问题有： 安装包需要 anaconda pip 换源 临时：pip install -i https://pypi.tuna.tsinghua.edu.cn/simple some-package 永久：pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple numpy 和 python 版本不匹配 卸载重装 安装 cuda 官网下载安装 占用储存巨大 requirements.txt 依赖没写完整 手动安装依赖 pip、conda 无法卸载 python 用 conda 直接安装 另一个版本的 python 或者用 anaconda 创建一个全新环境，创建时配置默认 python 但是储存占用……好吧、必要的牺牲 我自己电脑配置环境，遇到的问题： 最大问题：显存过小，至少需要 4.3G 而我只有 4G conda 无法更换 python 版本 同龚 但是龚的电脑可以随便折腾，不用担心储存不够。真的爽！ stable-diffusion 绘图时间太久了，想不起来，下次再写","categories":[],"tags":[{"name":"日志","slug":"日志","permalink":"http://petertan303.github.io/tags/%E6%97%A5%E5%BF%97/"}]},{"title":"2023年2月5日","slug":"2023年2月5日","date":"2023-02-05T11:17:48.000Z","updated":"2023-02-05T11:26:19.500Z","comments":true,"path":"2023/02/05/2023年2月5日/","link":"","permalink":"http://petertan303.github.io/2023/02/05/2023%E5%B9%B42%E6%9C%885%E6%97%A5/","excerpt":"","text":"测试网易云音乐的插件 原版 测试增大高度 测试自动播放 测试边框","categories":[],"tags":[{"name":"Test","slug":"Test","permalink":"http://petertan303.github.io/tags/Test/"}]},{"title":"2023年1月21日","slug":"2023年1月21日","date":"2023-01-21T11:43:16.000Z","updated":"2023-01-21T12:32:29.799Z","comments":true,"path":"2023/01/21/2023年1月21日/","link":"","permalink":"http://petertan303.github.io/2023/01/21/2023%E5%B9%B41%E6%9C%8821%E6%97%A5/","excerpt":"","text":"http-serverhttp-server可以通过在本地文件夹内运行来实现预览网站的功能。或者说，让任意一个目录成为服务器的目录。默认打开index.html，如果没有，会生成一个默认网页，里面有文件夹内所有内容。 一般默认的网址为192.168.1.2:8081和127.0.0.1:8081，前者可以通过在同一路由下的其他设备访问，后者只能在本设备内查看。 “程序员游戏” 网页游戏： https://screeps.com/ https://codecombat.cn/play https://www.codingame.com/start https://www.binancemag.com/?id=23707 steam 游戏： SHENZHEN I/O SpaceChem TIS - 100 Human Source Machine A = B","categories":[],"tags":[{"name":"日志","slug":"日志","permalink":"http://petertan303.github.io/tags/%E6%97%A5%E5%BF%97/"}]},{"title":"试图学习CSS","slug":"试图学习CSS","date":"2023-01-20T03:54:55.000Z","updated":"2023-01-20T05:06:57.050Z","comments":true,"path":"2023/01/20/试图学习CSS/","link":"","permalink":"http://petertan303.github.io/2023/01/20/%E8%AF%95%E5%9B%BE%E5%AD%A6%E4%B9%A0CSS/","excerpt":"","text":"基本语法格式CSS = 选择器 + 声明块 例：1234p &#123; color: red; text-align: center;&#125;p 为选择器，指向&lt;p&gt;标签。属性 - 冒号 - 属性值 - 分号。 注释同 C ，/*注释*/。 CSS的使用 外部CSS 例如，html内的一句&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;mystyle.css&quot;&gt;，指向mystyle.css：12345678body &#123; background-color: lightblue;&#125;h1 &#123; color: navy; margin-left: 20px;&#125; 内部css html文件中，head部分的&lt;style&gt;元素中进行定义。123456789101112131415161718192021&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;style&gt;body &#123; background-color: linen;&#125;h1 &#123; color: maroon; margin-left: 40px;&#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;This is a heading&lt;/h1&gt;&lt;p&gt;This is a paragraph.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 行内css（内联样式） 将style属性赋予某个元素。123456789&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;body&gt;&lt;h1 style=&quot;color:blue;text-align:center;&quot;&gt;This is a heading&lt;/h1&gt;&lt;p style=&quot;color:red;&quot;&gt;This is a paragraph.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 层叠顺序当为某个 HTML 元素指定了多个样式时，会使用哪种样式呢？ 页面中的所有样式将按照以下规则“层叠”为新的“虚拟”样式表，其中第一优先级最高： 1.行内样式（在 HTML 元素中） 2.外部和内部样式表（在 head 部分） 3.浏览器默认样式 因此，行内样式具有最高优先级，并且将覆盖外部和内部样式以及浏览器默认样式。 css内容颜色 颜色名 赋颜色的一种方式 背景色 12&lt;h1 style=&quot;background-color:DodgerBlue;&quot;&gt;China&lt;/h1&gt;&lt;p style=&quot;background-color:Tomato;&quot;&gt;China is a great country!&lt;/p&gt; 文本颜色 123&lt;h1 style=&quot;color:Tomato;&quot;&gt;China&lt;/h1&gt;&lt;p style=&quot;color:DodgerBlue;&quot;&gt;China is a great country!&lt;/p&gt;&lt;p style=&quot;color:MediumSeaGreen;&quot;&gt;China, officially the People&#x27;s Republic of China...&lt;/p&gt; 边框颜色 123&lt;h1 style=&quot;border:2px solid Tomato;&quot;&gt;Hello World&lt;/h1&gt;&lt;h1 style=&quot;border:2px solid DodgerBlue;&quot;&gt;Hello World&lt;/h1&gt;&lt;h1 style=&quot;border:2px solid Violet;&quot;&gt;Hello World&lt;/h1&gt; 颜色值 使用RGB值、HEX值、HSL值、RGBA值或者HSLA值来指定颜色。123456&lt;h1 style=&quot;background-color:rgb(255, 99, 71);&quot;&gt;...&lt;/h1&gt;&lt;h1 style=&quot;background-color:#ff6347;&quot;&gt;...&lt;/h1&gt;&lt;h1 style=&quot;background-color:hsl(9, 100%, 64%);&quot;&gt;...&lt;/h1&gt;&lt;h1 style=&quot;background-color:rgba(255, 99, 71, 0.5);&quot;&gt;...&lt;/h1&gt;&lt;h1 style=&quot;background-color:hsla(9, 100%, 64%, 0.5);&quot;&gt;...&lt;/h1&gt;直接使用RGB：rgb(red, green, blue) 使用RGBA：有不透明度的RGB 背景12345678910111213body &#123; background-color: lightblue;/* 背景色 */ opacity: 0.3;/* 不透明度 */ background-image: url(&quot;paper.gif&quot;);/* 背景图像 */&#125;/* 以及 */body &#123; background-image: url(&quot;tree.png&quot;); background-repeat: no-repeat; background-position: right top; background-attachment: fixed;&#125; 简写：123body &#123; background: #ffffff url(&quot;tree.png&quot;) no-repeat right top;&#125;在使用简写属性时，属性值的顺序为： background-color background-image background-repeat background-attachment background-position 轮廓（不同于边框）CSS 拥有如下轮廓属性： outline-style outline-color outline-width outline-offset outline 文本 文本对齐 文本方向 垂直对齐 文字装饰 大小写自动转换 缩进 字符间距 行高 字间距 文字阴影 斜体 粗细 大小 CSS 盒子模型CSS 选择器布局方式CSS3","categories":[],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://petertan303.github.io/tags/%E7%AC%94%E8%AE%B0/"},{"name":"未完待续","slug":"未完待续","permalink":"http://petertan303.github.io/tags/%E6%9C%AA%E5%AE%8C%E5%BE%85%E7%BB%AD/"}]},{"title":"2023年1月20日","slug":"2023年1月20日","date":"2023-01-20T03:42:26.000Z","updated":"2023-01-20T11:36:58.811Z","comments":true,"path":"2023/01/20/2023年1月20日/","link":"","permalink":"http://petertan303.github.io/2023/01/20/2023%E5%B9%B41%E6%9C%8820%E6%97%A5/","excerpt":"","text":"关于阿里云ESC的应用本质是一个可租赁服务器。要用于搭建博客，需要安装Apache（服务器软件）、MariaDB数据库（或者MySql）、PHP，然后通过WordPress完成博客的搭建。 CSS的学习笔记 测试html元素的插入hhhhh 12&lt;p&gt;&lt;b&gt;hhhhh&lt;/b&gt;&lt;/p&gt;","categories":[],"tags":[{"name":"日志","slug":"日志","permalink":"http://petertan303.github.io/tags/%E6%97%A5%E5%BF%97/"}]},{"title":"总结一下hexo-theme-fluid的使用方法","slug":"总结一下hexo-theme-fluid的使用方法","date":"2023-01-17T02:16:35.000Z","updated":"2023-01-17T03:32:21.729Z","comments":true,"path":"2023/01/17/总结一下hexo-theme-fluid的使用方法/","link":"","permalink":"http://petertan303.github.io/2023/01/17/%E6%80%BB%E7%BB%93%E4%B8%80%E4%B8%8Bhexo-theme-fluid%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/","excerpt":"来看看罢？","text":"全局 设置文章默认封面：12post: default_index_img: /img/example.jpg 代码块设置：123456789101112code: copy_btn: true highlight: enable: true line_number: true lib: &quot;highlightjs&quot; highlightjs: style: &#x27;Github Gist&#x27; bg_color: false prismjs: style: &quot;default&quot; preprocess: true copy_btn: 是否开启复制代码的按钮 line_number: 是否开启行号 highlight: 是否开启代码高亮 lib: 选择生成高亮的库，可选项: highlightjs、prismjs，对应下面两组配置，高亮的配置说明具体见主题配置中的注释 首页 大标题：Slogan(打字机)，配置方法是1234index: slogan: enable: true text: 这是一条 Slogan 每篇文章 指定摘要：12# 在文章开头加上：excerpt: 这是摘要 隐藏文章：12# 在文章开头加上：hide: true 手动置顶：12# 在文章开头加上：sticky: 100 在首页的封面：12# 在文章开头加上：index_img: /img/example.jpg 文章头图：12# 在文章开头加上：banner_img: /img/post_banner.jpg 手动置顶：12# 在文章开头加上：sticky: 100 勾选框：1&#123;% cb 文字, 是否已勾选, 是否内联 %&#125; 这是一个勾选框 按钮：1&#123;% btn 链接, text, title %&#125; text 组图：1234567&#123;% gi total n1-n2-... %&#125; ![](url) ![](url) ![](url) ![](url) ![](url)&#123;% endgi %&#125; 特殊页面 About 页","categories":[],"tags":[{"name":"日志","slug":"日志","permalink":"http://petertan303.github.io/tags/%E6%97%A5%E5%BF%97/"}]},{"title":"Hello World？Peter Tan！！","slug":"hello-world","date":"2023-01-16T13:39:17.273Z","updated":"2023-01-16T13:39:17.273Z","comments":true,"path":"2023/01/16/hello-world/","link":"","permalink":"http://petertan303.github.io/2023/01/16/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"我超，原","slug":"图片测试","date":"2023-01-16T12:19:36.000Z","updated":"2023-01-17T06:39:12.948Z","comments":true,"path":"2023/01/16/图片测试/","link":"","permalink":"http://petertan303.github.io/2023/01/16/%E5%9B%BE%E7%89%87%E6%B5%8B%E8%AF%95/","excerpt":"测试一下添加图片！！","text":"图片测试……？能看见吗？ 实际操作时，hexo 会给文件夹套进一串文件夹嵌套，比如说今天是2023年1月16日，套完前面会多一个2023/01/16/ 操作方法： 安装插件 hexo-asset-imageconfig 里的 post_asset_folder 改为 ture然后新生成的 md 就有了伴生图片文件夹，把图片放进去要使用的话，日期 + 文件夹 + 文件名例如：![图片](2023/01/16/图片测试/83-2.jpg &quot;&quot;) 有了插件 hexo-renderer-marked 的话，可以直接用图片名字，不需要日期和文件夹。 官方方法不使用中括号小括号的 md 语法，而是使用官方的 &#123;% asset_img example.jpg This is an example image %&#125; 现在使用了fluid主题放在source底下的img文件夹会被一并导出，使用img内图片：/img/asdasd.jpg 然后，事实证明，现在不能直接用图片名字了。 综上，要使用图片，就放在 source/img/ 下，使用的时候引用 ![](img/图片 &quot;&quot;)，要想并排显示需要套一个 &#123;% gi 4 4 %&#125;` 和 `&#123;% endgi %&#125;。&#123;% asset_img example.jpg This is an example image %&#125; 似乎不能用了。 这是按钮NGA!!","categories":[],"tags":[{"name":"test","slug":"test","permalink":"http://petertan303.github.io/tags/test/"}]},{"title":"2023年1月16日","slug":"2023年1月16日","date":"2023-01-16T09:28:49.000Z","updated":"2023-04-23T15:21:12.637Z","comments":true,"path":"2023/01/16/2023年1月16日/","link":"","permalink":"http://petertan303.github.io/2023/01/16/2023%E5%B9%B41%E6%9C%8816%E6%97%A5/","excerpt":"","text":"hexo 使用： 12345678$ cd myblog//首先进入myblog文件夹$ hexo clear//然后清理之前残留的网页$ hexo g//然后生成网页$ hexo d //然后推送到GitHub上 markdown 本身使用 标题：井号，或 “ === ” ， 或 “ —- ” 段落：一行空白行，不应使用 tab 或者空格。 换行：段尾加两个空格，并换行。或者使用 标签。 粗体：两个星号或者两个下划线。 斜体：一个星号或一个下划线。 引用：在段落前添加 &gt; 符号。要引用多个段落，应给空白行也添加 &gt; 符号。 嵌套引用：额外加一个 &gt; 符号。 列表：数字和英文句号。 例如： 阿三大苏打 阿三大苏打 阿三大苏打 无序列表：段前加 - 或 * 或 + 。要保持缩进，需要添加四个空格，或一个 tab 。 代码块：四个空格或一个 tab 。 短单词表示为代码：用 ‘ 包裹。一段代码包含单引号：这段代码应用 `` 包裹。围栏代码块：加入 ``` 包裹。 分割线： 三个星号、三个 - 、三个下划线，并在此之后添加空白行。 链接：中括号包含文本，小括号包含链接。所谓 title ， 即是鼠标悬浮在链接上的时候显示的东西，可以用双引号写在小括号结尾。hhh对于一般的链接，用尖括号框起来即可。https://nga.178.com 图片：![这是图片](/assets/img/philly-magic-garden.jpg &quot;Magic Gardens&quot;) 或者有链接的图片：[![沙漠中的岩石图片](/assets/img/shiprock.jpg &quot;Shi prock&quot;)](https://markdown.com.cn) 如何将 Windows 下文件导入 wsl wsl 中的 /mnt 文件夹，对应 Windows 的计算机。例如，想要引用 D:\\桌面\\临时 里面的 103041518_p0.jpg，对应过来就是 /mnt/d/桌面/临时/103041518_p0.jpg然后复制到 wsl：cp /mnt/d/桌面/临时/103041518_p0.jpg ~/myblog/source/_posts/图片测试 看看效果？ 2023年4月23日更新： 其实可以直接通过Windows资源管理器访问linux文件夹。 Git 的使用 git commit &lt;文件&gt; （然后需要写提交日志） git pull git push","categories":[],"tags":[]},{"title":"my first blog test?","slug":"博客测试1","date":"2023-01-16T05:30:02.000Z","updated":"2023-01-16T09:51:09.351Z","comments":true,"path":"2023/01/16/博客测试1/","link":"","permalink":"http://petertan303.github.io/2023/01/16/%E5%8D%9A%E5%AE%A2%E6%B5%8B%E8%AF%951/","excerpt":"","text":"Hello, world! 1//这是一个代码块 标题网址测试：nga","categories":[],"tags":[{"name":"test","slug":"test","permalink":"http://petertan303.github.io/tags/test/"}]}],"categories":[],"tags":[{"name":"日志","slug":"日志","permalink":"http://petertan303.github.io/tags/%E6%97%A5%E5%BF%97/"},{"name":"Test","slug":"Test","permalink":"http://petertan303.github.io/tags/Test/"},{"name":"笔记","slug":"笔记","permalink":"http://petertan303.github.io/tags/%E7%AC%94%E8%AE%B0/"},{"name":"未完待续","slug":"未完待续","permalink":"http://petertan303.github.io/tags/%E6%9C%AA%E5%AE%8C%E5%BE%85%E7%BB%AD/"},{"name":"test","slug":"test","permalink":"http://petertan303.github.io/tags/test/"}]}